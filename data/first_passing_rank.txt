wrap_data.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
start rank:4
start rank:2
start rank:5
start rank:3
start rank:1
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.501497 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 47854
[LightGBM] [Info] Number of data points in the train set: 632073, number of used features: 257
[LightGBM] [Info] Start training from score 7.467908
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 17.3586	valid_1's l2: 16.6441
[20]	training's l2: 15.8757	valid_1's l2: 15.1494
[30]	training's l2: 14.8476	valid_1's l2: 14.1101
[40]	training's l2: 14.1274	valid_1's l2: 13.3852
[50]	training's l2: 13.6171	valid_1's l2: 12.8747
[60]	training's l2: 13.2485	valid_1's l2: 12.5081
[70]	training's l2: 12.9765	valid_1's l2: 12.2371
[80]	training's l2: 12.7685	valid_1's l2: 12.0317
[90]	training's l2: 12.6121	valid_1's l2: 11.879
[100]	training's l2: 12.489	valid_1's l2: 11.7594
[110]	training's l2: 12.3916	valid_1's l2: 11.6641
[120]	training's l2: 12.3121	valid_1's l2: 11.5879
[130]	training's l2: 12.2474	valid_1's l2: 11.5273
[140]	training's l2: 12.19	valid_1's l2: 11.4764
[150]	training's l2: 12.1417	valid_1's l2: 11.4344
[160]	training's l2: 12.0982	valid_1's l2: 11.3986
[170]	training's l2: 12.0602	valid_1's l2: 11.3666
[180]	training's l2: 12.0255	valid_1's l2: 11.3395
[190]	training's l2: 11.9942	valid_1's l2: 11.3152
[200]	training's l2: 11.9653	valid_1's l2: 11.2936
[210]	training's l2: 11.9388	valid_1's l2: 11.2743
[220]	training's l2: 11.9135	valid_1's l2: 11.2562
[230]	training's l2: 11.8897	valid_1's l2: 11.2408
[240]	training's l2: 11.868	valid_1's l2: 11.2257
[250]	training's l2: 11.8469	valid_1's l2: 11.2121
[260]	training's l2: 11.8268	valid_1's l2: 11.1994
[270]	training's l2: 11.8077	valid_1's l2: 11.1885
[280]	training's l2: 11.7897	valid_1's l2: 11.1782
[290]	training's l2: 11.7716	valid_1's l2: 11.1684
[300]	training's l2: 11.7549	valid_1's l2: 11.159
[310]	training's l2: 11.7388	valid_1's l2: 11.1509
[320]	training's l2: 11.7228	valid_1's l2: 11.1429
[330]	training's l2: 11.7067	valid_1's l2: 11.1347
[340]	training's l2: 11.6921	valid_1's l2: 11.1283
[350]	training's l2: 11.6774	valid_1's l2: 11.1209
[360]	training's l2: 11.6628	valid_1's l2: 11.1136
[370]	training's l2: 11.6481	valid_1's l2: 11.106
[380]	training's l2: 11.6348	valid_1's l2: 11.1003
[390]	training's l2: 11.6213	valid_1's l2: 11.0943
[400]	training's l2: 11.6076	valid_1's l2: 11.0883
[410]	training's l2: 11.5953	valid_1's l2: 11.0836
[420]	training's l2: 11.5825	valid_1's l2: 11.0784
[430]	training's l2: 11.5702	valid_1's l2: 11.0735
[440]	training's l2: 11.5578	valid_1's l2: 11.0685
[450]	training's l2: 11.5455	valid_1's l2: 11.0636
[460]	training's l2: 11.5335	valid_1's l2: 11.0596
[470]	training's l2: 11.522	valid_1's l2: 11.0563
[480]	training's l2: 11.5106	valid_1's l2: 11.0524
[490]	training's l2: 11.4993	valid_1's l2: 11.048
[500]	training's l2: 11.488	valid_1's l2: 11.0443
[510]	training's l2: 11.4771	valid_1's l2: 11.0408
[520]	training's l2: 11.4666	valid_1's l2: 11.0384
[530]	training's l2: 11.4558	valid_1's l2: 11.035
[540]	training's l2: 11.4455	valid_1's l2: 11.0322
[550]	training's l2: 11.4356	valid_1's l2: 11.0294
[560]	training's l2: 11.4257	valid_1's l2: 11.0273
[570]	training's l2: 11.415	valid_1's l2: 11.0237
[580]	training's l2: 11.4049	valid_1's l2: 11.0206
[590]	training's l2: 11.3948	valid_1's l2: 11.018
[600]	training's l2: 11.385	valid_1's l2: 11.0159
[610]	training's l2: 11.3749	valid_1's l2: 11.0137
[620]	training's l2: 11.3654	valid_1's l2: 11.0113
[630]	training's l2: 11.3566	valid_1's l2: 11.0092
[640]	training's l2: 11.3473	valid_1's l2: 11.0069
[650]	training's l2: 11.3381	valid_1's l2: 11.0047
[660]	training's l2: 11.3291	valid_1's l2: 11.003
[670]	training's l2: 11.3202	valid_1's l2: 11.0015
[680]	training's l2: 11.3115	valid_1's l2: 11
[690]	training's l2: 11.3025	valid_1's l2: 10.9977
[700]	training's l2: 11.2944	valid_1's l2: 10.9963
[710]	training's l2: 11.2855	valid_1's l2: 10.9946
[720]	training's l2: 11.2766	valid_1's l2: 10.9934
[730]	training's l2: 11.2683	valid_1's l2: 10.9928
[740]	training's l2: 11.26	valid_1's l2: 10.991
[750]	training's l2: 11.2515	valid_1's l2: 10.9896
[760]	training's l2: 11.2434	valid_1's l2: 10.9886
[770]	training's l2: 11.2354	valid_1's l2: 10.9875
[780]	training's l2: 11.2269	valid_1's l2: 10.9859
[790]	training's l2: 11.2192	valid_1's l2: 10.9852
[800]	training's l2: 11.2117	valid_1's l2: 10.9846
[810]	training's l2: 11.2033	valid_1's l2: 10.9836
[820]	training's l2: 11.1949	valid_1's l2: 10.9822
[830]	training's l2: 11.1874	valid_1's l2: 10.9818
[840]	training's l2: 11.1794	valid_1's l2: 10.9804
[850]	training's l2: 11.1716	valid_1's l2: 10.9794
[860]	training's l2: 11.1639	valid_1's l2: 10.9791
[870]	training's l2: 11.1566	valid_1's l2: 10.9782
[880]	training's l2: 11.149	valid_1's l2: 10.9775
[890]	training's l2: 11.1423	valid_1's l2: 10.977
[900]	training's l2: 11.135	valid_1's l2: 10.9769
[910]	training's l2: 11.1278	valid_1's l2: 10.9763
[920]	training's l2: 11.1208	valid_1's l2: 10.9756
[930]	training's l2: 11.1134	valid_1's l2: 10.9754
[940]	training's l2: 11.1061	valid_1's l2: 10.9744
[950]	training's l2: 11.0991	valid_1's l2: 10.9738
[960]	training's l2: 11.0919	valid_1's l2: 10.9733
[970]	training's l2: 11.0849	valid_1's l2: 10.9728
[980]	training's l2: 11.0777	valid_1's l2: 10.9723
[990]	training's l2: 11.0707	valid_1's l2: 10.9716
[1000]	training's l2: 11.0634	valid_1's l2: 10.9705
[1010]	training's l2: 11.0559	valid_1's l2: 10.9698
[1020]	training's l2: 11.048	valid_1's l2: 10.9688
[1030]	training's l2: 11.0409	valid_1's l2: 10.9683
[1040]	training's l2: 11.0344	valid_1's l2: 10.9678
[1050]	training's l2: 11.0262	valid_1's l2: 10.9667
[1060]	training's l2: 11.0191	valid_1's l2: 10.9663
[1070]	training's l2: 11.0125	valid_1's l2: 10.9659
[1080]	training's l2: 11.0053	valid_1's l2: 10.9654
[1090]	training's l2: 10.999	valid_1's l2: 10.9647
[1100]	training's l2: 10.9919	valid_1's l2: 10.9644
[1110]	training's l2: 10.9849	valid_1's l2: 10.964
[1120]	training's l2: 10.9785	valid_1's l2: 10.9638
[1130]	training's l2: 10.9717	valid_1's l2: 10.9634
[1140]	training's l2: 10.965	valid_1's l2: 10.9631
[1150]	training's l2: 10.9582	valid_1's l2: 10.9632
[1160]	training's l2: 10.9515	valid_1's l2: 10.9628
[1170]	training's l2: 10.9447	valid_1's l2: 10.9622
[1180]	training's l2: 10.9383	valid_1's l2: 10.9621
[1190]	training's l2: 10.9312	valid_1's l2: 10.9616
[1200]	training's l2: 10.9242	valid_1's l2: 10.9613
[1210]	training's l2: 10.9175	valid_1's l2: 10.9607
[1220]	training's l2: 10.9108	valid_1's l2: 10.9607
[1230]	training's l2: 10.9041	valid_1's l2: 10.9602
[1240]	training's l2: 10.8978	valid_1's l2: 10.9601
[1250]	training's l2: 10.8905	valid_1's l2: 10.9595
[1260]	training's l2: 10.8843	valid_1's l2: 10.9593
[1270]	training's l2: 10.877	valid_1's l2: 10.9587
[1280]	training's l2: 10.8704	valid_1's l2: 10.9585
[1290]	training's l2: 10.8642	valid_1's l2: 10.9584
[1300]	training's l2: 10.8572	valid_1's l2: 10.9579
[1310]	training's l2: 10.8505	valid_1's l2: 10.9575
[1320]	training's l2: 10.8443	valid_1's l2: 10.9574
[1330]	training's l2: 10.8374	valid_1's l2: 10.9568
[1340]	training's l2: 10.831	valid_1's l2: 10.9562
[1350]	training's l2: 10.8246	valid_1's l2: 10.9561
[1360]	training's l2: 10.8182	valid_1's l2: 10.9556
[1370]	training's l2: 10.8114	valid_1's l2: 10.9555
[1380]	training's l2: 10.8043	valid_1's l2: 10.9546
[1390]	training's l2: 10.7981	valid_1's l2: 10.9544
[1400]	training's l2: 10.7925	valid_1's l2: 10.9543
[1410]	training's l2: 10.7861	valid_1's l2: 10.9541
[1420]	training's l2: 10.7791	valid_1's l2: 10.9534
[1430]	training's l2: 10.7721	valid_1's l2: 10.953
[1440]	training's l2: 10.7661	valid_1's l2: 10.9526
[1450]	training's l2: 10.76	valid_1's l2: 10.9528
[1460]	training's l2: 10.7534	valid_1's l2: 10.9524
[1470]	training's l2: 10.7476	valid_1's l2: 10.952
[1480]	training's l2: 10.7413	valid_1's l2: 10.9517
[1490]	training's l2: 10.7342	valid_1's l2: 10.9511
[1500]	training's l2: 10.7283	valid_1's l2: 10.9506
[1510]	training's l2: 10.7224	valid_1's l2: 10.9501
[1520]	training's l2: 10.7162	valid_1's l2: 10.9494
[1530]	training's l2: 10.7099	valid_1's l2: 10.9494
[1540]	training's l2: 10.7027	valid_1's l2: 10.949
[1550]	training's l2: 10.6964	valid_1's l2: 10.9486
[1560]	training's l2: 10.6905	valid_1's l2: 10.9482
[1570]	training's l2: 10.6842	valid_1's l2: 10.9478
[1580]	training's l2: 10.6779	valid_1's l2: 10.9475
[1590]	training's l2: 10.6714	valid_1's l2: 10.9476
[1600]	training's l2: 10.6655	valid_1's l2: 10.9479
Early stopping, best iteration is:
[1575]	training's l2: 10.6808	valid_1's l2: 10.9474
score: 3.3423360839046508
