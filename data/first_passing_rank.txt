standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish Gilgamesh
jockey_judgment_data.pickle download finish Gilgamesh
jockey_judgment_rate_data.pickle download finish Gilgamesh
trainer_judgment_data.pickle download finish Gilgamesh
trainer_judgment_rate_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
start rank:5
start rank:1
start rank:4
start rank:3
start rank:2
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.318401 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 36194
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 199
[LightGBM] [Info] Start training from score 7.356756
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 25.5358	valid_1's l2: 24.7784
[20]	training's l2: 23.3633	valid_1's l2: 22.6192
[30]	training's l2: 21.836	valid_1's l2: 21.1156
[40]	training's l2: 20.7475	valid_1's l2: 20.0537
[50]	training's l2: 19.9615	valid_1's l2: 19.301
[60]	training's l2: 19.385	valid_1's l2: 18.7609
[70]	training's l2: 18.9513	valid_1's l2: 18.3653
[80]	training's l2: 18.6157	valid_1's l2: 18.0714
[90]	training's l2: 18.3459	valid_1's l2: 17.8482
[100]	training's l2: 18.1259	valid_1's l2: 17.6758
[110]	training's l2: 17.943	valid_1's l2: 17.5402
[120]	training's l2: 17.785	valid_1's l2: 17.4323
[130]	training's l2: 17.6507	valid_1's l2: 17.3465
[140]	training's l2: 17.5309	valid_1's l2: 17.2766
[150]	training's l2: 17.422	valid_1's l2: 17.216
[160]	training's l2: 17.3215	valid_1's l2: 17.1655
[170]	training's l2: 17.2289	valid_1's l2: 17.1228
[180]	training's l2: 17.1434	valid_1's l2: 17.087
[190]	training's l2: 17.0643	valid_1's l2: 17.0555
[200]	training's l2: 16.988	valid_1's l2: 17.0279
[210]	training's l2: 16.9169	valid_1's l2: 17.0052
[220]	training's l2: 16.8479	valid_1's l2: 16.9846
[230]	training's l2: 16.7817	valid_1's l2: 16.966
[240]	training's l2: 16.7174	valid_1's l2: 16.9495
[250]	training's l2: 16.6552	valid_1's l2: 16.9354
[260]	training's l2: 16.5936	valid_1's l2: 16.9207
[270]	training's l2: 16.5337	valid_1's l2: 16.9082
[280]	training's l2: 16.4748	valid_1's l2: 16.8948
[290]	training's l2: 16.4167	valid_1's l2: 16.8829
[300]	training's l2: 16.3597	valid_1's l2: 16.8718
[310]	training's l2: 16.3041	valid_1's l2: 16.8629
[320]	training's l2: 16.2494	valid_1's l2: 16.853
[330]	training's l2: 16.1939	valid_1's l2: 16.8428
[340]	training's l2: 16.1399	valid_1's l2: 16.8332
[350]	training's l2: 16.087	valid_1's l2: 16.8253
[360]	training's l2: 16.0349	valid_1's l2: 16.8176
[370]	training's l2: 15.9828	valid_1's l2: 16.8105
[380]	training's l2: 15.9316	valid_1's l2: 16.803
[390]	training's l2: 15.8818	valid_1's l2: 16.7964
[400]	training's l2: 15.8323	valid_1's l2: 16.7907
[410]	training's l2: 15.783	valid_1's l2: 16.7848
[420]	training's l2: 15.7335	valid_1's l2: 16.7791
[430]	training's l2: 15.6858	valid_1's l2: 16.7739
[440]	training's l2: 15.6371	valid_1's l2: 16.7689
[450]	training's l2: 15.5897	valid_1's l2: 16.7628
[460]	training's l2: 15.5439	valid_1's l2: 16.7586
[470]	training's l2: 15.4973	valid_1's l2: 16.7541
[480]	training's l2: 15.451	valid_1's l2: 16.7506
[490]	training's l2: 15.4051	valid_1's l2: 16.746
[500]	training's l2: 15.3589	valid_1's l2: 16.742
[510]	training's l2: 15.3136	valid_1's l2: 16.7387
[520]	training's l2: 15.2697	valid_1's l2: 16.7354
[530]	training's l2: 15.2256	valid_1's l2: 16.7321
[540]	training's l2: 15.1824	valid_1's l2: 16.729
[550]	training's l2: 15.1395	valid_1's l2: 16.7255
[560]	training's l2: 15.0963	valid_1's l2: 16.7227
[570]	training's l2: 15.0535	valid_1's l2: 16.7202
[580]	training's l2: 15.0112	valid_1's l2: 16.7178
[590]	training's l2: 14.9704	valid_1's l2: 16.7166
[600]	training's l2: 14.9288	valid_1's l2: 16.7159
[610]	training's l2: 14.8886	valid_1's l2: 16.7139
[620]	training's l2: 14.8478	valid_1's l2: 16.7108
[630]	training's l2: 14.808	valid_1's l2: 16.7095
[640]	training's l2: 14.768	valid_1's l2: 16.7081
[650]	training's l2: 14.7274	valid_1's l2: 16.7059
[660]	training's l2: 14.6873	valid_1's l2: 16.7037
[670]	training's l2: 14.6482	valid_1's l2: 16.702
[680]	training's l2: 14.6094	valid_1's l2: 16.7004
[690]	training's l2: 14.5708	valid_1's l2: 16.6992
[700]	training's l2: 14.5332	valid_1's l2: 16.6975
[710]	training's l2: 14.496	valid_1's l2: 16.6964
[720]	training's l2: 14.4594	valid_1's l2: 16.6958
[730]	training's l2: 14.4242	valid_1's l2: 16.6951
[740]	training's l2: 14.3891	valid_1's l2: 16.6939
[750]	training's l2: 14.3532	valid_1's l2: 16.6933
[760]	training's l2: 14.3163	valid_1's l2: 16.6919
[770]	training's l2: 14.2798	valid_1's l2: 16.6909
[780]	training's l2: 14.2447	valid_1's l2: 16.6892
[790]	training's l2: 14.2099	valid_1's l2: 16.6891
[800]	training's l2: 14.1745	valid_1's l2: 16.6877
[810]	training's l2: 14.1396	valid_1's l2: 16.6859
[820]	training's l2: 14.105	valid_1's l2: 16.6852
[830]	training's l2: 14.0723	valid_1's l2: 16.6836
[840]	training's l2: 14.0377	valid_1's l2: 16.6829
[850]	training's l2: 14.0031	valid_1's l2: 16.6815
[860]	training's l2: 13.9671	valid_1's l2: 16.6797
[870]	training's l2: 13.9322	valid_1's l2: 16.6787
[880]	training's l2: 13.899	valid_1's l2: 16.6794
[890]	training's l2: 13.8672	valid_1's l2: 16.6795
Early stopping, best iteration is:
[868]	training's l2: 13.9391	valid_1's l2: 16.6785
score1: 3.806990841796414
score2: 3.37617039734014
