wrap_data.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
start rank:2
start rank:1
start rank:3
start rank:5
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.524822 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 47856
[LightGBM] [Info] Number of data points in the train set: 632073, number of used features: 257
[LightGBM] [Info] Start training from score 7.467908
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 17.3563	valid_1's l2: 16.6407
[20]	training's l2: 15.8735	valid_1's l2: 15.1483
[30]	training's l2: 14.8436	valid_1's l2: 14.1064
[40]	training's l2: 14.1216	valid_1's l2: 13.3819
[50]	training's l2: 13.61	valid_1's l2: 12.8694
[60]	training's l2: 13.2392	valid_1's l2: 12.5002
[70]	training's l2: 12.9671	valid_1's l2: 12.2305
[80]	training's l2: 12.7608	valid_1's l2: 12.0264
[90]	training's l2: 12.6041	valid_1's l2: 11.8738
[100]	training's l2: 12.4814	valid_1's l2: 11.7544
[110]	training's l2: 12.3836	valid_1's l2: 11.66
[120]	training's l2: 12.3042	valid_1's l2: 11.5844
[130]	training's l2: 12.2401	valid_1's l2: 11.5242
[140]	training's l2: 12.1839	valid_1's l2: 11.4742
[150]	training's l2: 12.1361	valid_1's l2: 11.4322
[160]	training's l2: 12.0938	valid_1's l2: 11.3973
[170]	training's l2: 12.0558	valid_1's l2: 11.3662
[180]	training's l2: 12.0217	valid_1's l2: 11.3384
[190]	training's l2: 11.991	valid_1's l2: 11.3158
[200]	training's l2: 11.9623	valid_1's l2: 11.2935
[210]	training's l2: 11.9355	valid_1's l2: 11.2741
[220]	training's l2: 11.9104	valid_1's l2: 11.2567
[230]	training's l2: 11.8868	valid_1's l2: 11.2401
[240]	training's l2: 11.8653	valid_1's l2: 11.2258
[250]	training's l2: 11.8442	valid_1's l2: 11.2123
[260]	training's l2: 11.8241	valid_1's l2: 11.2001
[270]	training's l2: 11.805	valid_1's l2: 11.1884
[280]	training's l2: 11.7867	valid_1's l2: 11.178
[290]	training's l2: 11.7692	valid_1's l2: 11.1682
[300]	training's l2: 11.7522	valid_1's l2: 11.1584
[310]	training's l2: 11.7358	valid_1's l2: 11.1503
[320]	training's l2: 11.7196	valid_1's l2: 11.1422
[330]	training's l2: 11.7047	valid_1's l2: 11.1353
[340]	training's l2: 11.6892	valid_1's l2: 11.1273
[350]	training's l2: 11.6748	valid_1's l2: 11.1202
[360]	training's l2: 11.6606	valid_1's l2: 11.1139
[370]	training's l2: 11.6461	valid_1's l2: 11.1068
[380]	training's l2: 11.6325	valid_1's l2: 11.1006
[390]	training's l2: 11.6191	valid_1's l2: 11.0949
[400]	training's l2: 11.6056	valid_1's l2: 11.0891
[410]	training's l2: 11.5926	valid_1's l2: 11.0838
[420]	training's l2: 11.5801	valid_1's l2: 11.0791
[430]	training's l2: 11.5675	valid_1's l2: 11.0736
[440]	training's l2: 11.5552	valid_1's l2: 11.0688
[450]	training's l2: 11.5433	valid_1's l2: 11.0644
[460]	training's l2: 11.5318	valid_1's l2: 11.0609
[470]	training's l2: 11.5203	valid_1's l2: 11.0566
[480]	training's l2: 11.5091	valid_1's l2: 11.0531
[490]	training's l2: 11.4976	valid_1's l2: 11.0491
[500]	training's l2: 11.4865	valid_1's l2: 11.0457
[510]	training's l2: 11.4759	valid_1's l2: 11.0427
[520]	training's l2: 11.4652	valid_1's l2: 11.0391
[530]	training's l2: 11.454	valid_1's l2: 11.036
[540]	training's l2: 11.4437	valid_1's l2: 11.0329
[550]	training's l2: 11.4331	valid_1's l2: 11.0295
[560]	training's l2: 11.423	valid_1's l2: 11.0264
[570]	training's l2: 11.4128	valid_1's l2: 11.0237
[580]	training's l2: 11.403	valid_1's l2: 11.0213
[590]	training's l2: 11.3925	valid_1's l2: 11.018
[600]	training's l2: 11.383	valid_1's l2: 11.0162
[610]	training's l2: 11.3735	valid_1's l2: 11.0141
[620]	training's l2: 11.3642	valid_1's l2: 11.0121
[630]	training's l2: 11.3544	valid_1's l2: 11.0102
[640]	training's l2: 11.3454	valid_1's l2: 11.0082
[650]	training's l2: 11.3364	valid_1's l2: 11.0065
[660]	training's l2: 11.3273	valid_1's l2: 11.0047
[670]	training's l2: 11.3185	valid_1's l2: 11.0032
[680]	training's l2: 11.3094	valid_1's l2: 11.0015
[690]	training's l2: 11.3006	valid_1's l2: 11.0005
[700]	training's l2: 11.292	valid_1's l2: 10.999
[710]	training's l2: 11.284	valid_1's l2: 10.9982
[720]	training's l2: 11.2762	valid_1's l2: 10.9976
[730]	training's l2: 11.2684	valid_1's l2: 10.9967
[740]	training's l2: 11.2598	valid_1's l2: 10.9952
[750]	training's l2: 11.2516	valid_1's l2: 10.9939
[760]	training's l2: 11.2435	valid_1's l2: 10.9925
[770]	training's l2: 11.2355	valid_1's l2: 10.9918
[780]	training's l2: 11.2275	valid_1's l2: 10.9907
[790]	training's l2: 11.2198	valid_1's l2: 10.9903
[800]	training's l2: 11.2118	valid_1's l2: 10.9893
[810]	training's l2: 11.2044	valid_1's l2: 10.9883
[820]	training's l2: 11.1973	valid_1's l2: 10.9878
[830]	training's l2: 11.1897	valid_1's l2: 10.9873
[840]	training's l2: 11.1818	valid_1's l2: 10.9862
[850]	training's l2: 11.174	valid_1's l2: 10.9859
[860]	training's l2: 11.1657	valid_1's l2: 10.9845
[870]	training's l2: 11.1577	valid_1's l2: 10.9833
[880]	training's l2: 11.151	valid_1's l2: 10.9829
[890]	training's l2: 11.1432	valid_1's l2: 10.9824
[900]	training's l2: 11.1364	valid_1's l2: 10.9818
[910]	training's l2: 11.129	valid_1's l2: 10.9811
[920]	training's l2: 11.1213	valid_1's l2: 10.9799
[930]	training's l2: 11.114	valid_1's l2: 10.9796
[940]	training's l2: 11.1063	valid_1's l2: 10.9788
[950]	training's l2: 11.0988	valid_1's l2: 10.978
[960]	training's l2: 11.0911	valid_1's l2: 10.9771
[970]	training's l2: 11.0841	valid_1's l2: 10.9769
[980]	training's l2: 11.0768	valid_1's l2: 10.9763
[990]	training's l2: 11.0693	valid_1's l2: 10.9756
[1000]	training's l2: 11.0624	valid_1's l2: 10.975
[1010]	training's l2: 11.0551	valid_1's l2: 10.9741
[1020]	training's l2: 11.0474	valid_1's l2: 10.9733
[1030]	training's l2: 11.0404	valid_1's l2: 10.9727
[1040]	training's l2: 11.0334	valid_1's l2: 10.9721
[1050]	training's l2: 11.0261	valid_1's l2: 10.9715
[1060]	training's l2: 11.019	valid_1's l2: 10.971
[1070]	training's l2: 11.0119	valid_1's l2: 10.9705
[1080]	training's l2: 11.0047	valid_1's l2: 10.9696
[1090]	training's l2: 10.9974	valid_1's l2: 10.9692
[1100]	training's l2: 10.991	valid_1's l2: 10.9689
[1110]	training's l2: 10.9843	valid_1's l2: 10.9684
[1120]	training's l2: 10.9781	valid_1's l2: 10.9679
[1130]	training's l2: 10.9711	valid_1's l2: 10.9678
[1140]	training's l2: 10.964	valid_1's l2: 10.9674
[1150]	training's l2: 10.9575	valid_1's l2: 10.9669
[1160]	training's l2: 10.9512	valid_1's l2: 10.9665
[1170]	training's l2: 10.9438	valid_1's l2: 10.9654
[1180]	training's l2: 10.9371	valid_1's l2: 10.9653
[1190]	training's l2: 10.9307	valid_1's l2: 10.9651
[1200]	training's l2: 10.9236	valid_1's l2: 10.9648
[1210]	training's l2: 10.9163	valid_1's l2: 10.9645
[1220]	training's l2: 10.9088	valid_1's l2: 10.9636
[1230]	training's l2: 10.9021	valid_1's l2: 10.9631
[1240]	training's l2: 10.8959	valid_1's l2: 10.9631
[1250]	training's l2: 10.89	valid_1's l2: 10.9629
[1260]	training's l2: 10.8835	valid_1's l2: 10.9626
[1270]	training's l2: 10.8764	valid_1's l2: 10.9622
[1280]	training's l2: 10.8694	valid_1's l2: 10.9617
[1290]	training's l2: 10.8624	valid_1's l2: 10.9611
[1300]	training's l2: 10.856	valid_1's l2: 10.961
[1310]	training's l2: 10.8501	valid_1's l2: 10.9607
[1320]	training's l2: 10.8428	valid_1's l2: 10.9604
[1330]	training's l2: 10.8366	valid_1's l2: 10.9599
[1340]	training's l2: 10.83	valid_1's l2: 10.9593
[1350]	training's l2: 10.8237	valid_1's l2: 10.9589
[1360]	training's l2: 10.8173	valid_1's l2: 10.9586
[1370]	training's l2: 10.8118	valid_1's l2: 10.9588
[1380]	training's l2: 10.8047	valid_1's l2: 10.9584
[1390]	training's l2: 10.7981	valid_1's l2: 10.958
[1400]	training's l2: 10.7917	valid_1's l2: 10.9574
[1410]	training's l2: 10.7853	valid_1's l2: 10.957
[1420]	training's l2: 10.7788	valid_1's l2: 10.9565
[1430]	training's l2: 10.7729	valid_1's l2: 10.9564
[1440]	training's l2: 10.7667	valid_1's l2: 10.9564
[1450]	training's l2: 10.76	valid_1's l2: 10.9561
[1460]	training's l2: 10.7529	valid_1's l2: 10.9559
[1470]	training's l2: 10.7469	valid_1's l2: 10.9555
[1480]	training's l2: 10.7405	valid_1's l2: 10.9552
[1490]	training's l2: 10.7344	valid_1's l2: 10.9551
[1500]	training's l2: 10.728	valid_1's l2: 10.9547
[1510]	training's l2: 10.7212	valid_1's l2: 10.9543
[1520]	training's l2: 10.7159	valid_1's l2: 10.9541
[1530]	training's l2: 10.7092	valid_1's l2: 10.9539
[1540]	training's l2: 10.7028	valid_1's l2: 10.9534
[1550]	training's l2: 10.6967	valid_1's l2: 10.9531
[1560]	training's l2: 10.6898	valid_1's l2: 10.953
[1570]	training's l2: 10.6837	valid_1's l2: 10.9528
[1580]	training's l2: 10.6773	valid_1's l2: 10.9525
[1590]	training's l2: 10.6711	valid_1's l2: 10.9521
[1600]	training's l2: 10.6648	valid_1's l2: 10.9519
[1610]	training's l2: 10.6583	valid_1's l2: 10.9515
[1620]	training's l2: 10.6522	valid_1's l2: 10.9514
[1630]	training's l2: 10.6462	valid_1's l2: 10.9511
[1640]	training's l2: 10.6402	valid_1's l2: 10.9511
[1650]	training's l2: 10.6342	valid_1's l2: 10.9508
[1660]	training's l2: 10.628	valid_1's l2: 10.9504
[1670]	training's l2: 10.6214	valid_1's l2: 10.9501
[1680]	training's l2: 10.6149	valid_1's l2: 10.9502
[1690]	training's l2: 10.6089	valid_1's l2: 10.9499
[1700]	training's l2: 10.6029	valid_1's l2: 10.9496
[1710]	training's l2: 10.596	valid_1's l2: 10.9496
[1720]	training's l2: 10.5899	valid_1's l2: 10.9492
[1730]	training's l2: 10.5838	valid_1's l2: 10.9492
[1740]	training's l2: 10.5772	valid_1's l2: 10.9489
[1750]	training's l2: 10.5715	valid_1's l2: 10.9486
[1760]	training's l2: 10.5657	valid_1's l2: 10.9483
[1770]	training's l2: 10.5596	valid_1's l2: 10.9482
[1780]	training's l2: 10.5536	valid_1's l2: 10.9478
[1790]	training's l2: 10.5472	valid_1's l2: 10.9472
[1800]	training's l2: 10.5415	valid_1's l2: 10.9468
[1810]	training's l2: 10.5352	valid_1's l2: 10.9463
[1820]	training's l2: 10.5296	valid_1's l2: 10.9463
[1830]	training's l2: 10.523	valid_1's l2: 10.9462
[1840]	training's l2: 10.5166	valid_1's l2: 10.9459
[1850]	training's l2: 10.5102	valid_1's l2: 10.9455
[1860]	training's l2: 10.5044	valid_1's l2: 10.9451
[1870]	training's l2: 10.4985	valid_1's l2: 10.9451
[1880]	training's l2: 10.4925	valid_1's l2: 10.9451
[1890]	training's l2: 10.4873	valid_1's l2: 10.9451
Early stopping, best iteration is:
[1863]	training's l2: 10.5024	valid_1's l2: 10.9449
score: 3.3408324605205912
