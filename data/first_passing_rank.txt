standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
race_time_analyze_data.pickle download finish Gilgamesh
up3_analyze_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
stride_ablity_analyze_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_data.pickle download finish Gilgamesh
jockey_judgment_rate_data.pickle download finish Gilgamesh
trainer_judgment_data.pickle download finish Gilgamesh
trainer_judgment_rate_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
predict_rough_race_data.pickle download finish Gilgamesh
condition_devi_data.pickle download finish Gilgamesh
predict_netkeiba_pace_data.pickle download finish Gilgamesh
predict_netkeiba_deployment_data.pickle download finish Gilgamesh
start rank:2
start rank:3
start rank:4
start rank:1
start rank:5
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.466025 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 47113
[LightGBM] [Info] Number of data points in the train set: 641880, number of used features: 254
[LightGBM] [Info] Start training from score 7.446663
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 17.7709	valid_1's l2: 17.2514
[20]	training's l2: 16.4725	valid_1's l2: 15.9683
[30]	training's l2: 15.474	valid_1's l2: 14.985
[40]	training's l2: 14.7038	valid_1's l2: 14.2331
[50]	training's l2: 14.1064	valid_1's l2: 13.6565
[60]	training's l2: 13.6401	valid_1's l2: 13.2086
[70]	training's l2: 13.27	valid_1's l2: 12.8582
[80]	training's l2: 12.9713	valid_1's l2: 12.582
[90]	training's l2: 12.729	valid_1's l2: 12.3637
[100]	training's l2: 12.5322	valid_1's l2: 12.1924
[110]	training's l2: 12.3683	valid_1's l2: 12.0541
[120]	training's l2: 12.2307	valid_1's l2: 11.9427
[130]	training's l2: 12.1135	valid_1's l2: 11.8512
[140]	training's l2: 12.0108	valid_1's l2: 11.7741
[150]	training's l2: 11.921	valid_1's l2: 11.7089
[160]	training's l2: 11.8397	valid_1's l2: 11.6515
[170]	training's l2: 11.768	valid_1's l2: 11.6054
[180]	training's l2: 11.7042	valid_1's l2: 11.5647
[190]	training's l2: 11.6432	valid_1's l2: 11.5271
[200]	training's l2: 11.5865	valid_1's l2: 11.4953
[210]	training's l2: 11.534	valid_1's l2: 11.4662
[220]	training's l2: 11.4843	valid_1's l2: 11.4404
[230]	training's l2: 11.4391	valid_1's l2: 11.4185
[240]	training's l2: 11.3944	valid_1's l2: 11.3984
[250]	training's l2: 11.3517	valid_1's l2: 11.38
[260]	training's l2: 11.3098	valid_1's l2: 11.363
[270]	training's l2: 11.2691	valid_1's l2: 11.3477
[280]	training's l2: 11.2309	valid_1's l2: 11.3336
[290]	training's l2: 11.1933	valid_1's l2: 11.3202
[300]	training's l2: 11.1572	valid_1's l2: 11.3072
[310]	training's l2: 11.122	valid_1's l2: 11.2957
[320]	training's l2: 11.088	valid_1's l2: 11.2854
[330]	training's l2: 11.055	valid_1's l2: 11.2764
[340]	training's l2: 11.0224	valid_1's l2: 11.267
[350]	training's l2: 10.9894	valid_1's l2: 11.2577
[360]	training's l2: 10.9576	valid_1's l2: 11.2496
[370]	training's l2: 10.9262	valid_1's l2: 11.2417
[380]	training's l2: 10.8953	valid_1's l2: 11.2326
[390]	training's l2: 10.8647	valid_1's l2: 11.2243
[400]	training's l2: 10.835	valid_1's l2: 11.2174
[410]	training's l2: 10.8051	valid_1's l2: 11.2096
[420]	training's l2: 10.7765	valid_1's l2: 11.2042
[430]	training's l2: 10.748	valid_1's l2: 11.1984
[440]	training's l2: 10.7197	valid_1's l2: 11.1924
[450]	training's l2: 10.6921	valid_1's l2: 11.188
[460]	training's l2: 10.6643	valid_1's l2: 11.1821
[470]	training's l2: 10.6373	valid_1's l2: 11.1779
[480]	training's l2: 10.61	valid_1's l2: 11.1728
[490]	training's l2: 10.5835	valid_1's l2: 11.1671
[500]	training's l2: 10.557	valid_1's l2: 11.162
[510]	training's l2: 10.5308	valid_1's l2: 11.1578
[520]	training's l2: 10.5045	valid_1's l2: 11.1536
[530]	training's l2: 10.4788	valid_1's l2: 11.1501
[540]	training's l2: 10.453	valid_1's l2: 11.1466
[550]	training's l2: 10.4277	valid_1's l2: 11.1425
[560]	training's l2: 10.4028	valid_1's l2: 11.139
[570]	training's l2: 10.3777	valid_1's l2: 11.1352
[580]	training's l2: 10.3528	valid_1's l2: 11.1319
[590]	training's l2: 10.3282	valid_1's l2: 11.1296
[600]	training's l2: 10.3037	valid_1's l2: 11.1264
[610]	training's l2: 10.2795	valid_1's l2: 11.1239
[620]	training's l2: 10.2553	valid_1's l2: 11.1213
[630]	training's l2: 10.2314	valid_1's l2: 11.1189
[640]	training's l2: 10.2078	valid_1's l2: 11.1161
[650]	training's l2: 10.1841	valid_1's l2: 11.1138
[660]	training's l2: 10.1609	valid_1's l2: 11.1121
[670]	training's l2: 10.1375	valid_1's l2: 11.11
[680]	training's l2: 10.1147	valid_1's l2: 11.1089
[690]	training's l2: 10.0919	valid_1's l2: 11.107
[700]	training's l2: 10.0694	valid_1's l2: 11.1051
[710]	training's l2: 10.0467	valid_1's l2: 11.1031
[720]	training's l2: 10.0242	valid_1's l2: 11.1011
[730]	training's l2: 10.0017	valid_1's l2: 11.0997
[740]	training's l2: 9.97942	valid_1's l2: 11.0976
[750]	training's l2: 9.95743	valid_1's l2: 11.0956
[760]	training's l2: 9.93592	valid_1's l2: 11.0944
[770]	training's l2: 9.91408	valid_1's l2: 11.0923
[780]	training's l2: 9.89281	valid_1's l2: 11.0914
[790]	training's l2: 9.87144	valid_1's l2: 11.0894
[800]	training's l2: 9.84983	valid_1's l2: 11.0873
[810]	training's l2: 9.8286	valid_1's l2: 11.087
[820]	training's l2: 9.80786	valid_1's l2: 11.0858
[830]	training's l2: 9.78711	valid_1's l2: 11.0846
[840]	training's l2: 9.7669	valid_1's l2: 11.0839
[850]	training's l2: 9.74657	valid_1's l2: 11.0827
[860]	training's l2: 9.72611	valid_1's l2: 11.0816
[870]	training's l2: 9.70597	valid_1's l2: 11.0798
[880]	training's l2: 9.68659	valid_1's l2: 11.0789
[890]	training's l2: 9.66652	valid_1's l2: 11.0782
[900]	training's l2: 9.64698	valid_1's l2: 11.0771
[910]	training's l2: 9.62745	valid_1's l2: 11.0765
[920]	training's l2: 9.60763	valid_1's l2: 11.0754
[930]	training's l2: 9.58801	valid_1's l2: 11.0742
[940]	training's l2: 9.56964	valid_1's l2: 11.0733
[950]	training's l2: 9.55113	valid_1's l2: 11.0731
[960]	training's l2: 9.53139	valid_1's l2: 11.0722
[970]	training's l2: 9.51363	valid_1's l2: 11.0719
[980]	training's l2: 9.49439	valid_1's l2: 11.0707
[990]	training's l2: 9.47651	valid_1's l2: 11.0698
[1000]	training's l2: 9.45826	valid_1's l2: 11.069
[1010]	training's l2: 9.44068	valid_1's l2: 11.0686
[1020]	training's l2: 9.42278	valid_1's l2: 11.0676
[1030]	training's l2: 9.40442	valid_1's l2: 11.0667
[1040]	training's l2: 9.38687	valid_1's l2: 11.0655
[1050]	training's l2: 9.36872	valid_1's l2: 11.0652
[1060]	training's l2: 9.35101	valid_1's l2: 11.0651
[1070]	training's l2: 9.33376	valid_1's l2: 11.0647
[1080]	training's l2: 9.31665	valid_1's l2: 11.0649
[1090]	training's l2: 9.29894	valid_1's l2: 11.0643
[1100]	training's l2: 9.28086	valid_1's l2: 11.0633
[1110]	training's l2: 9.26391	valid_1's l2: 11.0635
[1120]	training's l2: 9.24639	valid_1's l2: 11.0625
[1130]	training's l2: 9.22974	valid_1's l2: 11.0625
[1140]	training's l2: 9.21307	valid_1's l2: 11.0616
[1150]	training's l2: 9.1959	valid_1's l2: 11.0609
[1160]	training's l2: 9.17945	valid_1's l2: 11.0599
[1170]	training's l2: 9.16283	valid_1's l2: 11.0593
[1180]	training's l2: 9.14549	valid_1's l2: 11.0584
[1190]	training's l2: 9.12825	valid_1's l2: 11.0584
[1200]	training's l2: 9.11095	valid_1's l2: 11.0582
[1210]	training's l2: 9.09514	valid_1's l2: 11.0583
[1220]	training's l2: 9.07845	valid_1's l2: 11.058
[1230]	training's l2: 9.06204	valid_1's l2: 11.058
[1240]	training's l2: 9.04556	valid_1's l2: 11.0578
[1250]	training's l2: 9.02888	valid_1's l2: 11.0566
[1260]	training's l2: 9.01234	valid_1's l2: 11.0564
[1270]	training's l2: 8.99613	valid_1's l2: 11.0559
[1280]	training's l2: 8.9801	valid_1's l2: 11.0553
[1290]	training's l2: 8.9639	valid_1's l2: 11.0549
[1300]	training's l2: 8.94793	valid_1's l2: 11.0545
[1310]	training's l2: 8.93237	valid_1's l2: 11.0542
[1320]	training's l2: 8.91735	valid_1's l2: 11.0542
[1330]	training's l2: 8.90264	valid_1's l2: 11.0541
[1340]	training's l2: 8.88672	valid_1's l2: 11.0536
[1350]	training's l2: 8.87109	valid_1's l2: 11.053
[1360]	training's l2: 8.85534	valid_1's l2: 11.0525
[1370]	training's l2: 8.83939	valid_1's l2: 11.0524
[1380]	training's l2: 8.82394	valid_1's l2: 11.0515
[1390]	training's l2: 8.80849	valid_1's l2: 11.0516
[1400]	training's l2: 8.79398	valid_1's l2: 11.051
[1410]	training's l2: 8.77826	valid_1's l2: 11.0501
[1420]	training's l2: 8.7639	valid_1's l2: 11.0501
[1430]	training's l2: 8.74818	valid_1's l2: 11.0499
[1440]	training's l2: 8.73283	valid_1's l2: 11.0489
[1450]	training's l2: 8.71745	valid_1's l2: 11.0482
[1460]	training's l2: 8.70223	valid_1's l2: 11.0482
[1470]	training's l2: 8.68732	valid_1's l2: 11.0479
[1480]	training's l2: 8.67237	valid_1's l2: 11.0475
[1490]	training's l2: 8.6565	valid_1's l2: 11.0476
[1500]	training's l2: 8.64207	valid_1's l2: 11.0472
[1510]	training's l2: 8.62791	valid_1's l2: 11.0475
[1520]	training's l2: 8.61331	valid_1's l2: 11.0475
[1530]	training's l2: 8.59853	valid_1's l2: 11.0471
[1540]	training's l2: 8.5839	valid_1's l2: 11.0474
[1550]	training's l2: 8.5689	valid_1's l2: 11.047
Early stopping, best iteration is:
[1525]	training's l2: 8.60571	valid_1's l2: 11.0469
score: 2.9214774449361527
