standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish Gilgamesh
jockey_judgment_data.pickle download finish Gilgamesh
jockey_judgment_rate_data.pickle download finish Gilgamesh
trainer_judgment_data.pickle download finish Gilgamesh
trainer_judgment_rate_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
start rank:5
start rank:1
start rank:4
start rank:3
start rank:2
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.298833 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 36190
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 199
[LightGBM] [Info] Start training from score 7.356756
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 25.5367	valid_1's l2: 24.8022
[20]	training's l2: 23.366	valid_1's l2: 22.6527
[30]	training's l2: 21.8389	valid_1's l2: 21.1545
[40]	training's l2: 20.7505	valid_1's l2: 20.0928
[50]	training's l2: 19.9631	valid_1's l2: 19.3399
[60]	training's l2: 19.3855	valid_1's l2: 18.7998
[70]	training's l2: 18.9511	valid_1's l2: 18.4033
[80]	training's l2: 18.6161	valid_1's l2: 18.1084
[90]	training's l2: 18.3469	valid_1's l2: 17.8874
[100]	training's l2: 18.126	valid_1's l2: 17.7137
[110]	training's l2: 17.943	valid_1's l2: 17.5763
[120]	training's l2: 17.7856	valid_1's l2: 17.4654
[130]	training's l2: 17.65	valid_1's l2: 17.376
[140]	training's l2: 17.5294	valid_1's l2: 17.3036
[150]	training's l2: 17.4213	valid_1's l2: 17.2447
[160]	training's l2: 17.321	valid_1's l2: 17.1931
[170]	training's l2: 17.2296	valid_1's l2: 17.151
[180]	training's l2: 17.1445	valid_1's l2: 17.1145
[190]	training's l2: 17.0651	valid_1's l2: 17.0829
[200]	training's l2: 16.9906	valid_1's l2: 17.0563
[210]	training's l2: 16.9179	valid_1's l2: 17.0313
[220]	training's l2: 16.8486	valid_1's l2: 17.0086
[230]	training's l2: 16.7813	valid_1's l2: 16.9901
[240]	training's l2: 16.7164	valid_1's l2: 16.9751
[250]	training's l2: 16.6541	valid_1's l2: 16.9593
[260]	training's l2: 16.5926	valid_1's l2: 16.9455
[270]	training's l2: 16.5333	valid_1's l2: 16.9329
[280]	training's l2: 16.4748	valid_1's l2: 16.9199
[290]	training's l2: 16.417	valid_1's l2: 16.9092
[300]	training's l2: 16.3597	valid_1's l2: 16.899
[310]	training's l2: 16.3039	valid_1's l2: 16.8898
[320]	training's l2: 16.2493	valid_1's l2: 16.8805
[330]	training's l2: 16.1949	valid_1's l2: 16.871
[340]	training's l2: 16.1401	valid_1's l2: 16.8621
[350]	training's l2: 16.0868	valid_1's l2: 16.8549
[360]	training's l2: 16.0343	valid_1's l2: 16.8473
[370]	training's l2: 15.9824	valid_1's l2: 16.8396
[380]	training's l2: 15.931	valid_1's l2: 16.8328
[390]	training's l2: 15.8812	valid_1's l2: 16.8283
[400]	training's l2: 15.8304	valid_1's l2: 16.8228
[410]	training's l2: 15.7812	valid_1's l2: 16.818
[420]	training's l2: 15.7337	valid_1's l2: 16.8137
[430]	training's l2: 15.6851	valid_1's l2: 16.8087
[440]	training's l2: 15.6377	valid_1's l2: 16.8038
[450]	training's l2: 15.5903	valid_1's l2: 16.8005
[460]	training's l2: 15.544	valid_1's l2: 16.7959
[470]	training's l2: 15.498	valid_1's l2: 16.7917
[480]	training's l2: 15.4512	valid_1's l2: 16.7884
[490]	training's l2: 15.4049	valid_1's l2: 16.7831
[500]	training's l2: 15.3589	valid_1's l2: 16.779
[510]	training's l2: 15.3151	valid_1's l2: 16.776
[520]	training's l2: 15.2695	valid_1's l2: 16.7735
[530]	training's l2: 15.225	valid_1's l2: 16.7706
[540]	training's l2: 15.1812	valid_1's l2: 16.7686
[550]	training's l2: 15.1385	valid_1's l2: 16.7661
[560]	training's l2: 15.0952	valid_1's l2: 16.764
[570]	training's l2: 15.053	valid_1's l2: 16.7624
[580]	training's l2: 15.011	valid_1's l2: 16.7613
[590]	training's l2: 14.9688	valid_1's l2: 16.7593
[600]	training's l2: 14.928	valid_1's l2: 16.759
[610]	training's l2: 14.8865	valid_1's l2: 16.7577
[620]	training's l2: 14.8464	valid_1's l2: 16.7563
[630]	training's l2: 14.8062	valid_1's l2: 16.7562
[640]	training's l2: 14.7669	valid_1's l2: 16.7544
[650]	training's l2: 14.728	valid_1's l2: 16.7532
[660]	training's l2: 14.6873	valid_1's l2: 16.7496
[670]	training's l2: 14.6483	valid_1's l2: 16.7472
[680]	training's l2: 14.6089	valid_1's l2: 16.7449
[690]	training's l2: 14.5705	valid_1's l2: 16.7435
[700]	training's l2: 14.5329	valid_1's l2: 16.7423
[710]	training's l2: 14.496	valid_1's l2: 16.7414
[720]	training's l2: 14.4578	valid_1's l2: 16.7397
[730]	training's l2: 14.4213	valid_1's l2: 16.7387
[740]	training's l2: 14.3858	valid_1's l2: 16.7379
[750]	training's l2: 14.3492	valid_1's l2: 16.7361
[760]	training's l2: 14.3129	valid_1's l2: 16.7348
[770]	training's l2: 14.2785	valid_1's l2: 16.7339
[780]	training's l2: 14.2438	valid_1's l2: 16.735
[790]	training's l2: 14.2087	valid_1's l2: 16.7349
[800]	training's l2: 14.175	valid_1's l2: 16.7337
[810]	training's l2: 14.1396	valid_1's l2: 16.7331
[820]	training's l2: 14.1043	valid_1's l2: 16.7324
[830]	training's l2: 14.0716	valid_1's l2: 16.7308
[840]	training's l2: 14.0363	valid_1's l2: 16.7293
[850]	training's l2: 14.0027	valid_1's l2: 16.7278
[860]	training's l2: 13.9679	valid_1's l2: 16.7267
[870]	training's l2: 13.9365	valid_1's l2: 16.7257
[880]	training's l2: 13.9062	valid_1's l2: 16.7238
[890]	training's l2: 13.8733	valid_1's l2: 16.7235
[900]	training's l2: 13.841	valid_1's l2: 16.7227
[910]	training's l2: 13.8079	valid_1's l2: 16.7219
[920]	training's l2: 13.7758	valid_1's l2: 16.722
[930]	training's l2: 13.7434	valid_1's l2: 16.7218
[940]	training's l2: 13.7112	valid_1's l2: 16.7205
[950]	training's l2: 13.6786	valid_1's l2: 16.7198
[960]	training's l2: 13.6472	valid_1's l2: 16.7183
[970]	training's l2: 13.6144	valid_1's l2: 16.7177
[980]	training's l2: 13.5841	valid_1's l2: 16.7169
[990]	training's l2: 13.552	valid_1's l2: 16.7161
[1000]	training's l2: 13.5207	valid_1's l2: 16.7161
[1010]	training's l2: 13.4893	valid_1's l2: 16.7149
[1020]	training's l2: 13.4572	valid_1's l2: 16.7149
[1030]	training's l2: 13.4282	valid_1's l2: 16.7146
[1040]	training's l2: 13.3976	valid_1's l2: 16.7142
[1050]	training's l2: 13.3687	valid_1's l2: 16.7143
[1060]	training's l2: 13.3382	valid_1's l2: 16.7133
[1070]	training's l2: 13.3062	valid_1's l2: 16.7133
[1080]	training's l2: 13.2779	valid_1's l2: 16.7135
[1090]	training's l2: 13.2489	valid_1's l2: 16.7128
[1100]	training's l2: 13.2195	valid_1's l2: 16.7127
[1110]	training's l2: 13.1902	valid_1's l2: 16.7124
[1120]	training's l2: 13.16	valid_1's l2: 16.7116
[1130]	training's l2: 13.1303	valid_1's l2: 16.711
[1140]	training's l2: 13.1021	valid_1's l2: 16.7098
[1150]	training's l2: 13.0729	valid_1's l2: 16.709
[1160]	training's l2: 13.0433	valid_1's l2: 16.7088
[1170]	training's l2: 13.0137	valid_1's l2: 16.7081
[1180]	training's l2: 12.9849	valid_1's l2: 16.7087
[1190]	training's l2: 12.9548	valid_1's l2: 16.7081
Early stopping, best iteration is:
[1169]	training's l2: 13.0166	valid_1's l2: 16.7079
score1: 3.8068462121151487
score2: 3.380967653442383
