standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:1
start rank:3
start rank:4
start rank:5
start rank:2
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.345780 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 39780
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 213
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151615	valid_1's l2: 0.00158071
[20]	training's l2: 0.00144824	valid_1's l2: 0.00151803
[30]	training's l2: 0.00139155	valid_1's l2: 0.00146601
[40]	training's l2: 0.00134388	valid_1's l2: 0.00142267
[50]	training's l2: 0.00130346	valid_1's l2: 0.00138647
[60]	training's l2: 0.00126927	valid_1's l2: 0.00135615
[70]	training's l2: 0.00124007	valid_1's l2: 0.00133021
[80]	training's l2: 0.00121499	valid_1's l2: 0.00130793
[90]	training's l2: 0.00119349	valid_1's l2: 0.00128911
[100]	training's l2: 0.00117487	valid_1's l2: 0.00127309
[110]	training's l2: 0.00115873	valid_1's l2: 0.00125946
[120]	training's l2: 0.00114434	valid_1's l2: 0.00124765
[130]	training's l2: 0.00113158	valid_1's l2: 0.00123738
[140]	training's l2: 0.00112031	valid_1's l2: 0.0012285
[150]	training's l2: 0.00111011	valid_1's l2: 0.00122048
[160]	training's l2: 0.00110123	valid_1's l2: 0.00121373
[170]	training's l2: 0.00109306	valid_1's l2: 0.0012074
[180]	training's l2: 0.00108569	valid_1's l2: 0.00120177
[190]	training's l2: 0.00107864	valid_1's l2: 0.00119681
[200]	training's l2: 0.00107236	valid_1's l2: 0.00119246
[210]	training's l2: 0.00106666	valid_1's l2: 0.00118843
[220]	training's l2: 0.00106128	valid_1's l2: 0.0011847
[230]	training's l2: 0.00105622	valid_1's l2: 0.00118121
[240]	training's l2: 0.0010514	valid_1's l2: 0.00117801
[250]	training's l2: 0.00104683	valid_1's l2: 0.00117498
[260]	training's l2: 0.00104259	valid_1's l2: 0.00117218
[270]	training's l2: 0.00103851	valid_1's l2: 0.0011695
[280]	training's l2: 0.00103457	valid_1's l2: 0.00116706
[290]	training's l2: 0.00103071	valid_1's l2: 0.00116461
[300]	training's l2: 0.00102686	valid_1's l2: 0.0011622
[310]	training's l2: 0.00102322	valid_1's l2: 0.0011601
[320]	training's l2: 0.00101981	valid_1's l2: 0.00115822
[330]	training's l2: 0.00101675	valid_1's l2: 0.00115655
[340]	training's l2: 0.00101382	valid_1's l2: 0.00115495
[350]	training's l2: 0.00101081	valid_1's l2: 0.00115332
[360]	training's l2: 0.0010077	valid_1's l2: 0.00115165
[370]	training's l2: 0.00100461	valid_1's l2: 0.00115004
[380]	training's l2: 0.00100143	valid_1's l2: 0.00114835
[390]	training's l2: 0.000998505	valid_1's l2: 0.00114694
[400]	training's l2: 0.000995815	valid_1's l2: 0.0011457
[410]	training's l2: 0.000993088	valid_1's l2: 0.00114449
[420]	training's l2: 0.000990426	valid_1's l2: 0.00114323
[430]	training's l2: 0.00098787	valid_1's l2: 0.00114211
[440]	training's l2: 0.000985414	valid_1's l2: 0.00114115
[450]	training's l2: 0.000982955	valid_1's l2: 0.00114008
[460]	training's l2: 0.000980481	valid_1's l2: 0.00113906
[470]	training's l2: 0.000978142	valid_1's l2: 0.00113814
[480]	training's l2: 0.000975529	valid_1's l2: 0.00113708
[490]	training's l2: 0.000973159	valid_1's l2: 0.00113622
[500]	training's l2: 0.000970645	valid_1's l2: 0.00113529
[510]	training's l2: 0.000968264	valid_1's l2: 0.00113441
[520]	training's l2: 0.000966034	valid_1's l2: 0.00113374
[530]	training's l2: 0.000963757	valid_1's l2: 0.00113308
[540]	training's l2: 0.000961534	valid_1's l2: 0.00113243
[550]	training's l2: 0.000959362	valid_1's l2: 0.00113181
[560]	training's l2: 0.000957103	valid_1's l2: 0.00113113
[570]	training's l2: 0.000955217	valid_1's l2: 0.0011306
[580]	training's l2: 0.000953151	valid_1's l2: 0.00113
[590]	training's l2: 0.000951292	valid_1's l2: 0.00112959
[600]	training's l2: 0.000949292	valid_1's l2: 0.00112917
[610]	training's l2: 0.000947163	valid_1's l2: 0.00112868
[620]	training's l2: 0.000945318	valid_1's l2: 0.00112829
[630]	training's l2: 0.000943326	valid_1's l2: 0.00112783
[640]	training's l2: 0.000941368	valid_1's l2: 0.00112733
[650]	training's l2: 0.000939395	valid_1's l2: 0.00112681
[660]	training's l2: 0.000937438	valid_1's l2: 0.00112633
[670]	training's l2: 0.000935661	valid_1's l2: 0.00112591
[680]	training's l2: 0.000933795	valid_1's l2: 0.00112535
[690]	training's l2: 0.000931894	valid_1's l2: 0.00112493
[700]	training's l2: 0.000930204	valid_1's l2: 0.00112462
[710]	training's l2: 0.000928401	valid_1's l2: 0.00112436
[720]	training's l2: 0.000926745	valid_1's l2: 0.00112399
[730]	training's l2: 0.000924863	valid_1's l2: 0.00112354
[740]	training's l2: 0.000923134	valid_1's l2: 0.00112317
[750]	training's l2: 0.000921478	valid_1's l2: 0.00112286
[760]	training's l2: 0.000919618	valid_1's l2: 0.00112257
[770]	training's l2: 0.000917995	valid_1's l2: 0.00112228
[780]	training's l2: 0.000916191	valid_1's l2: 0.001122
[790]	training's l2: 0.000914492	valid_1's l2: 0.00112165
[800]	training's l2: 0.000912849	valid_1's l2: 0.00112145
[810]	training's l2: 0.000911206	valid_1's l2: 0.00112129
[820]	training's l2: 0.000909489	valid_1's l2: 0.00112101
[830]	training's l2: 0.000907829	valid_1's l2: 0.00112075
[840]	training's l2: 0.000906196	valid_1's l2: 0.00112045
[850]	training's l2: 0.000904671	valid_1's l2: 0.00112025
[860]	training's l2: 0.000903118	valid_1's l2: 0.00112011
[870]	training's l2: 0.000901447	valid_1's l2: 0.00111989
[880]	training's l2: 0.000899909	valid_1's l2: 0.00111975
[890]	training's l2: 0.000898277	valid_1's l2: 0.00111953
[900]	training's l2: 0.000896811	valid_1's l2: 0.00111934
[910]	training's l2: 0.000895284	valid_1's l2: 0.00111919
[920]	training's l2: 0.00089373	valid_1's l2: 0.00111903
[930]	training's l2: 0.000892287	valid_1's l2: 0.00111892
[940]	training's l2: 0.000890881	valid_1's l2: 0.00111877
[950]	training's l2: 0.000889515	valid_1's l2: 0.00111862
[960]	training's l2: 0.000888133	valid_1's l2: 0.00111853
[970]	training's l2: 0.000886644	valid_1's l2: 0.00111848
[980]	training's l2: 0.000885162	valid_1's l2: 0.0011183
[990]	training's l2: 0.000883776	valid_1's l2: 0.0011181
[1000]	training's l2: 0.000882263	valid_1's l2: 0.00111791
[1010]	training's l2: 0.000880851	valid_1's l2: 0.00111777
[1020]	training's l2: 0.000879308	valid_1's l2: 0.0011175
[1030]	training's l2: 0.000877898	valid_1's l2: 0.00111738
[1040]	training's l2: 0.000876476	valid_1's l2: 0.00111723
[1050]	training's l2: 0.000875056	valid_1's l2: 0.00111719
[1060]	training's l2: 0.00087371	valid_1's l2: 0.00111698
[1070]	training's l2: 0.000872288	valid_1's l2: 0.00111692
[1080]	training's l2: 0.000870927	valid_1's l2: 0.00111674
[1090]	training's l2: 0.000869565	valid_1's l2: 0.00111668
[1100]	training's l2: 0.000868197	valid_1's l2: 0.0011166
[1110]	training's l2: 0.000866817	valid_1's l2: 0.0011165
[1120]	training's l2: 0.000865412	valid_1's l2: 0.00111647
[1130]	training's l2: 0.000863971	valid_1's l2: 0.00111628
[1140]	training's l2: 0.00086269	valid_1's l2: 0.00111622
[1150]	training's l2: 0.000861328	valid_1's l2: 0.00111612
[1160]	training's l2: 0.00085984	valid_1's l2: 0.00111603
[1170]	training's l2: 0.000858533	valid_1's l2: 0.00111595
[1180]	training's l2: 0.000857252	valid_1's l2: 0.00111591
[1190]	training's l2: 0.000855974	valid_1's l2: 0.00111584
[1200]	training's l2: 0.000854636	valid_1's l2: 0.00111581
[1210]	training's l2: 0.000853317	valid_1's l2: 0.00111575
[1220]	training's l2: 0.000852047	valid_1's l2: 0.00111565
[1230]	training's l2: 0.00085079	valid_1's l2: 0.00111566
[1240]	training's l2: 0.000849581	valid_1's l2: 0.00111556
[1250]	training's l2: 0.000848349	valid_1's l2: 0.0011155
[1260]	training's l2: 0.000847033	valid_1's l2: 0.00111539
[1270]	training's l2: 0.000845776	valid_1's l2: 0.00111531
[1280]	training's l2: 0.000844526	valid_1's l2: 0.00111524
[1290]	training's l2: 0.000843316	valid_1's l2: 0.00111523
[1300]	training's l2: 0.000842062	valid_1's l2: 0.0011152
[1310]	training's l2: 0.00084087	valid_1's l2: 0.00111515
[1320]	training's l2: 0.000839639	valid_1's l2: 0.00111507
[1330]	training's l2: 0.000838448	valid_1's l2: 0.00111498
[1340]	training's l2: 0.000837277	valid_1's l2: 0.00111491
[1350]	training's l2: 0.000836128	valid_1's l2: 0.00111486
[1360]	training's l2: 0.000834911	valid_1's l2: 0.00111485
[1370]	training's l2: 0.000833725	valid_1's l2: 0.00111482
[1380]	training's l2: 0.000832514	valid_1's l2: 0.00111483
[1390]	training's l2: 0.000831336	valid_1's l2: 0.00111476
[1400]	training's l2: 0.000830161	valid_1's l2: 0.00111469
[1410]	training's l2: 0.000828932	valid_1's l2: 0.00111462
[1420]	training's l2: 0.000827798	valid_1's l2: 0.00111458
[1430]	training's l2: 0.00082668	valid_1's l2: 0.00111453
[1440]	training's l2: 0.000825531	valid_1's l2: 0.00111452
[1450]	training's l2: 0.00082444	valid_1's l2: 0.00111448
[1460]	training's l2: 0.000823282	valid_1's l2: 0.00111451
[1470]	training's l2: 0.000822169	valid_1's l2: 0.00111444
[1480]	training's l2: 0.000820998	valid_1's l2: 0.00111441
[1490]	training's l2: 0.000819875	valid_1's l2: 0.0011144
[1500]	training's l2: 0.000818833	valid_1's l2: 0.00111437
[1510]	training's l2: 0.000817748	valid_1's l2: 0.00111432
[1520]	training's l2: 0.000816695	valid_1's l2: 0.00111434
[1530]	training's l2: 0.000815606	valid_1's l2: 0.00111434
[1540]	training's l2: 0.000814532	valid_1's l2: 0.00111432
[1550]	training's l2: 0.000813361	valid_1's l2: 0.00111422
[1560]	training's l2: 0.000812336	valid_1's l2: 0.00111426
[1570]	training's l2: 0.000811293	valid_1's l2: 0.00111425
[1580]	training's l2: 0.000810255	valid_1's l2: 0.0011142
[1590]	training's l2: 0.000809217	valid_1's l2: 0.00111419
[1600]	training's l2: 0.000808167	valid_1's l2: 0.00111419
[1610]	training's l2: 0.00080716	valid_1's l2: 0.00111419
[1620]	training's l2: 0.000806064	valid_1's l2: 0.00111413
[1630]	training's l2: 0.000805025	valid_1's l2: 0.00111412
[1640]	training's l2: 0.000804051	valid_1's l2: 0.00111408
[1650]	training's l2: 0.000803039	valid_1's l2: 0.00111403
[1660]	training's l2: 0.000801998	valid_1's l2: 0.00111397
[1670]	training's l2: 0.000800955	valid_1's l2: 0.00111391
[1680]	training's l2: 0.000799929	valid_1's l2: 0.00111385
[1690]	training's l2: 0.000798919	valid_1's l2: 0.00111384
[1700]	training's l2: 0.00079799	valid_1's l2: 0.00111388
[1710]	training's l2: 0.000796937	valid_1's l2: 0.00111382
[1720]	training's l2: 0.000795917	valid_1's l2: 0.00111381
[1730]	training's l2: 0.000794868	valid_1's l2: 0.00111377
[1740]	training's l2: 0.000793898	valid_1's l2: 0.00111371
[1750]	training's l2: 0.000792917	valid_1's l2: 0.0011137
[1760]	training's l2: 0.000791934	valid_1's l2: 0.00111371
[1770]	training's l2: 0.000790967	valid_1's l2: 0.00111371
Early stopping, best iteration is:
[1749]	training's l2: 0.000793015	valid_1's l2: 0.00111367
score1: 1.252326813674214
