standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:1
start rank:2
start rank:3
start rank:4
start rank:5
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.311004 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 35763
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 193
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151554	valid_1's l2: 0.0015798
[20]	training's l2: 0.0014472	valid_1's l2: 0.00151681
[30]	training's l2: 0.00139004	valid_1's l2: 0.00146423
[40]	training's l2: 0.00134174	valid_1's l2: 0.00141996
[50]	training's l2: 0.00130097	valid_1's l2: 0.0013834
[60]	training's l2: 0.00126633	valid_1's l2: 0.00135273
[70]	training's l2: 0.00123713	valid_1's l2: 0.00132705
[80]	training's l2: 0.00121201	valid_1's l2: 0.00130501
[90]	training's l2: 0.00119058	valid_1's l2: 0.0012865
[100]	training's l2: 0.0011719	valid_1's l2: 0.00127052
[110]	training's l2: 0.00115557	valid_1's l2: 0.00125697
[120]	training's l2: 0.00114096	valid_1's l2: 0.00124501
[130]	training's l2: 0.00112811	valid_1's l2: 0.00123472
[140]	training's l2: 0.00111671	valid_1's l2: 0.00122576
[150]	training's l2: 0.00110663	valid_1's l2: 0.00121805
[160]	training's l2: 0.0010977	valid_1's l2: 0.00121111
[170]	training's l2: 0.00108946	valid_1's l2: 0.00120475
[180]	training's l2: 0.0010819	valid_1's l2: 0.00119918
[190]	training's l2: 0.00107501	valid_1's l2: 0.0011944
[200]	training's l2: 0.00106878	valid_1's l2: 0.0011901
[210]	training's l2: 0.00106308	valid_1's l2: 0.00118602
[220]	training's l2: 0.0010578	valid_1's l2: 0.00118231
[230]	training's l2: 0.00105275	valid_1's l2: 0.0011787
[240]	training's l2: 0.00104808	valid_1's l2: 0.00117549
[250]	training's l2: 0.00104362	valid_1's l2: 0.00117254
[260]	training's l2: 0.00103942	valid_1's l2: 0.00116978
[270]	training's l2: 0.00103526	valid_1's l2: 0.00116722
[280]	training's l2: 0.00103117	valid_1's l2: 0.00116459
[290]	training's l2: 0.00102726	valid_1's l2: 0.00116224
[300]	training's l2: 0.00102344	valid_1's l2: 0.00116
[310]	training's l2: 0.00101996	valid_1's l2: 0.00115805
[320]	training's l2: 0.00101652	valid_1's l2: 0.00115628
[330]	training's l2: 0.00101341	valid_1's l2: 0.00115453
[340]	training's l2: 0.00101012	valid_1's l2: 0.00115254
[350]	training's l2: 0.001007	valid_1's l2: 0.00115093
[360]	training's l2: 0.00100394	valid_1's l2: 0.00114935
[370]	training's l2: 0.00100107	valid_1's l2: 0.00114797
[380]	training's l2: 0.000998201	valid_1's l2: 0.00114649
[390]	training's l2: 0.00099531	valid_1's l2: 0.00114513
[400]	training's l2: 0.000992505	valid_1's l2: 0.00114377
[410]	training's l2: 0.000989936	valid_1's l2: 0.00114259
[420]	training's l2: 0.000987398	valid_1's l2: 0.0011414
[430]	training's l2: 0.000984904	valid_1's l2: 0.00114039
[440]	training's l2: 0.00098258	valid_1's l2: 0.00113944
[450]	training's l2: 0.000980039	valid_1's l2: 0.00113834
[460]	training's l2: 0.00097766	valid_1's l2: 0.0011373
[470]	training's l2: 0.000975173	valid_1's l2: 0.00113634
[480]	training's l2: 0.000972731	valid_1's l2: 0.00113551
[490]	training's l2: 0.000970298	valid_1's l2: 0.00113468
[500]	training's l2: 0.000968028	valid_1's l2: 0.00113389
[510]	training's l2: 0.000965725	valid_1's l2: 0.00113317
[520]	training's l2: 0.000963506	valid_1's l2: 0.00113257
[530]	training's l2: 0.000961317	valid_1's l2: 0.00113202
[540]	training's l2: 0.000959126	valid_1's l2: 0.0011313
[550]	training's l2: 0.000957093	valid_1's l2: 0.00113065
[560]	training's l2: 0.000954943	valid_1's l2: 0.0011301
[570]	training's l2: 0.000952814	valid_1's l2: 0.00112949
[580]	training's l2: 0.000950836	valid_1's l2: 0.00112896
[590]	training's l2: 0.000948746	valid_1's l2: 0.0011284
[600]	training's l2: 0.000946685	valid_1's l2: 0.00112792
[610]	training's l2: 0.000944815	valid_1's l2: 0.00112747
[620]	training's l2: 0.000942855	valid_1's l2: 0.00112706
[630]	training's l2: 0.000940956	valid_1's l2: 0.00112654
[640]	training's l2: 0.000939128	valid_1's l2: 0.00112611
[650]	training's l2: 0.000937288	valid_1's l2: 0.00112571
[660]	training's l2: 0.000935461	valid_1's l2: 0.00112531
[670]	training's l2: 0.000933667	valid_1's l2: 0.0011249
[680]	training's l2: 0.000931815	valid_1's l2: 0.00112449
[690]	training's l2: 0.000929912	valid_1's l2: 0.00112413
[700]	training's l2: 0.000928186	valid_1's l2: 0.00112381
[710]	training's l2: 0.000926306	valid_1's l2: 0.00112343
[720]	training's l2: 0.000924476	valid_1's l2: 0.00112317
[730]	training's l2: 0.000922708	valid_1's l2: 0.00112286
[740]	training's l2: 0.000920891	valid_1's l2: 0.00112258
[750]	training's l2: 0.000919163	valid_1's l2: 0.00112224
[760]	training's l2: 0.000917463	valid_1's l2: 0.001122
[770]	training's l2: 0.000915822	valid_1's l2: 0.00112172
[780]	training's l2: 0.000914109	valid_1's l2: 0.00112134
[790]	training's l2: 0.000912465	valid_1's l2: 0.00112105
[800]	training's l2: 0.000910856	valid_1's l2: 0.00112075
[810]	training's l2: 0.000909119	valid_1's l2: 0.00112045
[820]	training's l2: 0.000907575	valid_1's l2: 0.00112018
[830]	training's l2: 0.000905951	valid_1's l2: 0.00111991
[840]	training's l2: 0.000904483	valid_1's l2: 0.00111969
[850]	training's l2: 0.000902933	valid_1's l2: 0.00111947
[860]	training's l2: 0.000901292	valid_1's l2: 0.00111924
[870]	training's l2: 0.000899663	valid_1's l2: 0.00111904
[880]	training's l2: 0.000898099	valid_1's l2: 0.00111887
[890]	training's l2: 0.000896549	valid_1's l2: 0.0011187
[900]	training's l2: 0.000895067	valid_1's l2: 0.00111858
[910]	training's l2: 0.00089365	valid_1's l2: 0.00111844
[920]	training's l2: 0.000892081	valid_1's l2: 0.00111827
[930]	training's l2: 0.000890626	valid_1's l2: 0.0011181
[940]	training's l2: 0.00088913	valid_1's l2: 0.00111792
[950]	training's l2: 0.000887535	valid_1's l2: 0.00111765
[960]	training's l2: 0.000886132	valid_1's l2: 0.00111751
[970]	training's l2: 0.000884704	valid_1's l2: 0.00111732
[980]	training's l2: 0.00088326	valid_1's l2: 0.00111719
[990]	training's l2: 0.000881842	valid_1's l2: 0.00111708
[1000]	training's l2: 0.00088041	valid_1's l2: 0.00111691
[1010]	training's l2: 0.000878931	valid_1's l2: 0.00111679
[1020]	training's l2: 0.000877484	valid_1's l2: 0.00111671
[1030]	training's l2: 0.000876011	valid_1's l2: 0.00111658
[1040]	training's l2: 0.000874568	valid_1's l2: 0.00111652
[1050]	training's l2: 0.00087312	valid_1's l2: 0.00111636
[1060]	training's l2: 0.000871717	valid_1's l2: 0.00111628
[1070]	training's l2: 0.00087032	valid_1's l2: 0.0011162
[1080]	training's l2: 0.000868972	valid_1's l2: 0.00111606
[1090]	training's l2: 0.000867583	valid_1's l2: 0.00111593
[1100]	training's l2: 0.000866307	valid_1's l2: 0.00111584
[1110]	training's l2: 0.000865035	valid_1's l2: 0.00111577
[1120]	training's l2: 0.000863645	valid_1's l2: 0.00111563
[1130]	training's l2: 0.000862323	valid_1's l2: 0.00111548
[1140]	training's l2: 0.000861003	valid_1's l2: 0.00111542
[1150]	training's l2: 0.000859744	valid_1's l2: 0.00111538
[1160]	training's l2: 0.000858419	valid_1's l2: 0.00111532
[1170]	training's l2: 0.000857166	valid_1's l2: 0.00111522
[1180]	training's l2: 0.000855858	valid_1's l2: 0.00111516
[1190]	training's l2: 0.000854556	valid_1's l2: 0.00111507
[1200]	training's l2: 0.000853255	valid_1's l2: 0.00111494
[1210]	training's l2: 0.000852029	valid_1's l2: 0.00111489
[1220]	training's l2: 0.000850754	valid_1's l2: 0.0011148
[1230]	training's l2: 0.000849457	valid_1's l2: 0.00111473
[1240]	training's l2: 0.000848232	valid_1's l2: 0.00111469
[1250]	training's l2: 0.000846961	valid_1's l2: 0.00111462
[1260]	training's l2: 0.000845634	valid_1's l2: 0.00111454
[1270]	training's l2: 0.000844445	valid_1's l2: 0.00111449
[1280]	training's l2: 0.000843159	valid_1's l2: 0.00111443
[1290]	training's l2: 0.000841974	valid_1's l2: 0.00111437
[1300]	training's l2: 0.000840715	valid_1's l2: 0.00111432
[1310]	training's l2: 0.000839526	valid_1's l2: 0.00111434
[1320]	training's l2: 0.000838292	valid_1's l2: 0.00111428
[1330]	training's l2: 0.000837138	valid_1's l2: 0.00111421
[1340]	training's l2: 0.000835967	valid_1's l2: 0.00111417
[1350]	training's l2: 0.000834764	valid_1's l2: 0.00111406
[1360]	training's l2: 0.000833606	valid_1's l2: 0.00111403
[1370]	training's l2: 0.000832473	valid_1's l2: 0.00111397
[1380]	training's l2: 0.000831335	valid_1's l2: 0.00111392
[1390]	training's l2: 0.000830195	valid_1's l2: 0.00111388
[1400]	training's l2: 0.000829048	valid_1's l2: 0.00111381
[1410]	training's l2: 0.000827929	valid_1's l2: 0.00111379
[1420]	training's l2: 0.000826749	valid_1's l2: 0.00111374
[1430]	training's l2: 0.000825595	valid_1's l2: 0.00111364
[1440]	training's l2: 0.000824454	valid_1's l2: 0.00111357
[1450]	training's l2: 0.000823287	valid_1's l2: 0.00111349
[1460]	training's l2: 0.000822084	valid_1's l2: 0.00111348
[1470]	training's l2: 0.000820952	valid_1's l2: 0.00111339
[1480]	training's l2: 0.000819858	valid_1's l2: 0.00111339
[1490]	training's l2: 0.000818762	valid_1's l2: 0.00111328
[1500]	training's l2: 0.000817685	valid_1's l2: 0.0011133
[1510]	training's l2: 0.000816543	valid_1's l2: 0.00111326
[1520]	training's l2: 0.000815424	valid_1's l2: 0.00111317
[1530]	training's l2: 0.000814347	valid_1's l2: 0.0011132
[1540]	training's l2: 0.000813279	valid_1's l2: 0.0011132
[1550]	training's l2: 0.000812227	valid_1's l2: 0.00111315
[1560]	training's l2: 0.000811141	valid_1's l2: 0.00111309
[1570]	training's l2: 0.000810055	valid_1's l2: 0.00111309
[1580]	training's l2: 0.000808957	valid_1's l2: 0.00111307
[1590]	training's l2: 0.00080794	valid_1's l2: 0.00111311
[1600]	training's l2: 0.000806872	valid_1's l2: 0.00111314
Early stopping, best iteration is:
[1575]	training's l2: 0.000809511	valid_1's l2: 0.00111305
score1: 1.2520891590921563
