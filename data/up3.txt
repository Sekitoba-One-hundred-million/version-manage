standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:4
start rank:2
start rank:5
start rank:3
start rank:1
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.500587 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 39780
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 213
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151619	valid_1's l2: 0.00158353
[20]	training's l2: 0.00144836	valid_1's l2: 0.00152102
[30]	training's l2: 0.00139172	valid_1's l2: 0.00146911
[40]	training's l2: 0.00134406	valid_1's l2: 0.00142593
[50]	training's l2: 0.0013036	valid_1's l2: 0.00138959
[60]	training's l2: 0.0012694	valid_1's l2: 0.00135907
[70]	training's l2: 0.00124023	valid_1's l2: 0.00133319
[80]	training's l2: 0.00121523	valid_1's l2: 0.00131112
[90]	training's l2: 0.00119359	valid_1's l2: 0.00129212
[100]	training's l2: 0.00117509	valid_1's l2: 0.00127624
[110]	training's l2: 0.00115912	valid_1's l2: 0.00126275
[120]	training's l2: 0.00114466	valid_1's l2: 0.0012508
[130]	training's l2: 0.00113207	valid_1's l2: 0.00124059
[140]	training's l2: 0.00112075	valid_1's l2: 0.0012315
[150]	training's l2: 0.00111065	valid_1's l2: 0.00122363
[160]	training's l2: 0.00110163	valid_1's l2: 0.00121673
[170]	training's l2: 0.00109358	valid_1's l2: 0.00121039
[180]	training's l2: 0.00108609	valid_1's l2: 0.00120467
[190]	training's l2: 0.00107912	valid_1's l2: 0.0011997
[200]	training's l2: 0.00107283	valid_1's l2: 0.00119522
[210]	training's l2: 0.00106705	valid_1's l2: 0.00119131
[220]	training's l2: 0.0010617	valid_1's l2: 0.00118759
[230]	training's l2: 0.00105663	valid_1's l2: 0.00118407
[240]	training's l2: 0.00105184	valid_1's l2: 0.00118064
[250]	training's l2: 0.00104729	valid_1's l2: 0.00117762
[260]	training's l2: 0.00104308	valid_1's l2: 0.00117488
[270]	training's l2: 0.00103904	valid_1's l2: 0.00117237
[280]	training's l2: 0.0010351	valid_1's l2: 0.00116978
[290]	training's l2: 0.00103122	valid_1's l2: 0.00116726
[300]	training's l2: 0.00102749	valid_1's l2: 0.00116485
[310]	training's l2: 0.00102395	valid_1's l2: 0.00116269
[320]	training's l2: 0.00102058	valid_1's l2: 0.00116089
[330]	training's l2: 0.0010175	valid_1's l2: 0.00115927
[340]	training's l2: 0.00101452	valid_1's l2: 0.0011576
[350]	training's l2: 0.00101144	valid_1's l2: 0.00115595
[360]	training's l2: 0.00100843	valid_1's l2: 0.00115436
[370]	training's l2: 0.00100555	valid_1's l2: 0.00115291
[380]	training's l2: 0.00100255	valid_1's l2: 0.00115132
[390]	training's l2: 0.000999892	valid_1's l2: 0.00115002
[400]	training's l2: 0.000996923	valid_1's l2: 0.00114852
[410]	training's l2: 0.000994225	valid_1's l2: 0.00114727
[420]	training's l2: 0.000991397	valid_1's l2: 0.0011459
[430]	training's l2: 0.000988829	valid_1's l2: 0.00114477
[440]	training's l2: 0.00098624	valid_1's l2: 0.00114366
[450]	training's l2: 0.000983951	valid_1's l2: 0.00114276
[460]	training's l2: 0.000981649	valid_1's l2: 0.00114177
[470]	training's l2: 0.00097925	valid_1's l2: 0.00114087
[480]	training's l2: 0.000976835	valid_1's l2: 0.00113995
[490]	training's l2: 0.000974472	valid_1's l2: 0.00113903
[500]	training's l2: 0.000971982	valid_1's l2: 0.00113809
[510]	training's l2: 0.000969642	valid_1's l2: 0.00113715
[520]	training's l2: 0.000967318	valid_1's l2: 0.00113638
[530]	training's l2: 0.000965096	valid_1's l2: 0.0011356
[540]	training's l2: 0.00096284	valid_1's l2: 0.00113494
[550]	training's l2: 0.000960696	valid_1's l2: 0.00113435
[560]	training's l2: 0.000958473	valid_1's l2: 0.00113384
[570]	training's l2: 0.000956464	valid_1's l2: 0.00113334
[580]	training's l2: 0.00095443	valid_1's l2: 0.00113275
[590]	training's l2: 0.000952418	valid_1's l2: 0.00113226
[600]	training's l2: 0.000950499	valid_1's l2: 0.00113181
[610]	training's l2: 0.00094843	valid_1's l2: 0.00113132
[620]	training's l2: 0.000946413	valid_1's l2: 0.00113081
[630]	training's l2: 0.000944413	valid_1's l2: 0.00113021
[640]	training's l2: 0.000942422	valid_1's l2: 0.00112967
[650]	training's l2: 0.000940567	valid_1's l2: 0.00112927
[660]	training's l2: 0.00093853	valid_1's l2: 0.00112871
[670]	training's l2: 0.0009367	valid_1's l2: 0.00112838
[680]	training's l2: 0.000934926	valid_1's l2: 0.00112793
[690]	training's l2: 0.000932975	valid_1's l2: 0.0011275
[700]	training's l2: 0.000931195	valid_1's l2: 0.00112718
[710]	training's l2: 0.000929209	valid_1's l2: 0.00112671
[720]	training's l2: 0.000927473	valid_1's l2: 0.00112637
[730]	training's l2: 0.000925785	valid_1's l2: 0.00112604
[740]	training's l2: 0.000923991	valid_1's l2: 0.00112585
[750]	training's l2: 0.000922188	valid_1's l2: 0.00112554
[760]	training's l2: 0.000920509	valid_1's l2: 0.00112526
[770]	training's l2: 0.000918791	valid_1's l2: 0.00112514
[780]	training's l2: 0.000917095	valid_1's l2: 0.00112475
[790]	training's l2: 0.000915411	valid_1's l2: 0.00112446
[800]	training's l2: 0.000913769	valid_1's l2: 0.00112415
[810]	training's l2: 0.000912175	valid_1's l2: 0.00112388
[820]	training's l2: 0.000910565	valid_1's l2: 0.00112358
[830]	training's l2: 0.000908977	valid_1's l2: 0.00112328
[840]	training's l2: 0.000907356	valid_1's l2: 0.00112307
[850]	training's l2: 0.000905716	valid_1's l2: 0.00112283
[860]	training's l2: 0.000904154	valid_1's l2: 0.00112261
[870]	training's l2: 0.000902613	valid_1's l2: 0.00112251
[880]	training's l2: 0.000901083	valid_1's l2: 0.00112229
[890]	training's l2: 0.000899513	valid_1's l2: 0.00112215
[900]	training's l2: 0.000898031	valid_1's l2: 0.00112196
[910]	training's l2: 0.000896572	valid_1's l2: 0.00112178
[920]	training's l2: 0.000895089	valid_1's l2: 0.00112158
[930]	training's l2: 0.000893481	valid_1's l2: 0.00112143
[940]	training's l2: 0.000892064	valid_1's l2: 0.00112128
[950]	training's l2: 0.000890545	valid_1's l2: 0.00112106
[960]	training's l2: 0.000889068	valid_1's l2: 0.00112093
[970]	training's l2: 0.00088758	valid_1's l2: 0.00112072
[980]	training's l2: 0.000886193	valid_1's l2: 0.00112056
[990]	training's l2: 0.000884688	valid_1's l2: 0.00112034
[1000]	training's l2: 0.00088327	valid_1's l2: 0.00112018
[1010]	training's l2: 0.000881868	valid_1's l2: 0.00112001
[1020]	training's l2: 0.000880509	valid_1's l2: 0.00111989
[1030]	training's l2: 0.000879218	valid_1's l2: 0.00111972
[1040]	training's l2: 0.000877748	valid_1's l2: 0.00111959
[1050]	training's l2: 0.0008764	valid_1's l2: 0.00111947
[1060]	training's l2: 0.000875015	valid_1's l2: 0.00111935
[1070]	training's l2: 0.0008737	valid_1's l2: 0.00111919
[1080]	training's l2: 0.000872271	valid_1's l2: 0.00111906
[1090]	training's l2: 0.000870904	valid_1's l2: 0.00111891
[1100]	training's l2: 0.000869533	valid_1's l2: 0.00111877
[1110]	training's l2: 0.000868222	valid_1's l2: 0.00111866
[1120]	training's l2: 0.0008669	valid_1's l2: 0.00111853
[1130]	training's l2: 0.000865603	valid_1's l2: 0.00111844
[1140]	training's l2: 0.000864174	valid_1's l2: 0.00111843
[1150]	training's l2: 0.000862796	valid_1's l2: 0.00111836
[1160]	training's l2: 0.000861411	valid_1's l2: 0.00111824
[1170]	training's l2: 0.000860171	valid_1's l2: 0.00111818
[1180]	training's l2: 0.000858833	valid_1's l2: 0.00111806
[1190]	training's l2: 0.000857343	valid_1's l2: 0.001118
[1200]	training's l2: 0.000856053	valid_1's l2: 0.0011179
[1210]	training's l2: 0.000854803	valid_1's l2: 0.00111782
[1220]	training's l2: 0.000853562	valid_1's l2: 0.00111773
[1230]	training's l2: 0.000852318	valid_1's l2: 0.00111771
[1240]	training's l2: 0.000851018	valid_1's l2: 0.00111765
[1250]	training's l2: 0.000849659	valid_1's l2: 0.00111757
[1260]	training's l2: 0.000848448	valid_1's l2: 0.00111752
[1270]	training's l2: 0.000847233	valid_1's l2: 0.00111748
[1280]	training's l2: 0.000845873	valid_1's l2: 0.00111742
[1290]	training's l2: 0.000844593	valid_1's l2: 0.00111736
[1300]	training's l2: 0.000843396	valid_1's l2: 0.00111726
[1310]	training's l2: 0.000842053	valid_1's l2: 0.00111719
[1320]	training's l2: 0.000840874	valid_1's l2: 0.0011172
[1330]	training's l2: 0.000839669	valid_1's l2: 0.00111717
[1340]	training's l2: 0.000838493	valid_1's l2: 0.00111714
[1350]	training's l2: 0.00083726	valid_1's l2: 0.0011172
[1360]	training's l2: 0.000836055	valid_1's l2: 0.00111713
[1370]	training's l2: 0.000834933	valid_1's l2: 0.00111713
[1380]	training's l2: 0.00083367	valid_1's l2: 0.00111716
[1390]	training's l2: 0.000832419	valid_1's l2: 0.00111711
[1400]	training's l2: 0.000831252	valid_1's l2: 0.00111711
[1410]	training's l2: 0.000830114	valid_1's l2: 0.00111711
[1420]	training's l2: 0.000828962	valid_1's l2: 0.00111699
[1430]	training's l2: 0.00082782	valid_1's l2: 0.00111702
[1440]	training's l2: 0.000826687	valid_1's l2: 0.00111701
[1450]	training's l2: 0.000825532	valid_1's l2: 0.00111701
[1460]	training's l2: 0.000824378	valid_1's l2: 0.00111695
[1470]	training's l2: 0.000823255	valid_1's l2: 0.00111694
[1480]	training's l2: 0.000822125	valid_1's l2: 0.00111686
[1490]	training's l2: 0.000820996	valid_1's l2: 0.00111677
[1500]	training's l2: 0.000819892	valid_1's l2: 0.00111667
[1510]	training's l2: 0.000818793	valid_1's l2: 0.00111666
[1520]	training's l2: 0.000817743	valid_1's l2: 0.00111664
[1530]	training's l2: 0.000816658	valid_1's l2: 0.0011166
[1540]	training's l2: 0.000815551	valid_1's l2: 0.00111659
[1550]	training's l2: 0.000814434	valid_1's l2: 0.00111661
[1560]	training's l2: 0.000813371	valid_1's l2: 0.00111658
[1570]	training's l2: 0.000812284	valid_1's l2: 0.00111651
[1580]	training's l2: 0.000811233	valid_1's l2: 0.00111646
[1590]	training's l2: 0.000810227	valid_1's l2: 0.0011164
[1600]	training's l2: 0.000809169	valid_1's l2: 0.0011163
[1610]	training's l2: 0.000808152	valid_1's l2: 0.00111626
[1620]	training's l2: 0.000807097	valid_1's l2: 0.00111628
[1630]	training's l2: 0.0008061	valid_1's l2: 0.00111626
[1640]	training's l2: 0.00080503	valid_1's l2: 0.00111625
[1650]	training's l2: 0.000804022	valid_1's l2: 0.00111624
Early stopping, best iteration is:
[1628]	training's l2: 0.000806298	valid_1's l2: 0.0011162
score1: 1.2536524490735566
