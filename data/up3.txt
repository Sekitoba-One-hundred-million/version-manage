standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:5
start rank:1
start rank:2
start rank:3
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.458541 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 39878
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 213
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151615	valid_1's l2: 0.00158071
[20]	training's l2: 0.00144823	valid_1's l2: 0.00151803
[30]	training's l2: 0.00139159	valid_1's l2: 0.00146599
[40]	training's l2: 0.00134382	valid_1's l2: 0.00142263
[50]	training's l2: 0.00130349	valid_1's l2: 0.00138657
[60]	training's l2: 0.00126924	valid_1's l2: 0.00135608
[70]	training's l2: 0.00124	valid_1's l2: 0.0013301
[80]	training's l2: 0.00121505	valid_1's l2: 0.00130804
[90]	training's l2: 0.00119353	valid_1's l2: 0.00128925
[100]	training's l2: 0.00117488	valid_1's l2: 0.00127309
[110]	training's l2: 0.00115875	valid_1's l2: 0.00125951
[120]	training's l2: 0.00114437	valid_1's l2: 0.00124776
[130]	training's l2: 0.00113161	valid_1's l2: 0.00123751
[140]	training's l2: 0.00112026	valid_1's l2: 0.00122836
[150]	training's l2: 0.0011101	valid_1's l2: 0.00122052
[160]	training's l2: 0.0011012	valid_1's l2: 0.00121383
[170]	training's l2: 0.00109321	valid_1's l2: 0.00120766
[180]	training's l2: 0.00108569	valid_1's l2: 0.00120189
[190]	training's l2: 0.00107878	valid_1's l2: 0.00119688
[200]	training's l2: 0.00107241	valid_1's l2: 0.0011926
[210]	training's l2: 0.00106675	valid_1's l2: 0.00118865
[220]	training's l2: 0.00106141	valid_1's l2: 0.00118483
[230]	training's l2: 0.00105629	valid_1's l2: 0.00118128
[240]	training's l2: 0.00105146	valid_1's l2: 0.00117805
[250]	training's l2: 0.00104681	valid_1's l2: 0.00117505
[260]	training's l2: 0.00104242	valid_1's l2: 0.00117211
[270]	training's l2: 0.0010384	valid_1's l2: 0.00116946
[280]	training's l2: 0.00103449	valid_1's l2: 0.00116706
[290]	training's l2: 0.00103054	valid_1's l2: 0.00116462
[300]	training's l2: 0.00102676	valid_1's l2: 0.00116239
[310]	training's l2: 0.00102315	valid_1's l2: 0.00116034
[320]	training's l2: 0.00101974	valid_1's l2: 0.0011585
[330]	training's l2: 0.00101671	valid_1's l2: 0.00115691
[340]	training's l2: 0.00101379	valid_1's l2: 0.00115524
[350]	training's l2: 0.00101061	valid_1's l2: 0.00115353
[360]	training's l2: 0.00100747	valid_1's l2: 0.0011518
[370]	training's l2: 0.00100459	valid_1's l2: 0.00115039
[380]	training's l2: 0.00100156	valid_1's l2: 0.00114892
[390]	training's l2: 0.000998493	valid_1's l2: 0.00114741
[400]	training's l2: 0.000995744	valid_1's l2: 0.00114619
[410]	training's l2: 0.000993101	valid_1's l2: 0.00114508
[420]	training's l2: 0.000990342	valid_1's l2: 0.00114387
[430]	training's l2: 0.000987776	valid_1's l2: 0.00114268
[440]	training's l2: 0.000985387	valid_1's l2: 0.00114175
[450]	training's l2: 0.000982902	valid_1's l2: 0.00114064
[460]	training's l2: 0.000980442	valid_1's l2: 0.00113972
[470]	training's l2: 0.000977999	valid_1's l2: 0.00113871
[480]	training's l2: 0.000975484	valid_1's l2: 0.00113772
[490]	training's l2: 0.000973086	valid_1's l2: 0.0011368
[500]	training's l2: 0.000970601	valid_1's l2: 0.00113585
[510]	training's l2: 0.000968331	valid_1's l2: 0.00113507
[520]	training's l2: 0.000966057	valid_1's l2: 0.00113429
[530]	training's l2: 0.000963709	valid_1's l2: 0.00113353
[540]	training's l2: 0.000961478	valid_1's l2: 0.00113281
[550]	training's l2: 0.000959335	valid_1's l2: 0.00113228
[560]	training's l2: 0.000957149	valid_1's l2: 0.00113174
[570]	training's l2: 0.000955045	valid_1's l2: 0.00113119
[580]	training's l2: 0.000952846	valid_1's l2: 0.00113057
[590]	training's l2: 0.000950955	valid_1's l2: 0.00113017
[600]	training's l2: 0.000948857	valid_1's l2: 0.00112957
[610]	training's l2: 0.000946838	valid_1's l2: 0.00112923
[620]	training's l2: 0.000944902	valid_1's l2: 0.00112884
[630]	training's l2: 0.000942952	valid_1's l2: 0.0011284
[640]	training's l2: 0.000940893	valid_1's l2: 0.00112801
[650]	training's l2: 0.000938888	valid_1's l2: 0.00112759
[660]	training's l2: 0.00093691	valid_1's l2: 0.00112724
[670]	training's l2: 0.000935113	valid_1's l2: 0.00112692
[680]	training's l2: 0.000933329	valid_1's l2: 0.00112656
[690]	training's l2: 0.000931472	valid_1's l2: 0.00112622
[700]	training's l2: 0.000929658	valid_1's l2: 0.00112586
[710]	training's l2: 0.000927955	valid_1's l2: 0.00112549
[720]	training's l2: 0.000926057	valid_1's l2: 0.00112512
[730]	training's l2: 0.000924353	valid_1's l2: 0.00112483
[740]	training's l2: 0.000922624	valid_1's l2: 0.00112458
[750]	training's l2: 0.000920736	valid_1's l2: 0.00112434
[760]	training's l2: 0.000918919	valid_1's l2: 0.00112406
[770]	training's l2: 0.00091727	valid_1's l2: 0.00112385
[780]	training's l2: 0.000915598	valid_1's l2: 0.00112357
[790]	training's l2: 0.00091387	valid_1's l2: 0.00112325
[800]	training's l2: 0.000912219	valid_1's l2: 0.00112298
[810]	training's l2: 0.000910599	valid_1's l2: 0.00112274
[820]	training's l2: 0.000908949	valid_1's l2: 0.00112255
[830]	training's l2: 0.000907376	valid_1's l2: 0.0011224
[840]	training's l2: 0.000905704	valid_1's l2: 0.00112211
[850]	training's l2: 0.000904088	valid_1's l2: 0.00112181
[860]	training's l2: 0.000902583	valid_1's l2: 0.0011216
[870]	training's l2: 0.000900979	valid_1's l2: 0.00112139
[880]	training's l2: 0.000899387	valid_1's l2: 0.00112107
[890]	training's l2: 0.000897854	valid_1's l2: 0.00112088
[900]	training's l2: 0.000896335	valid_1's l2: 0.00112068
[910]	training's l2: 0.000894871	valid_1's l2: 0.00112048
[920]	training's l2: 0.000893377	valid_1's l2: 0.00112019
[930]	training's l2: 0.000891763	valid_1's l2: 0.00111994
[940]	training's l2: 0.000890248	valid_1's l2: 0.00111973
[950]	training's l2: 0.000888856	valid_1's l2: 0.00111959
[960]	training's l2: 0.000887402	valid_1's l2: 0.00111946
[970]	training's l2: 0.000886009	valid_1's l2: 0.00111936
[980]	training's l2: 0.000884576	valid_1's l2: 0.00111913
[990]	training's l2: 0.000883145	valid_1's l2: 0.00111902
[1000]	training's l2: 0.000881736	valid_1's l2: 0.00111904
[1010]	training's l2: 0.000880287	valid_1's l2: 0.00111887
[1020]	training's l2: 0.00087889	valid_1's l2: 0.00111882
[1030]	training's l2: 0.000877532	valid_1's l2: 0.00111878
[1040]	training's l2: 0.000876174	valid_1's l2: 0.00111864
[1050]	training's l2: 0.000874718	valid_1's l2: 0.00111845
[1060]	training's l2: 0.000873292	valid_1's l2: 0.0011183
[1070]	training's l2: 0.000871904	valid_1's l2: 0.00111817
[1080]	training's l2: 0.000870537	valid_1's l2: 0.00111795
[1090]	training's l2: 0.000869135	valid_1's l2: 0.00111783
[1100]	training's l2: 0.000867739	valid_1's l2: 0.0011177
[1110]	training's l2: 0.000866467	valid_1's l2: 0.00111762
[1120]	training's l2: 0.000865029	valid_1's l2: 0.00111758
[1130]	training's l2: 0.00086363	valid_1's l2: 0.00111754
[1140]	training's l2: 0.000862313	valid_1's l2: 0.00111747
[1150]	training's l2: 0.000860963	valid_1's l2: 0.00111742
[1160]	training's l2: 0.000859655	valid_1's l2: 0.00111734
[1170]	training's l2: 0.000858315	valid_1's l2: 0.00111727
[1180]	training's l2: 0.000857025	valid_1's l2: 0.00111719
[1190]	training's l2: 0.000855751	valid_1's l2: 0.00111705
[1200]	training's l2: 0.000854529	valid_1's l2: 0.00111692
[1210]	training's l2: 0.00085321	valid_1's l2: 0.00111684
[1220]	training's l2: 0.000851959	valid_1's l2: 0.00111676
[1230]	training's l2: 0.000850648	valid_1's l2: 0.00111667
[1240]	training's l2: 0.000849384	valid_1's l2: 0.00111655
[1250]	training's l2: 0.000848074	valid_1's l2: 0.0011165
[1260]	training's l2: 0.000846789	valid_1's l2: 0.0011165
[1270]	training's l2: 0.000845555	valid_1's l2: 0.00111646
[1280]	training's l2: 0.000844307	valid_1's l2: 0.00111636
[1290]	training's l2: 0.000843102	valid_1's l2: 0.0011163
[1300]	training's l2: 0.000841885	valid_1's l2: 0.00111623
[1310]	training's l2: 0.000840572	valid_1's l2: 0.00111621
[1320]	training's l2: 0.000839339	valid_1's l2: 0.00111615
[1330]	training's l2: 0.000838135	valid_1's l2: 0.00111608
[1340]	training's l2: 0.000836969	valid_1's l2: 0.00111603
[1350]	training's l2: 0.000835736	valid_1's l2: 0.00111592
[1360]	training's l2: 0.000834565	valid_1's l2: 0.00111584
[1370]	training's l2: 0.000833393	valid_1's l2: 0.00111576
[1380]	training's l2: 0.000832202	valid_1's l2: 0.00111567
[1390]	training's l2: 0.000831011	valid_1's l2: 0.00111561
[1400]	training's l2: 0.000829779	valid_1's l2: 0.00111554
[1410]	training's l2: 0.000828555	valid_1's l2: 0.00111542
[1420]	training's l2: 0.000827455	valid_1's l2: 0.00111536
[1430]	training's l2: 0.00082633	valid_1's l2: 0.0011153
[1440]	training's l2: 0.000825173	valid_1's l2: 0.00111524
[1450]	training's l2: 0.000824014	valid_1's l2: 0.00111518
[1460]	training's l2: 0.000822895	valid_1's l2: 0.00111511
[1470]	training's l2: 0.000821719	valid_1's l2: 0.0011152
[1480]	training's l2: 0.000820582	valid_1's l2: 0.00111518
Early stopping, best iteration is:
[1459]	training's l2: 0.000822996	valid_1's l2: 0.0011151
score1: 1.2531348167877072
