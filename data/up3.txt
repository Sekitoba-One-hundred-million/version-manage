standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:5
start rank:1
start rank:3
start rank:2
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.312082 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 35623
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 194
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151696	valid_1's l2: 0.00154731
[20]	training's l2: 0.00144957	valid_1's l2: 0.00148431
[30]	training's l2: 0.00139309	valid_1's l2: 0.0014322
[40]	training's l2: 0.00134557	valid_1's l2: 0.00138861
[50]	training's l2: 0.00130517	valid_1's l2: 0.00135219
[60]	training's l2: 0.00127084	valid_1's l2: 0.00132167
[70]	training's l2: 0.00124165	valid_1's l2: 0.00129591
[80]	training's l2: 0.00121674	valid_1's l2: 0.00127419
[90]	training's l2: 0.00119504	valid_1's l2: 0.00125567
[100]	training's l2: 0.00117618	valid_1's l2: 0.0012398
[110]	training's l2: 0.00115956	valid_1's l2: 0.00122574
[120]	training's l2: 0.00114517	valid_1's l2: 0.00121375
[130]	training's l2: 0.00113257	valid_1's l2: 0.00120336
[140]	training's l2: 0.00112134	valid_1's l2: 0.00119414
[150]	training's l2: 0.00111117	valid_1's l2: 0.00118608
[160]	training's l2: 0.00110213	valid_1's l2: 0.001179
[170]	training's l2: 0.00109391	valid_1's l2: 0.00117261
[180]	training's l2: 0.00108646	valid_1's l2: 0.00116687
[190]	training's l2: 0.0010795	valid_1's l2: 0.00116166
[200]	training's l2: 0.00107302	valid_1's l2: 0.00115693
[210]	training's l2: 0.00106705	valid_1's l2: 0.00115256
[220]	training's l2: 0.00106154	valid_1's l2: 0.00114861
[230]	training's l2: 0.00105629	valid_1's l2: 0.00114501
[240]	training's l2: 0.00105135	valid_1's l2: 0.00114157
[250]	training's l2: 0.00104673	valid_1's l2: 0.00113844
[260]	training's l2: 0.00104217	valid_1's l2: 0.00113534
[270]	training's l2: 0.00103793	valid_1's l2: 0.00113269
[280]	training's l2: 0.00103389	valid_1's l2: 0.00113015
[290]	training's l2: 0.00102993	valid_1's l2: 0.00112773
[300]	training's l2: 0.00102621	valid_1's l2: 0.00112566
[310]	training's l2: 0.00102238	valid_1's l2: 0.00112337
[320]	training's l2: 0.00101909	valid_1's l2: 0.00112153
[330]	training's l2: 0.00101558	valid_1's l2: 0.00111935
[340]	training's l2: 0.00101238	valid_1's l2: 0.00111748
[350]	training's l2: 0.00100925	valid_1's l2: 0.00111568
[360]	training's l2: 0.0010062	valid_1's l2: 0.00111395
[370]	training's l2: 0.00100296	valid_1's l2: 0.00111217
[380]	training's l2: 0.000999953	valid_1's l2: 0.00111066
[390]	training's l2: 0.000997165	valid_1's l2: 0.0011093
[400]	training's l2: 0.000994517	valid_1's l2: 0.00110803
[410]	training's l2: 0.000991915	valid_1's l2: 0.00110678
[420]	training's l2: 0.000989349	valid_1's l2: 0.00110561
[430]	training's l2: 0.000986903	valid_1's l2: 0.00110457
[440]	training's l2: 0.000984459	valid_1's l2: 0.00110347
[450]	training's l2: 0.000981956	valid_1's l2: 0.00110246
[460]	training's l2: 0.000979642	valid_1's l2: 0.00110153
[470]	training's l2: 0.000977145	valid_1's l2: 0.00110048
[480]	training's l2: 0.000974698	valid_1's l2: 0.00109965
[490]	training's l2: 0.000972112	valid_1's l2: 0.00109868
[500]	training's l2: 0.000969667	valid_1's l2: 0.0010977
[510]	training's l2: 0.000967322	valid_1's l2: 0.00109682
[520]	training's l2: 0.000965109	valid_1's l2: 0.00109612
[530]	training's l2: 0.00096271	valid_1's l2: 0.00109536
[540]	training's l2: 0.000960414	valid_1's l2: 0.00109458
[550]	training's l2: 0.000958241	valid_1's l2: 0.00109384
[560]	training's l2: 0.000956239	valid_1's l2: 0.00109323
[570]	training's l2: 0.000954097	valid_1's l2: 0.0010925
[580]	training's l2: 0.000952206	valid_1's l2: 0.0010919
[590]	training's l2: 0.000949955	valid_1's l2: 0.00109108
[600]	training's l2: 0.000947994	valid_1's l2: 0.00109048
[610]	training's l2: 0.000946087	valid_1's l2: 0.00108996
[620]	training's l2: 0.000944157	valid_1's l2: 0.00108943
[630]	training's l2: 0.000942017	valid_1's l2: 0.00108879
[640]	training's l2: 0.000939995	valid_1's l2: 0.00108823
[650]	training's l2: 0.0009382	valid_1's l2: 0.0010878
[660]	training's l2: 0.000936228	valid_1's l2: 0.00108726
[670]	training's l2: 0.000934223	valid_1's l2: 0.00108664
[680]	training's l2: 0.000932338	valid_1's l2: 0.00108617
[690]	training's l2: 0.000930561	valid_1's l2: 0.00108573
[700]	training's l2: 0.000928707	valid_1's l2: 0.00108528
[710]	training's l2: 0.00092702	valid_1's l2: 0.0010849
[720]	training's l2: 0.000925129	valid_1's l2: 0.00108438
[730]	training's l2: 0.000923393	valid_1's l2: 0.00108394
[740]	training's l2: 0.00092163	valid_1's l2: 0.00108348
[750]	training's l2: 0.000919932	valid_1's l2: 0.00108321
[760]	training's l2: 0.000918276	valid_1's l2: 0.00108283
[770]	training's l2: 0.000916447	valid_1's l2: 0.00108238
[780]	training's l2: 0.000914795	valid_1's l2: 0.00108206
[790]	training's l2: 0.000913122	valid_1's l2: 0.00108171
[800]	training's l2: 0.000911428	valid_1's l2: 0.00108141
[810]	training's l2: 0.000909816	valid_1's l2: 0.00108106
[820]	training's l2: 0.000908219	valid_1's l2: 0.00108073
[830]	training's l2: 0.000906559	valid_1's l2: 0.00108045
[840]	training's l2: 0.000905078	valid_1's l2: 0.00108021
[850]	training's l2: 0.000903495	valid_1's l2: 0.0010799
[860]	training's l2: 0.000902024	valid_1's l2: 0.00107965
[870]	training's l2: 0.000900469	valid_1's l2: 0.00107939
[880]	training's l2: 0.000898869	valid_1's l2: 0.001079
[890]	training's l2: 0.000897343	valid_1's l2: 0.00107879
[900]	training's l2: 0.000895728	valid_1's l2: 0.00107851
[910]	training's l2: 0.000894223	valid_1's l2: 0.0010782
[920]	training's l2: 0.00089263	valid_1's l2: 0.0010779
[930]	training's l2: 0.000891101	valid_1's l2: 0.00107767
[940]	training's l2: 0.000889515	valid_1's l2: 0.00107735
[950]	training's l2: 0.00088801	valid_1's l2: 0.00107707
[960]	training's l2: 0.000886441	valid_1's l2: 0.00107682
[970]	training's l2: 0.000884972	valid_1's l2: 0.00107655
[980]	training's l2: 0.000883589	valid_1's l2: 0.00107642
[990]	training's l2: 0.000882043	valid_1's l2: 0.00107614
[1000]	training's l2: 0.000880559	valid_1's l2: 0.00107599
[1010]	training's l2: 0.000879166	valid_1's l2: 0.00107578
[1020]	training's l2: 0.000877675	valid_1's l2: 0.00107559
[1030]	training's l2: 0.000876379	valid_1's l2: 0.00107542
[1040]	training's l2: 0.000874896	valid_1's l2: 0.00107521
[1050]	training's l2: 0.000873553	valid_1's l2: 0.00107503
[1060]	training's l2: 0.000872144	valid_1's l2: 0.00107486
[1070]	training's l2: 0.000870835	valid_1's l2: 0.00107468
[1080]	training's l2: 0.000869336	valid_1's l2: 0.00107448
[1090]	training's l2: 0.000867986	valid_1's l2: 0.0010744
[1100]	training's l2: 0.000866668	valid_1's l2: 0.00107431
[1110]	training's l2: 0.000865295	valid_1's l2: 0.00107419
[1120]	training's l2: 0.000863929	valid_1's l2: 0.00107404
[1130]	training's l2: 0.000862575	valid_1's l2: 0.00107393
[1140]	training's l2: 0.000861216	valid_1's l2: 0.00107379
[1150]	training's l2: 0.000859862	valid_1's l2: 0.0010737
[1160]	training's l2: 0.000858588	valid_1's l2: 0.00107361
[1170]	training's l2: 0.000857366	valid_1's l2: 0.00107349
[1180]	training's l2: 0.000855976	valid_1's l2: 0.00107332
[1190]	training's l2: 0.000854742	valid_1's l2: 0.00107326
[1200]	training's l2: 0.000853498	valid_1's l2: 0.00107312
[1210]	training's l2: 0.00085219	valid_1's l2: 0.00107305
[1220]	training's l2: 0.000850936	valid_1's l2: 0.00107295
[1230]	training's l2: 0.000849683	valid_1's l2: 0.00107277
[1240]	training's l2: 0.000848385	valid_1's l2: 0.00107268
[1250]	training's l2: 0.000847179	valid_1's l2: 0.0010726
[1260]	training's l2: 0.000845956	valid_1's l2: 0.00107251
[1270]	training's l2: 0.000844724	valid_1's l2: 0.00107242
[1280]	training's l2: 0.000843449	valid_1's l2: 0.00107228
[1290]	training's l2: 0.000842291	valid_1's l2: 0.00107222
[1300]	training's l2: 0.000841102	valid_1's l2: 0.00107219
[1310]	training's l2: 0.000839897	valid_1's l2: 0.00107211
[1320]	training's l2: 0.000838701	valid_1's l2: 0.00107198
[1330]	training's l2: 0.000837546	valid_1's l2: 0.00107193
[1340]	training's l2: 0.000836356	valid_1's l2: 0.00107185
[1350]	training's l2: 0.000835107	valid_1's l2: 0.00107181
[1360]	training's l2: 0.000833986	valid_1's l2: 0.00107173
[1370]	training's l2: 0.000832852	valid_1's l2: 0.00107163
[1380]	training's l2: 0.000831681	valid_1's l2: 0.00107157
[1390]	training's l2: 0.00083053	valid_1's l2: 0.00107151
[1400]	training's l2: 0.000829415	valid_1's l2: 0.00107141
[1410]	training's l2: 0.000828284	valid_1's l2: 0.00107131
[1420]	training's l2: 0.000827189	valid_1's l2: 0.00107123
[1430]	training's l2: 0.000826066	valid_1's l2: 0.00107122
[1440]	training's l2: 0.000824935	valid_1's l2: 0.00107111
[1450]	training's l2: 0.000823846	valid_1's l2: 0.00107104
[1460]	training's l2: 0.000822785	valid_1's l2: 0.00107094
[1470]	training's l2: 0.000821695	valid_1's l2: 0.00107084
[1480]	training's l2: 0.000820616	valid_1's l2: 0.00107075
[1490]	training's l2: 0.000819505	valid_1's l2: 0.00107063
[1500]	training's l2: 0.00081837	valid_1's l2: 0.00107053
[1510]	training's l2: 0.000817355	valid_1's l2: 0.0010705
[1520]	training's l2: 0.000816292	valid_1's l2: 0.00107045
[1530]	training's l2: 0.000815204	valid_1's l2: 0.00107037
[1540]	training's l2: 0.000814124	valid_1's l2: 0.0010703
[1550]	training's l2: 0.000813119	valid_1's l2: 0.00107029
[1560]	training's l2: 0.000812027	valid_1's l2: 0.00107017
[1570]	training's l2: 0.000811004	valid_1's l2: 0.00107015
[1580]	training's l2: 0.000809971	valid_1's l2: 0.00107009
[1590]	training's l2: 0.00080893	valid_1's l2: 0.00107003
[1600]	training's l2: 0.000807926	valid_1's l2: 0.00107
[1610]	training's l2: 0.000806932	valid_1's l2: 0.00107002
[1620]	training's l2: 0.000805869	valid_1's l2: 0.00107
[1630]	training's l2: 0.000804835	valid_1's l2: 0.00106997
[1640]	training's l2: 0.000803812	valid_1's l2: 0.00106992
[1650]	training's l2: 0.000802786	valid_1's l2: 0.0010698
[1660]	training's l2: 0.000801842	valid_1's l2: 0.00106972
[1670]	training's l2: 0.000800783	valid_1's l2: 0.00106967
[1680]	training's l2: 0.000799796	valid_1's l2: 0.00106968
[1690]	training's l2: 0.000798851	valid_1's l2: 0.00106957
[1700]	training's l2: 0.000797892	valid_1's l2: 0.0010696
[1710]	training's l2: 0.00079681	valid_1's l2: 0.00106954
[1720]	training's l2: 0.000795869	valid_1's l2: 0.00106943
[1730]	training's l2: 0.0007948	valid_1's l2: 0.00106931
[1740]	training's l2: 0.000793819	valid_1's l2: 0.00106926
[1750]	training's l2: 0.000792856	valid_1's l2: 0.00106922
[1760]	training's l2: 0.00079189	valid_1's l2: 0.00106915
[1770]	training's l2: 0.000790992	valid_1's l2: 0.00106909
[1780]	training's l2: 0.000789983	valid_1's l2: 0.00106902
[1790]	training's l2: 0.000788993	valid_1's l2: 0.00106891
[1800]	training's l2: 0.000788084	valid_1's l2: 0.00106887
[1810]	training's l2: 0.000787179	valid_1's l2: 0.00106878
[1820]	training's l2: 0.000786313	valid_1's l2: 0.00106875
[1830]	training's l2: 0.000785368	valid_1's l2: 0.00106871
[1840]	training's l2: 0.000784452	valid_1's l2: 0.00106865
[1850]	training's l2: 0.000783548	valid_1's l2: 0.00106861
[1860]	training's l2: 0.000782652	valid_1's l2: 0.00106857
[1870]	training's l2: 0.000781711	valid_1's l2: 0.00106854
[1880]	training's l2: 0.000780871	valid_1's l2: 0.00106848
[1890]	training's l2: 0.000780029	valid_1's l2: 0.00106844
[1900]	training's l2: 0.000779149	valid_1's l2: 0.0010684
[1910]	training's l2: 0.00077829	valid_1's l2: 0.00106836
[1920]	training's l2: 0.000777464	valid_1's l2: 0.00106834
[1930]	training's l2: 0.000776635	valid_1's l2: 0.00106831
[1940]	training's l2: 0.000775825	valid_1's l2: 0.00106825
[1950]	training's l2: 0.000774963	valid_1's l2: 0.00106818
[1960]	training's l2: 0.000774077	valid_1's l2: 0.00106809
[1970]	training's l2: 0.000773242	valid_1's l2: 0.00106807
[1980]	training's l2: 0.000772404	valid_1's l2: 0.00106805
[1990]	training's l2: 0.000771535	valid_1's l2: 0.001068
[2000]	training's l2: 0.000770706	valid_1's l2: 0.00106796
[2010]	training's l2: 0.000769909	valid_1's l2: 0.00106792
[2020]	training's l2: 0.000769089	valid_1's l2: 0.00106792
[2030]	training's l2: 0.000768258	valid_1's l2: 0.00106789
[2040]	training's l2: 0.00076741	valid_1's l2: 0.0010679
[2050]	training's l2: 0.000766614	valid_1's l2: 0.0010679
[2060]	training's l2: 0.000765713	valid_1's l2: 0.00106786
[2070]	training's l2: 0.000764956	valid_1's l2: 0.00106782
[2080]	training's l2: 0.000764154	valid_1's l2: 0.0010678
[2090]	training's l2: 0.000763328	valid_1's l2: 0.00106773
[2100]	training's l2: 0.000762367	valid_1's l2: 0.00106764
[2110]	training's l2: 0.000761565	valid_1's l2: 0.00106763
[2120]	training's l2: 0.000760792	valid_1's l2: 0.00106762
[2130]	training's l2: 0.000759946	valid_1's l2: 0.00106759
[2140]	training's l2: 0.000759063	valid_1's l2: 0.00106756
[2150]	training's l2: 0.000758332	valid_1's l2: 0.00106755
[2160]	training's l2: 0.00075762	valid_1's l2: 0.00106757
[2170]	training's l2: 0.000756907	valid_1's l2: 0.00106757
Early stopping, best iteration is:
[2144]	training's l2: 0.000758779	valid_1's l2: 0.00106754
score1: 1.2281309474972921
