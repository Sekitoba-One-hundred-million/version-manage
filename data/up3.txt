standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:1
start rank:4
start rank:3
start rank:5
start rank:2
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.304591 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 35627
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 194
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151563	valid_1's l2: 0.00157908
[20]	training's l2: 0.00144729	valid_1's l2: 0.00151572
[30]	training's l2: 0.00139012	valid_1's l2: 0.00146258
[40]	training's l2: 0.00134196	valid_1's l2: 0.00141845
[50]	training's l2: 0.00130111	valid_1's l2: 0.00138169
[60]	training's l2: 0.00126662	valid_1's l2: 0.0013508
[70]	training's l2: 0.00123727	valid_1's l2: 0.0013248
[80]	training's l2: 0.00121225	valid_1's l2: 0.00130299
[90]	training's l2: 0.00119071	valid_1's l2: 0.00128431
[100]	training's l2: 0.00117213	valid_1's l2: 0.00126837
[110]	training's l2: 0.00115561	valid_1's l2: 0.00125463
[120]	training's l2: 0.00114103	valid_1's l2: 0.00124286
[130]	training's l2: 0.0011282	valid_1's l2: 0.00123257
[140]	training's l2: 0.00111678	valid_1's l2: 0.00122357
[150]	training's l2: 0.00110663	valid_1's l2: 0.00121599
[160]	training's l2: 0.00109763	valid_1's l2: 0.00120905
[170]	training's l2: 0.00108953	valid_1's l2: 0.00120282
[180]	training's l2: 0.00108204	valid_1's l2: 0.00119723
[190]	training's l2: 0.0010751	valid_1's l2: 0.00119256
[200]	training's l2: 0.0010688	valid_1's l2: 0.0011883
[210]	training's l2: 0.00106304	valid_1's l2: 0.00118443
[220]	training's l2: 0.00105781	valid_1's l2: 0.00118071
[230]	training's l2: 0.00105271	valid_1's l2: 0.0011771
[240]	training's l2: 0.00104799	valid_1's l2: 0.00117397
[250]	training's l2: 0.00104359	valid_1's l2: 0.00117121
[260]	training's l2: 0.00103933	valid_1's l2: 0.00116845
[270]	training's l2: 0.0010353	valid_1's l2: 0.00116587
[280]	training's l2: 0.00103128	valid_1's l2: 0.00116334
[290]	training's l2: 0.00102731	valid_1's l2: 0.00116083
[300]	training's l2: 0.00102362	valid_1's l2: 0.00115874
[310]	training's l2: 0.00102003	valid_1's l2: 0.00115679
[320]	training's l2: 0.00101652	valid_1's l2: 0.00115476
[330]	training's l2: 0.00101354	valid_1's l2: 0.00115307
[340]	training's l2: 0.00101016	valid_1's l2: 0.00115118
[350]	training's l2: 0.001007	valid_1's l2: 0.00114958
[360]	training's l2: 0.00100393	valid_1's l2: 0.00114806
[370]	training's l2: 0.00100076	valid_1's l2: 0.00114636
[380]	training's l2: 0.000998024	valid_1's l2: 0.00114505
[390]	training's l2: 0.000995238	valid_1's l2: 0.00114366
[400]	training's l2: 0.000992343	valid_1's l2: 0.00114224
[410]	training's l2: 0.000989665	valid_1's l2: 0.00114105
[420]	training's l2: 0.000987127	valid_1's l2: 0.00113991
[430]	training's l2: 0.000984691	valid_1's l2: 0.00113886
[440]	training's l2: 0.000982431	valid_1's l2: 0.00113781
[450]	training's l2: 0.000979934	valid_1's l2: 0.00113674
[460]	training's l2: 0.000977352	valid_1's l2: 0.00113566
[470]	training's l2: 0.000974829	valid_1's l2: 0.00113464
[480]	training's l2: 0.000972403	valid_1's l2: 0.00113377
[490]	training's l2: 0.000970014	valid_1's l2: 0.00113289
[500]	training's l2: 0.000967545	valid_1's l2: 0.00113213
[510]	training's l2: 0.000965207	valid_1's l2: 0.00113129
[520]	training's l2: 0.000963006	valid_1's l2: 0.00113062
[530]	training's l2: 0.00096071	valid_1's l2: 0.00112989
[540]	training's l2: 0.000958577	valid_1's l2: 0.00112917
[550]	training's l2: 0.000956385	valid_1's l2: 0.00112854
[560]	training's l2: 0.000954287	valid_1's l2: 0.00112789
[570]	training's l2: 0.000952149	valid_1's l2: 0.00112727
[580]	training's l2: 0.000950098	valid_1's l2: 0.00112662
[590]	training's l2: 0.000948162	valid_1's l2: 0.00112615
[600]	training's l2: 0.000946187	valid_1's l2: 0.00112566
[610]	training's l2: 0.000944127	valid_1's l2: 0.0011251
[620]	training's l2: 0.00094229	valid_1's l2: 0.00112468
[630]	training's l2: 0.000940444	valid_1's l2: 0.0011242
[640]	training's l2: 0.000938478	valid_1's l2: 0.00112367
[650]	training's l2: 0.000936604	valid_1's l2: 0.00112325
[660]	training's l2: 0.00093483	valid_1's l2: 0.00112284
[670]	training's l2: 0.000932954	valid_1's l2: 0.00112244
[680]	training's l2: 0.00093111	valid_1's l2: 0.00112201
[690]	training's l2: 0.00092932	valid_1's l2: 0.00112157
[700]	training's l2: 0.000927459	valid_1's l2: 0.00112117
[710]	training's l2: 0.000925642	valid_1's l2: 0.00112075
[720]	training's l2: 0.000923717	valid_1's l2: 0.00112027
[730]	training's l2: 0.000921923	valid_1's l2: 0.00111989
[740]	training's l2: 0.000920161	valid_1's l2: 0.00111965
[750]	training's l2: 0.000918391	valid_1's l2: 0.00111934
[760]	training's l2: 0.00091669	valid_1's l2: 0.00111903
[770]	training's l2: 0.000915135	valid_1's l2: 0.0011188
[780]	training's l2: 0.000913419	valid_1's l2: 0.00111848
[790]	training's l2: 0.000911777	valid_1's l2: 0.00111823
[800]	training's l2: 0.000910042	valid_1's l2: 0.00111793
[810]	training's l2: 0.000908389	valid_1's l2: 0.00111772
[820]	training's l2: 0.000906862	valid_1's l2: 0.00111742
[830]	training's l2: 0.000905335	valid_1's l2: 0.00111715
[840]	training's l2: 0.000903769	valid_1's l2: 0.0011169
[850]	training's l2: 0.000902286	valid_1's l2: 0.00111672
[860]	training's l2: 0.000900735	valid_1's l2: 0.0011165
[870]	training's l2: 0.000899128	valid_1's l2: 0.00111628
[880]	training's l2: 0.000897614	valid_1's l2: 0.0011161
[890]	training's l2: 0.000896084	valid_1's l2: 0.00111587
[900]	training's l2: 0.000894519	valid_1's l2: 0.0011157
[910]	training's l2: 0.000893088	valid_1's l2: 0.00111551
[920]	training's l2: 0.000891555	valid_1's l2: 0.00111532
[930]	training's l2: 0.000890077	valid_1's l2: 0.00111511
[940]	training's l2: 0.000888607	valid_1's l2: 0.00111498
[950]	training's l2: 0.000887077	valid_1's l2: 0.00111484
[960]	training's l2: 0.000885447	valid_1's l2: 0.00111472
[970]	training's l2: 0.000884068	valid_1's l2: 0.00111453
[980]	training's l2: 0.000882572	valid_1's l2: 0.00111449
[990]	training's l2: 0.000881135	valid_1's l2: 0.00111441
[1000]	training's l2: 0.00087963	valid_1's l2: 0.0011143
[1010]	training's l2: 0.000878243	valid_1's l2: 0.00111423
[1020]	training's l2: 0.000876826	valid_1's l2: 0.00111414
[1030]	training's l2: 0.000875491	valid_1's l2: 0.00111402
[1040]	training's l2: 0.000874068	valid_1's l2: 0.00111391
[1050]	training's l2: 0.000872681	valid_1's l2: 0.00111376
[1060]	training's l2: 0.000871273	valid_1's l2: 0.00111357
[1070]	training's l2: 0.000869867	valid_1's l2: 0.00111345
[1080]	training's l2: 0.000868512	valid_1's l2: 0.00111341
[1090]	training's l2: 0.000867194	valid_1's l2: 0.00111332
[1100]	training's l2: 0.000865804	valid_1's l2: 0.00111314
[1110]	training's l2: 0.000864396	valid_1's l2: 0.00111314
[1120]	training's l2: 0.000863164	valid_1's l2: 0.001113
[1130]	training's l2: 0.000861845	valid_1's l2: 0.00111296
[1140]	training's l2: 0.000860506	valid_1's l2: 0.00111288
[1150]	training's l2: 0.000859192	valid_1's l2: 0.00111273
[1160]	training's l2: 0.000857929	valid_1's l2: 0.00111261
[1170]	training's l2: 0.000856657	valid_1's l2: 0.00111259
[1180]	training's l2: 0.00085532	valid_1's l2: 0.00111258
[1190]	training's l2: 0.000854047	valid_1's l2: 0.00111252
[1200]	training's l2: 0.000852701	valid_1's l2: 0.00111248
[1210]	training's l2: 0.000851377	valid_1's l2: 0.00111243
[1220]	training's l2: 0.000850155	valid_1's l2: 0.00111235
[1230]	training's l2: 0.000848906	valid_1's l2: 0.00111225
[1240]	training's l2: 0.000847638	valid_1's l2: 0.00111212
[1250]	training's l2: 0.000846371	valid_1's l2: 0.00111212
[1260]	training's l2: 0.000845163	valid_1's l2: 0.00111208
[1270]	training's l2: 0.000843908	valid_1's l2: 0.001112
[1280]	training's l2: 0.000842666	valid_1's l2: 0.00111194
[1290]	training's l2: 0.000841499	valid_1's l2: 0.00111189
[1300]	training's l2: 0.000840354	valid_1's l2: 0.00111182
[1310]	training's l2: 0.000839195	valid_1's l2: 0.00111173
[1320]	training's l2: 0.000837955	valid_1's l2: 0.00111171
[1330]	training's l2: 0.000836742	valid_1's l2: 0.00111166
[1340]	training's l2: 0.000835523	valid_1's l2: 0.00111163
[1350]	training's l2: 0.000834317	valid_1's l2: 0.00111161
[1360]	training's l2: 0.000833133	valid_1's l2: 0.00111158
[1370]	training's l2: 0.000831946	valid_1's l2: 0.00111158
[1380]	training's l2: 0.000830801	valid_1's l2: 0.00111154
[1390]	training's l2: 0.000829646	valid_1's l2: 0.00111152
[1400]	training's l2: 0.000828498	valid_1's l2: 0.00111147
[1410]	training's l2: 0.000827348	valid_1's l2: 0.00111143
[1420]	training's l2: 0.000826258	valid_1's l2: 0.00111142
[1430]	training's l2: 0.000825107	valid_1's l2: 0.00111142
[1440]	training's l2: 0.000823975	valid_1's l2: 0.0011114
[1450]	training's l2: 0.000822849	valid_1's l2: 0.0011113
[1460]	training's l2: 0.000821689	valid_1's l2: 0.00111125
[1470]	training's l2: 0.000820548	valid_1's l2: 0.00111129
[1480]	training's l2: 0.000819454	valid_1's l2: 0.0011112
[1490]	training's l2: 0.000818381	valid_1's l2: 0.00111117
[1500]	training's l2: 0.000817282	valid_1's l2: 0.00111115
[1510]	training's l2: 0.000816236	valid_1's l2: 0.00111104
[1520]	training's l2: 0.000815192	valid_1's l2: 0.00111106
[1530]	training's l2: 0.000814099	valid_1's l2: 0.00111105
[1540]	training's l2: 0.000813084	valid_1's l2: 0.00111101
[1550]	training's l2: 0.00081203	valid_1's l2: 0.00111099
[1560]	training's l2: 0.000810971	valid_1's l2: 0.00111105
[1570]	training's l2: 0.000809894	valid_1's l2: 0.00111111
[1580]	training's l2: 0.000808882	valid_1's l2: 0.00111109
Early stopping, best iteration is:
[1550]	training's l2: 0.00081203	valid_1's l2: 0.00111099
score1: 1.2516741660957094
