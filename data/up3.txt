standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:5
start rank:1
start rank:2
start rank:3
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.408205 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 36014
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 193
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151616	valid_1's l2: 0.00158071
[20]	training's l2: 0.00144823	valid_1's l2: 0.00151803
[30]	training's l2: 0.00139158	valid_1's l2: 0.001466
[40]	training's l2: 0.00134386	valid_1's l2: 0.00142272
[50]	training's l2: 0.0013035	valid_1's l2: 0.00138651
[60]	training's l2: 0.00126925	valid_1's l2: 0.00135605
[70]	training's l2: 0.00124005	valid_1's l2: 0.00133014
[80]	training's l2: 0.00121496	valid_1's l2: 0.00130785
[90]	training's l2: 0.00119362	valid_1's l2: 0.00128925
[100]	training's l2: 0.001175	valid_1's l2: 0.00127319
[110]	training's l2: 0.00115889	valid_1's l2: 0.00125946
[120]	training's l2: 0.00114451	valid_1's l2: 0.00124785
[130]	training's l2: 0.00113183	valid_1's l2: 0.00123752
[140]	training's l2: 0.00112048	valid_1's l2: 0.00122842
[150]	training's l2: 0.00111032	valid_1's l2: 0.00122046
[160]	training's l2: 0.0011013	valid_1's l2: 0.00121361
[170]	training's l2: 0.00109325	valid_1's l2: 0.00120745
[180]	training's l2: 0.00108586	valid_1's l2: 0.00120174
[190]	training's l2: 0.00107891	valid_1's l2: 0.00119656
[200]	training's l2: 0.00107266	valid_1's l2: 0.00119223
[210]	training's l2: 0.00106691	valid_1's l2: 0.00118827
[220]	training's l2: 0.00106161	valid_1's l2: 0.00118447
[230]	training's l2: 0.00105657	valid_1's l2: 0.00118091
[240]	training's l2: 0.00105163	valid_1's l2: 0.00117755
[250]	training's l2: 0.00104711	valid_1's l2: 0.00117461
[260]	training's l2: 0.00104289	valid_1's l2: 0.00117191
[270]	training's l2: 0.00103877	valid_1's l2: 0.00116921
[280]	training's l2: 0.00103495	valid_1's l2: 0.00116683
[290]	training's l2: 0.00103106	valid_1's l2: 0.00116433
[300]	training's l2: 0.0010272	valid_1's l2: 0.00116201
[310]	training's l2: 0.00102368	valid_1's l2: 0.00115997
[320]	training's l2: 0.0010203	valid_1's l2: 0.001158
[330]	training's l2: 0.0010172	valid_1's l2: 0.00115637
[340]	training's l2: 0.00101425	valid_1's l2: 0.00115486
[350]	training's l2: 0.00101113	valid_1's l2: 0.00115317
[360]	training's l2: 0.00100805	valid_1's l2: 0.00115151
[370]	training's l2: 0.00100502	valid_1's l2: 0.00114993
[380]	training's l2: 0.00100223	valid_1's l2: 0.00114852
[390]	training's l2: 0.000999361	valid_1's l2: 0.0011471
[400]	training's l2: 0.000996471	valid_1's l2: 0.00114583
[410]	training's l2: 0.000993851	valid_1's l2: 0.00114463
[420]	training's l2: 0.000991089	valid_1's l2: 0.00114331
[430]	training's l2: 0.000988639	valid_1's l2: 0.00114226
[440]	training's l2: 0.000986191	valid_1's l2: 0.00114123
[450]	training's l2: 0.000983529	valid_1's l2: 0.00114009
[460]	training's l2: 0.000981096	valid_1's l2: 0.00113915
[470]	training's l2: 0.000978826	valid_1's l2: 0.00113829
[480]	training's l2: 0.000976357	valid_1's l2: 0.00113735
[490]	training's l2: 0.000973958	valid_1's l2: 0.0011364
[500]	training's l2: 0.000971443	valid_1's l2: 0.0011355
[510]	training's l2: 0.000969094	valid_1's l2: 0.00113474
[520]	training's l2: 0.000966723	valid_1's l2: 0.00113398
[530]	training's l2: 0.000964441	valid_1's l2: 0.00113338
[540]	training's l2: 0.000962274	valid_1's l2: 0.00113271
[550]	training's l2: 0.0009602	valid_1's l2: 0.00113219
[560]	training's l2: 0.000957964	valid_1's l2: 0.00113154
[570]	training's l2: 0.000955966	valid_1's l2: 0.001131
[580]	training's l2: 0.000953918	valid_1's l2: 0.00113056
[590]	training's l2: 0.000951902	valid_1's l2: 0.00112999
[600]	training's l2: 0.0009499	valid_1's l2: 0.00112949
[610]	training's l2: 0.000947991	valid_1's l2: 0.00112896
[620]	training's l2: 0.000946067	valid_1's l2: 0.00112851
[630]	training's l2: 0.000944198	valid_1's l2: 0.00112815
[640]	training's l2: 0.000942206	valid_1's l2: 0.00112768
[650]	training's l2: 0.00094035	valid_1's l2: 0.0011273
[660]	training's l2: 0.000938401	valid_1's l2: 0.00112685
[670]	training's l2: 0.000936525	valid_1's l2: 0.00112645
[680]	training's l2: 0.0009347	valid_1's l2: 0.00112597
[690]	training's l2: 0.000932893	valid_1's l2: 0.0011255
[700]	training's l2: 0.000931074	valid_1's l2: 0.00112505
[710]	training's l2: 0.000929308	valid_1's l2: 0.0011247
[720]	training's l2: 0.00092748	valid_1's l2: 0.00112441
[730]	training's l2: 0.000925664	valid_1's l2: 0.00112403
[740]	training's l2: 0.000923895	valid_1's l2: 0.00112376
[750]	training's l2: 0.000922181	valid_1's l2: 0.00112344
[760]	training's l2: 0.000920575	valid_1's l2: 0.00112316
[770]	training's l2: 0.00091892	valid_1's l2: 0.00112283
[780]	training's l2: 0.000917254	valid_1's l2: 0.00112254
[790]	training's l2: 0.000915613	valid_1's l2: 0.00112239
[800]	training's l2: 0.000913971	valid_1's l2: 0.00112212
[810]	training's l2: 0.0009124	valid_1's l2: 0.00112189
[820]	training's l2: 0.00091072	valid_1's l2: 0.00112155
[830]	training's l2: 0.000909215	valid_1's l2: 0.00112129
[840]	training's l2: 0.000907636	valid_1's l2: 0.00112104
[850]	training's l2: 0.000905991	valid_1's l2: 0.00112075
[860]	training's l2: 0.000904455	valid_1's l2: 0.00112054
[870]	training's l2: 0.000902787	valid_1's l2: 0.00112024
[880]	training's l2: 0.000901285	valid_1's l2: 0.00112004
[890]	training's l2: 0.000899822	valid_1's l2: 0.00111991
[900]	training's l2: 0.000898171	valid_1's l2: 0.00111969
[910]	training's l2: 0.000896759	valid_1's l2: 0.00111951
[920]	training's l2: 0.000895234	valid_1's l2: 0.00111927
[930]	training's l2: 0.000893766	valid_1's l2: 0.00111902
[940]	training's l2: 0.000892336	valid_1's l2: 0.00111892
[950]	training's l2: 0.000890958	valid_1's l2: 0.00111863
[960]	training's l2: 0.000889508	valid_1's l2: 0.00111852
[970]	training's l2: 0.0008881	valid_1's l2: 0.0011185
[980]	training's l2: 0.000886661	valid_1's l2: 0.00111833
[990]	training's l2: 0.000885274	valid_1's l2: 0.0011182
[1000]	training's l2: 0.000883837	valid_1's l2: 0.00111812
[1010]	training's l2: 0.000882429	valid_1's l2: 0.00111796
[1020]	training's l2: 0.000881003	valid_1's l2: 0.00111781
[1030]	training's l2: 0.000879636	valid_1's l2: 0.00111768
[1040]	training's l2: 0.000878188	valid_1's l2: 0.00111753
[1050]	training's l2: 0.000876861	valid_1's l2: 0.00111744
[1060]	training's l2: 0.000875418	valid_1's l2: 0.00111729
[1070]	training's l2: 0.00087406	valid_1's l2: 0.00111719
[1080]	training's l2: 0.000872673	valid_1's l2: 0.00111702
[1090]	training's l2: 0.000871279	valid_1's l2: 0.00111696
[1100]	training's l2: 0.000869939	valid_1's l2: 0.00111691
[1110]	training's l2: 0.000868596	valid_1's l2: 0.00111675
[1120]	training's l2: 0.000867266	valid_1's l2: 0.00111662
[1130]	training's l2: 0.000865911	valid_1's l2: 0.00111656
[1140]	training's l2: 0.000864578	valid_1's l2: 0.0011165
[1150]	training's l2: 0.000863306	valid_1's l2: 0.00111644
[1160]	training's l2: 0.000861981	valid_1's l2: 0.00111638
[1170]	training's l2: 0.000860647	valid_1's l2: 0.00111635
[1180]	training's l2: 0.000859397	valid_1's l2: 0.00111621
[1190]	training's l2: 0.000858146	valid_1's l2: 0.00111617
[1200]	training's l2: 0.000856899	valid_1's l2: 0.00111611
[1210]	training's l2: 0.000855652	valid_1's l2: 0.00111604
[1220]	training's l2: 0.000854409	valid_1's l2: 0.00111603
[1230]	training's l2: 0.000853109	valid_1's l2: 0.00111595
[1240]	training's l2: 0.000851856	valid_1's l2: 0.00111589
[1250]	training's l2: 0.00085059	valid_1's l2: 0.00111579
[1260]	training's l2: 0.000849367	valid_1's l2: 0.00111576
[1270]	training's l2: 0.000848135	valid_1's l2: 0.0011157
[1280]	training's l2: 0.000846914	valid_1's l2: 0.00111561
[1290]	training's l2: 0.000845688	valid_1's l2: 0.0011156
[1300]	training's l2: 0.00084444	valid_1's l2: 0.0011155
[1310]	training's l2: 0.000843244	valid_1's l2: 0.00111549
[1320]	training's l2: 0.000841999	valid_1's l2: 0.00111551
[1330]	training's l2: 0.000840837	valid_1's l2: 0.0011155
Early stopping, best iteration is:
[1307]	training's l2: 0.000843632	valid_1's l2: 0.00111546
score1: 1.2533236707221744
