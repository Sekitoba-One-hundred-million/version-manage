standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:3
start rank:5
start rank:2
start rank:1
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.398936 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 39761
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 213
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151615	valid_1's l2: 0.00158071
[20]	training's l2: 0.00144824	valid_1's l2: 0.00151803
[30]	training's l2: 0.00139155	valid_1's l2: 0.00146601
[40]	training's l2: 0.00134388	valid_1's l2: 0.00142267
[50]	training's l2: 0.00130346	valid_1's l2: 0.00138647
[60]	training's l2: 0.00126926	valid_1's l2: 0.00135612
[70]	training's l2: 0.00124006	valid_1's l2: 0.0013302
[80]	training's l2: 0.00121504	valid_1's l2: 0.00130795
[90]	training's l2: 0.00119349	valid_1's l2: 0.00128913
[100]	training's l2: 0.00117489	valid_1's l2: 0.00127306
[110]	training's l2: 0.00115882	valid_1's l2: 0.00125956
[120]	training's l2: 0.00114445	valid_1's l2: 0.00124779
[130]	training's l2: 0.00113174	valid_1's l2: 0.00123746
[140]	training's l2: 0.00112042	valid_1's l2: 0.00122852
[150]	training's l2: 0.00111023	valid_1's l2: 0.00122062
[160]	training's l2: 0.00110116	valid_1's l2: 0.00121357
[170]	training's l2: 0.00109316	valid_1's l2: 0.00120745
[180]	training's l2: 0.00108561	valid_1's l2: 0.00120173
[190]	training's l2: 0.00107862	valid_1's l2: 0.00119665
[200]	training's l2: 0.00107235	valid_1's l2: 0.00119234
[210]	training's l2: 0.00106663	valid_1's l2: 0.00118831
[220]	training's l2: 0.00106135	valid_1's l2: 0.00118451
[230]	training's l2: 0.00105626	valid_1's l2: 0.00118106
[240]	training's l2: 0.00105142	valid_1's l2: 0.00117768
[250]	training's l2: 0.00104684	valid_1's l2: 0.00117468
[260]	training's l2: 0.00104254	valid_1's l2: 0.00117199
[270]	training's l2: 0.00103846	valid_1's l2: 0.00116941
[280]	training's l2: 0.00103462	valid_1's l2: 0.001167
[290]	training's l2: 0.00103064	valid_1's l2: 0.00116445
[300]	training's l2: 0.00102687	valid_1's l2: 0.00116218
[310]	training's l2: 0.00102332	valid_1's l2: 0.00116005
[320]	training's l2: 0.00102	valid_1's l2: 0.00115829
[330]	training's l2: 0.00101687	valid_1's l2: 0.00115664
[340]	training's l2: 0.00101396	valid_1's l2: 0.00115511
[350]	training's l2: 0.00101075	valid_1's l2: 0.00115339
[360]	training's l2: 0.00100764	valid_1's l2: 0.00115171
[370]	training's l2: 0.0010047	valid_1's l2: 0.00115013
[380]	training's l2: 0.00100152	valid_1's l2: 0.00114842
[390]	training's l2: 0.000998719	valid_1's l2: 0.00114708
[400]	training's l2: 0.000995903	valid_1's l2: 0.00114583
[410]	training's l2: 0.000993253	valid_1's l2: 0.00114473
[420]	training's l2: 0.000990673	valid_1's l2: 0.00114365
[430]	training's l2: 0.000987985	valid_1's l2: 0.00114237
[440]	training's l2: 0.000985567	valid_1's l2: 0.0011413
[450]	training's l2: 0.000983084	valid_1's l2: 0.00114019
[460]	training's l2: 0.000980588	valid_1's l2: 0.00113921
[470]	training's l2: 0.000978177	valid_1's l2: 0.00113824
[480]	training's l2: 0.000975578	valid_1's l2: 0.0011372
[490]	training's l2: 0.000973268	valid_1's l2: 0.00113636
[500]	training's l2: 0.00097088	valid_1's l2: 0.00113553
[510]	training's l2: 0.000968529	valid_1's l2: 0.00113476
[520]	training's l2: 0.00096617	valid_1's l2: 0.00113418
[530]	training's l2: 0.000963809	valid_1's l2: 0.00113332
[540]	training's l2: 0.000961671	valid_1's l2: 0.0011327
[550]	training's l2: 0.000959537	valid_1's l2: 0.00113213
[560]	training's l2: 0.000957325	valid_1's l2: 0.00113155
[570]	training's l2: 0.00095528	valid_1's l2: 0.00113096
[580]	training's l2: 0.00095331	valid_1's l2: 0.0011305
[590]	training's l2: 0.000951383	valid_1's l2: 0.00113003
[600]	training's l2: 0.000949364	valid_1's l2: 0.00112954
[610]	training's l2: 0.000947281	valid_1's l2: 0.00112904
[620]	training's l2: 0.000945356	valid_1's l2: 0.0011286
[630]	training's l2: 0.000943457	valid_1's l2: 0.00112819
[640]	training's l2: 0.00094148	valid_1's l2: 0.00112782
[650]	training's l2: 0.000939419	valid_1's l2: 0.0011273
[660]	training's l2: 0.000937544	valid_1's l2: 0.00112676
[670]	training's l2: 0.000935697	valid_1's l2: 0.00112645
[680]	training's l2: 0.000933821	valid_1's l2: 0.00112601
[690]	training's l2: 0.000931946	valid_1's l2: 0.00112559
[700]	training's l2: 0.000930283	valid_1's l2: 0.00112532
[710]	training's l2: 0.000928398	valid_1's l2: 0.00112489
[720]	training's l2: 0.000926456	valid_1's l2: 0.00112445
[730]	training's l2: 0.000924739	valid_1's l2: 0.00112414
[740]	training's l2: 0.000923121	valid_1's l2: 0.00112384
[750]	training's l2: 0.000921224	valid_1's l2: 0.00112341
[760]	training's l2: 0.000919536	valid_1's l2: 0.00112313
[770]	training's l2: 0.000917915	valid_1's l2: 0.00112296
[780]	training's l2: 0.000916222	valid_1's l2: 0.00112265
[790]	training's l2: 0.000914579	valid_1's l2: 0.00112243
[800]	training's l2: 0.000912858	valid_1's l2: 0.00112214
[810]	training's l2: 0.00091123	valid_1's l2: 0.00112195
[820]	training's l2: 0.000909509	valid_1's l2: 0.00112177
[830]	training's l2: 0.000907864	valid_1's l2: 0.00112148
[840]	training's l2: 0.000906244	valid_1's l2: 0.00112124
[850]	training's l2: 0.000904749	valid_1's l2: 0.00112102
[860]	training's l2: 0.00090323	valid_1's l2: 0.00112084
[870]	training's l2: 0.000901592	valid_1's l2: 0.00112058
[880]	training's l2: 0.000900047	valid_1's l2: 0.00112036
[890]	training's l2: 0.000898502	valid_1's l2: 0.00112014
[900]	training's l2: 0.000896969	valid_1's l2: 0.00111992
[910]	training's l2: 0.000895432	valid_1's l2: 0.00111977
[920]	training's l2: 0.000893942	valid_1's l2: 0.00111962
[930]	training's l2: 0.000892367	valid_1's l2: 0.00111938
[940]	training's l2: 0.00089092	valid_1's l2: 0.00111927
[950]	training's l2: 0.000889417	valid_1's l2: 0.00111907
[960]	training's l2: 0.000887994	valid_1's l2: 0.00111895
[970]	training's l2: 0.000886524	valid_1's l2: 0.00111884
[980]	training's l2: 0.000885079	valid_1's l2: 0.0011187
[990]	training's l2: 0.000883634	valid_1's l2: 0.00111851
[1000]	training's l2: 0.000882232	valid_1's l2: 0.00111836
[1010]	training's l2: 0.000880886	valid_1's l2: 0.00111816
[1020]	training's l2: 0.000879394	valid_1's l2: 0.00111806
[1030]	training's l2: 0.000878048	valid_1's l2: 0.00111795
[1040]	training's l2: 0.00087666	valid_1's l2: 0.00111777
[1050]	training's l2: 0.000875231	valid_1's l2: 0.0011176
[1060]	training's l2: 0.000873853	valid_1's l2: 0.00111739
[1070]	training's l2: 0.000872427	valid_1's l2: 0.00111725
[1080]	training's l2: 0.000871059	valid_1's l2: 0.00111707
[1090]	training's l2: 0.000869757	valid_1's l2: 0.00111701
[1100]	training's l2: 0.00086831	valid_1's l2: 0.00111683
[1110]	training's l2: 0.00086695	valid_1's l2: 0.00111671
[1120]	training's l2: 0.000865604	valid_1's l2: 0.00111656
[1130]	training's l2: 0.000864274	valid_1's l2: 0.00111651
[1140]	training's l2: 0.000862905	valid_1's l2: 0.00111649
[1150]	training's l2: 0.000861614	valid_1's l2: 0.00111638
[1160]	training's l2: 0.00086027	valid_1's l2: 0.00111625
[1170]	training's l2: 0.000858957	valid_1's l2: 0.00111621
[1180]	training's l2: 0.000857652	valid_1's l2: 0.00111616
[1190]	training's l2: 0.000856351	valid_1's l2: 0.00111608
[1200]	training's l2: 0.000855094	valid_1's l2: 0.001116
[1210]	training's l2: 0.00085382	valid_1's l2: 0.00111597
[1220]	training's l2: 0.00085252	valid_1's l2: 0.00111588
[1230]	training's l2: 0.000851261	valid_1's l2: 0.00111583
[1240]	training's l2: 0.000850006	valid_1's l2: 0.00111576
[1250]	training's l2: 0.000848747	valid_1's l2: 0.00111571
[1260]	training's l2: 0.000847524	valid_1's l2: 0.00111562
[1270]	training's l2: 0.000846275	valid_1's l2: 0.00111557
[1280]	training's l2: 0.000845031	valid_1's l2: 0.00111553
[1290]	training's l2: 0.000843831	valid_1's l2: 0.00111549
[1300]	training's l2: 0.000842566	valid_1's l2: 0.00111547
[1310]	training's l2: 0.000841385	valid_1's l2: 0.00111537
[1320]	training's l2: 0.000840101	valid_1's l2: 0.00111531
[1330]	training's l2: 0.00083891	valid_1's l2: 0.00111527
[1340]	training's l2: 0.000837709	valid_1's l2: 0.00111523
[1350]	training's l2: 0.000836487	valid_1's l2: 0.00111516
[1360]	training's l2: 0.000835307	valid_1's l2: 0.00111505
[1370]	training's l2: 0.000834181	valid_1's l2: 0.00111497
[1380]	training's l2: 0.000832993	valid_1's l2: 0.00111489
[1390]	training's l2: 0.000831852	valid_1's l2: 0.00111484
[1400]	training's l2: 0.000830704	valid_1's l2: 0.00111473
[1410]	training's l2: 0.000829606	valid_1's l2: 0.0011147
[1420]	training's l2: 0.000828479	valid_1's l2: 0.00111466
[1430]	training's l2: 0.000827334	valid_1's l2: 0.00111458
[1440]	training's l2: 0.000826121	valid_1's l2: 0.00111454
[1450]	training's l2: 0.000824969	valid_1's l2: 0.00111454
[1460]	training's l2: 0.000823784	valid_1's l2: 0.00111445
[1470]	training's l2: 0.000822677	valid_1's l2: 0.00111444
[1480]	training's l2: 0.000821509	valid_1's l2: 0.00111448
[1490]	training's l2: 0.000820391	valid_1's l2: 0.00111443
Early stopping, best iteration is:
[1463]	training's l2: 0.000823456	valid_1's l2: 0.00111443
score1: 1.2527587966596208
