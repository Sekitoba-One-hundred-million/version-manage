standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:5
start rank:2
start rank:4
start rank:3
start rank:1
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.450369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 35882
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 195
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151563	valid_1's l2: 0.00157908
[20]	training's l2: 0.00144729	valid_1's l2: 0.00151572
[30]	training's l2: 0.00139012	valid_1's l2: 0.00146258
[40]	training's l2: 0.00134196	valid_1's l2: 0.00141845
[50]	training's l2: 0.00130111	valid_1's l2: 0.00138169
[60]	training's l2: 0.00126662	valid_1's l2: 0.0013508
[70]	training's l2: 0.00123727	valid_1's l2: 0.0013248
[80]	training's l2: 0.00121224	valid_1's l2: 0.00130299
[90]	training's l2: 0.0011907	valid_1's l2: 0.00128433
[100]	training's l2: 0.00117206	valid_1's l2: 0.00126829
[110]	training's l2: 0.00115564	valid_1's l2: 0.00125473
[120]	training's l2: 0.00114113	valid_1's l2: 0.00124302
[130]	training's l2: 0.00112822	valid_1's l2: 0.00123254
[140]	training's l2: 0.00111677	valid_1's l2: 0.0012236
[150]	training's l2: 0.00110666	valid_1's l2: 0.0012158
[160]	training's l2: 0.00109777	valid_1's l2: 0.00120903
[170]	training's l2: 0.00108962	valid_1's l2: 0.00120286
[180]	training's l2: 0.00108218	valid_1's l2: 0.00119727
[190]	training's l2: 0.00107528	valid_1's l2: 0.0011925
[200]	training's l2: 0.00106893	valid_1's l2: 0.00118832
[210]	training's l2: 0.00106313	valid_1's l2: 0.00118433
[220]	training's l2: 0.00105777	valid_1's l2: 0.00118053
[230]	training's l2: 0.00105272	valid_1's l2: 0.00117703
[240]	training's l2: 0.00104808	valid_1's l2: 0.00117395
[250]	training's l2: 0.00104365	valid_1's l2: 0.00117107
[260]	training's l2: 0.00103935	valid_1's l2: 0.00116828
[270]	training's l2: 0.00103531	valid_1's l2: 0.00116576
[280]	training's l2: 0.00103115	valid_1's l2: 0.00116304
[290]	training's l2: 0.00102716	valid_1's l2: 0.00116061
[300]	training's l2: 0.00102348	valid_1's l2: 0.00115856
[310]	training's l2: 0.00101996	valid_1's l2: 0.00115666
[320]	training's l2: 0.00101651	valid_1's l2: 0.00115484
[330]	training's l2: 0.0010133	valid_1's l2: 0.00115312
[340]	training's l2: 0.00101009	valid_1's l2: 0.00115121
[350]	training's l2: 0.00100687	valid_1's l2: 0.00114944
[360]	training's l2: 0.00100378	valid_1's l2: 0.00114797
[370]	training's l2: 0.00100079	valid_1's l2: 0.00114651
[380]	training's l2: 0.00099782	valid_1's l2: 0.00114513
[390]	training's l2: 0.000995011	valid_1's l2: 0.00114371
[400]	training's l2: 0.00099214	valid_1's l2: 0.0011424
[410]	training's l2: 0.000989461	valid_1's l2: 0.00114118
[420]	training's l2: 0.00098698	valid_1's l2: 0.00113999
[430]	training's l2: 0.000984586	valid_1's l2: 0.00113896
[440]	training's l2: 0.000982277	valid_1's l2: 0.00113796
[450]	training's l2: 0.00097964	valid_1's l2: 0.00113684
[460]	training's l2: 0.00097709	valid_1's l2: 0.00113582
[470]	training's l2: 0.000974717	valid_1's l2: 0.00113486
[480]	training's l2: 0.000972119	valid_1's l2: 0.00113386
[490]	training's l2: 0.000969864	valid_1's l2: 0.00113309
[500]	training's l2: 0.000967416	valid_1's l2: 0.0011323
[510]	training's l2: 0.0009651	valid_1's l2: 0.00113154
[520]	training's l2: 0.000962926	valid_1's l2: 0.00113086
[530]	training's l2: 0.00096072	valid_1's l2: 0.00113023
[540]	training's l2: 0.000958564	valid_1's l2: 0.00112961
[550]	training's l2: 0.000956396	valid_1's l2: 0.00112894
[560]	training's l2: 0.000954357	valid_1's l2: 0.00112826
[570]	training's l2: 0.000952373	valid_1's l2: 0.00112771
[580]	training's l2: 0.000950139	valid_1's l2: 0.00112704
[590]	training's l2: 0.000948096	valid_1's l2: 0.00112646
[600]	training's l2: 0.000946157	valid_1's l2: 0.00112595
[610]	training's l2: 0.000944113	valid_1's l2: 0.00112541
[620]	training's l2: 0.000942199	valid_1's l2: 0.00112495
[630]	training's l2: 0.000940328	valid_1's l2: 0.00112451
[640]	training's l2: 0.000938521	valid_1's l2: 0.00112408
[650]	training's l2: 0.000936708	valid_1's l2: 0.00112364
[660]	training's l2: 0.000934694	valid_1's l2: 0.0011232
[670]	training's l2: 0.000932875	valid_1's l2: 0.00112275
[680]	training's l2: 0.000931056	valid_1's l2: 0.00112236
[690]	training's l2: 0.000929282	valid_1's l2: 0.00112193
[700]	training's l2: 0.000927342	valid_1's l2: 0.0011214
[710]	training's l2: 0.000925571	valid_1's l2: 0.00112102
[720]	training's l2: 0.000923804	valid_1's l2: 0.00112065
[730]	training's l2: 0.000922051	valid_1's l2: 0.0011203
[740]	training's l2: 0.000920246	valid_1's l2: 0.00111992
[750]	training's l2: 0.000918471	valid_1's l2: 0.00111964
[760]	training's l2: 0.000916777	valid_1's l2: 0.0011193
[770]	training's l2: 0.000915135	valid_1's l2: 0.00111902
[780]	training's l2: 0.000913481	valid_1's l2: 0.00111867
[790]	training's l2: 0.000911782	valid_1's l2: 0.00111844
[800]	training's l2: 0.000910132	valid_1's l2: 0.0011182
[810]	training's l2: 0.000908507	valid_1's l2: 0.00111797
[820]	training's l2: 0.000906963	valid_1's l2: 0.00111765
[830]	training's l2: 0.00090533	valid_1's l2: 0.00111744
[840]	training's l2: 0.000903746	valid_1's l2: 0.0011172
[850]	training's l2: 0.000902261	valid_1's l2: 0.00111695
[860]	training's l2: 0.000900655	valid_1's l2: 0.00111669
[870]	training's l2: 0.000898991	valid_1's l2: 0.00111649
[880]	training's l2: 0.000897424	valid_1's l2: 0.00111626
[890]	training's l2: 0.000895895	valid_1's l2: 0.00111613
[900]	training's l2: 0.000894356	valid_1's l2: 0.00111592
[910]	training's l2: 0.000892788	valid_1's l2: 0.00111574
[920]	training's l2: 0.000891278	valid_1's l2: 0.00111555
[930]	training's l2: 0.000889789	valid_1's l2: 0.00111542
[940]	training's l2: 0.000888279	valid_1's l2: 0.00111519
[950]	training's l2: 0.000886812	valid_1's l2: 0.00111505
[960]	training's l2: 0.000885335	valid_1's l2: 0.00111487
[970]	training's l2: 0.000883917	valid_1's l2: 0.00111474
[980]	training's l2: 0.000882429	valid_1's l2: 0.00111462
[990]	training's l2: 0.000881015	valid_1's l2: 0.00111438
[1000]	training's l2: 0.000879625	valid_1's l2: 0.00111422
[1010]	training's l2: 0.000878083	valid_1's l2: 0.00111404
[1020]	training's l2: 0.000876651	valid_1's l2: 0.00111398
[1030]	training's l2: 0.000875288	valid_1's l2: 0.00111396
[1040]	training's l2: 0.000873923	valid_1's l2: 0.00111387
[1050]	training's l2: 0.000872563	valid_1's l2: 0.00111376
[1060]	training's l2: 0.0008712	valid_1's l2: 0.00111371
[1070]	training's l2: 0.000869863	valid_1's l2: 0.0011136
[1080]	training's l2: 0.000868487	valid_1's l2: 0.00111354
[1090]	training's l2: 0.000867154	valid_1's l2: 0.00111342
[1100]	training's l2: 0.000865703	valid_1's l2: 0.00111336
[1110]	training's l2: 0.000864372	valid_1's l2: 0.0011133
[1120]	training's l2: 0.000862919	valid_1's l2: 0.00111321
[1130]	training's l2: 0.000861601	valid_1's l2: 0.0011131
[1140]	training's l2: 0.000860298	valid_1's l2: 0.00111302
[1150]	training's l2: 0.000858956	valid_1's l2: 0.001113
[1160]	training's l2: 0.000857691	valid_1's l2: 0.00111292
[1170]	training's l2: 0.000856394	valid_1's l2: 0.00111289
[1180]	training's l2: 0.000855135	valid_1's l2: 0.00111283
[1190]	training's l2: 0.000853798	valid_1's l2: 0.00111277
[1200]	training's l2: 0.000852507	valid_1's l2: 0.00111277
[1210]	training's l2: 0.00085125	valid_1's l2: 0.00111264
[1220]	training's l2: 0.000850009	valid_1's l2: 0.00111258
[1230]	training's l2: 0.000848755	valid_1's l2: 0.00111248
[1240]	training's l2: 0.000847533	valid_1's l2: 0.00111243
[1250]	training's l2: 0.000846228	valid_1's l2: 0.00111239
[1260]	training's l2: 0.000845051	valid_1's l2: 0.00111236
[1270]	training's l2: 0.000843787	valid_1's l2: 0.00111236
[1280]	training's l2: 0.000842599	valid_1's l2: 0.00111231
[1290]	training's l2: 0.000841417	valid_1's l2: 0.00111224
[1300]	training's l2: 0.000840222	valid_1's l2: 0.0011123
[1310]	training's l2: 0.000839027	valid_1's l2: 0.00111219
[1320]	training's l2: 0.000837857	valid_1's l2: 0.00111217
[1330]	training's l2: 0.000836583	valid_1's l2: 0.00111215
[1340]	training's l2: 0.000835454	valid_1's l2: 0.00111213
[1350]	training's l2: 0.000834274	valid_1's l2: 0.00111208
[1360]	training's l2: 0.000833112	valid_1's l2: 0.00111203
[1370]	training's l2: 0.000831975	valid_1's l2: 0.00111196
[1380]	training's l2: 0.000830775	valid_1's l2: 0.00111194
[1390]	training's l2: 0.000829635	valid_1's l2: 0.00111187
[1400]	training's l2: 0.000828503	valid_1's l2: 0.00111184
[1410]	training's l2: 0.000827421	valid_1's l2: 0.0011118
[1420]	training's l2: 0.000826327	valid_1's l2: 0.00111178
[1430]	training's l2: 0.000825175	valid_1's l2: 0.00111166
[1440]	training's l2: 0.000824092	valid_1's l2: 0.00111164
[1450]	training's l2: 0.000822995	valid_1's l2: 0.00111162
[1460]	training's l2: 0.000821907	valid_1's l2: 0.00111163
[1470]	training's l2: 0.000820834	valid_1's l2: 0.00111159
[1480]	training's l2: 0.000819734	valid_1's l2: 0.00111157
[1490]	training's l2: 0.000818712	valid_1's l2: 0.00111148
[1500]	training's l2: 0.000817492	valid_1's l2: 0.00111143
[1510]	training's l2: 0.000816456	valid_1's l2: 0.00111141
[1520]	training's l2: 0.000815372	valid_1's l2: 0.00111136
[1530]	training's l2: 0.000814309	valid_1's l2: 0.00111135
[1540]	training's l2: 0.000813204	valid_1's l2: 0.00111133
[1550]	training's l2: 0.000812184	valid_1's l2: 0.00111124
[1560]	training's l2: 0.000811135	valid_1's l2: 0.00111123
[1570]	training's l2: 0.000810108	valid_1's l2: 0.0011112
[1580]	training's l2: 0.000809037	valid_1's l2: 0.00111118
[1590]	training's l2: 0.00080804	valid_1's l2: 0.00111115
[1600]	training's l2: 0.000806952	valid_1's l2: 0.00111111
[1610]	training's l2: 0.000805884	valid_1's l2: 0.00111105
[1620]	training's l2: 0.000804807	valid_1's l2: 0.00111108
[1630]	training's l2: 0.000803785	valid_1's l2: 0.00111101
[1640]	training's l2: 0.000802788	valid_1's l2: 0.00111098
[1650]	training's l2: 0.000801754	valid_1's l2: 0.00111096
[1660]	training's l2: 0.000800821	valid_1's l2: 0.00111094
[1670]	training's l2: 0.000799783	valid_1's l2: 0.00111094
[1680]	training's l2: 0.000798816	valid_1's l2: 0.00111092
[1690]	training's l2: 0.000797846	valid_1's l2: 0.00111089
[1700]	training's l2: 0.000796809	valid_1's l2: 0.00111091
[1710]	training's l2: 0.000795833	valid_1's l2: 0.00111091
[1720]	training's l2: 0.000794931	valid_1's l2: 0.00111089
[1730]	training's l2: 0.000793913	valid_1's l2: 0.00111081
[1740]	training's l2: 0.000792924	valid_1's l2: 0.00111081
[1750]	training's l2: 0.000791991	valid_1's l2: 0.00111078
[1760]	training's l2: 0.000791124	valid_1's l2: 0.00111074
[1770]	training's l2: 0.000790151	valid_1's l2: 0.00111075
[1780]	training's l2: 0.000789295	valid_1's l2: 0.0011108
[1790]	training's l2: 0.000788395	valid_1's l2: 0.00111077
Early stopping, best iteration is:
[1768]	training's l2: 0.000790351	valid_1's l2: 0.00111072
score1: 1.251492940941105
