race_money_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
predict_last_passing_rank.pickle download finish Gilgamesh
start rank:3
start rank:2
start rank:1
start rank:4
start rank:5
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.427304 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 42017
[LightGBM] [Info] Number of data points in the train set: 570293, number of used features: 236
[LightGBM] [Info] Start training from score 37.090952
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 3.45449	valid_1's l2: 3.61848
[20]	training's l2: 2.68357	valid_1's l2: 2.8167
[30]	training's l2: 2.21255	valid_1's l2: 2.3334
[40]	training's l2: 1.91958	valid_1's l2: 2.03746
[50]	training's l2: 1.73085	valid_1's l2: 1.85535
[60]	training's l2: 1.60762	valid_1's l2: 1.73953
[70]	training's l2: 1.52323	valid_1's l2: 1.66398
[80]	training's l2: 1.46431	valid_1's l2: 1.6141
[90]	training's l2: 1.42138	valid_1's l2: 1.57988
[100]	training's l2: 1.38901	valid_1's l2: 1.55503
[110]	training's l2: 1.36349	valid_1's l2: 1.5382
[120]	training's l2: 1.34304	valid_1's l2: 1.52604
[130]	training's l2: 1.32503	valid_1's l2: 1.51594
[140]	training's l2: 1.30851	valid_1's l2: 1.50699
[150]	training's l2: 1.29544	valid_1's l2: 1.501
[160]	training's l2: 1.28347	valid_1's l2: 1.49664
[170]	training's l2: 1.27259	valid_1's l2: 1.49314
[180]	training's l2: 1.26253	valid_1's l2: 1.49019
[190]	training's l2: 1.25383	valid_1's l2: 1.48764
[200]	training's l2: 1.24583	valid_1's l2: 1.4853
[210]	training's l2: 1.23704	valid_1's l2: 1.48337
[220]	training's l2: 1.22929	valid_1's l2: 1.48125
[230]	training's l2: 1.22197	valid_1's l2: 1.47944
[240]	training's l2: 1.21489	valid_1's l2: 1.47792
[250]	training's l2: 1.20817	valid_1's l2: 1.47639
[260]	training's l2: 1.20193	valid_1's l2: 1.47474
[270]	training's l2: 1.19568	valid_1's l2: 1.47368
[280]	training's l2: 1.18979	valid_1's l2: 1.47255
[290]	training's l2: 1.18346	valid_1's l2: 1.47194
[300]	training's l2: 1.17768	valid_1's l2: 1.47118
[310]	training's l2: 1.17201	valid_1's l2: 1.47019
[320]	training's l2: 1.1665	valid_1's l2: 1.46949
[330]	training's l2: 1.16153	valid_1's l2: 1.4685
[340]	training's l2: 1.15638	valid_1's l2: 1.46766
[350]	training's l2: 1.15132	valid_1's l2: 1.46692
[360]	training's l2: 1.14624	valid_1's l2: 1.46614
[370]	training's l2: 1.14132	valid_1's l2: 1.46535
[380]	training's l2: 1.13638	valid_1's l2: 1.46426
[390]	training's l2: 1.13194	valid_1's l2: 1.46372
[400]	training's l2: 1.12737	valid_1's l2: 1.46329
[410]	training's l2: 1.12279	valid_1's l2: 1.46291
[420]	training's l2: 1.11819	valid_1's l2: 1.46252
[430]	training's l2: 1.11333	valid_1's l2: 1.46157
[440]	training's l2: 1.1088	valid_1's l2: 1.46105
[450]	training's l2: 1.10469	valid_1's l2: 1.46049
[460]	training's l2: 1.10067	valid_1's l2: 1.46013
[470]	training's l2: 1.09638	valid_1's l2: 1.4603
[480]	training's l2: 1.09211	valid_1's l2: 1.46021
[490]	training's l2: 1.08818	valid_1's l2: 1.46008
[500]	training's l2: 1.0844	valid_1's l2: 1.45988
[510]	training's l2: 1.08063	valid_1's l2: 1.45951
[520]	training's l2: 1.0768	valid_1's l2: 1.45915
[530]	training's l2: 1.07247	valid_1's l2: 1.45895
[540]	training's l2: 1.06877	valid_1's l2: 1.4587
[550]	training's l2: 1.06494	valid_1's l2: 1.45864
[560]	training's l2: 1.06114	valid_1's l2: 1.45816
[570]	training's l2: 1.05777	valid_1's l2: 1.45777
[580]	training's l2: 1.05416	valid_1's l2: 1.45747
[590]	training's l2: 1.05043	valid_1's l2: 1.457
[600]	training's l2: 1.04706	valid_1's l2: 1.45693
[610]	training's l2: 1.04372	valid_1's l2: 1.45678
[620]	training's l2: 1.04057	valid_1's l2: 1.4567
[630]	training's l2: 1.03706	valid_1's l2: 1.45644
[640]	training's l2: 1.0338	valid_1's l2: 1.45622
[650]	training's l2: 1.0304	valid_1's l2: 1.45613
[660]	training's l2: 1.02714	valid_1's l2: 1.45594
[670]	training's l2: 1.02402	valid_1's l2: 1.45591
[680]	training's l2: 1.02068	valid_1's l2: 1.45604
[690]	training's l2: 1.01767	valid_1's l2: 1.45594
[700]	training's l2: 1.01454	valid_1's l2: 1.45562
[710]	training's l2: 1.0114	valid_1's l2: 1.45569
[720]	training's l2: 1.00841	valid_1's l2: 1.45533
[730]	training's l2: 1.00538	valid_1's l2: 1.45518
[740]	training's l2: 1.00238	valid_1's l2: 1.45501
[750]	training's l2: 0.999351	valid_1's l2: 1.45478
[760]	training's l2: 0.996482	valid_1's l2: 1.45474
[770]	training's l2: 0.9936	valid_1's l2: 1.45525
[780]	training's l2: 0.990853	valid_1's l2: 1.45524
Early stopping, best iteration is:
[754]	training's l2: 0.998256	valid_1's l2: 1.45472
score: 1.259403360909427
