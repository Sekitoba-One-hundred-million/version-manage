standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
omega_index_data.pickle download finish
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
up3_ave_data.pickle download finish Gilgamesh
start rank:1
start rank:5
start rank:2
start rank:4
start rank:3
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.395028 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 35623
[LightGBM] [Info] Number of data points in the train set: 610176, number of used features: 194
[LightGBM] [Info] Start training from score 0.000180
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 0.00151696	valid_1's l2: 0.00154731
[20]	training's l2: 0.00144957	valid_1's l2: 0.00148431
[30]	training's l2: 0.00139309	valid_1's l2: 0.0014322
[40]	training's l2: 0.00134557	valid_1's l2: 0.00138861
[50]	training's l2: 0.00130517	valid_1's l2: 0.00135219
[60]	training's l2: 0.00127084	valid_1's l2: 0.00132167
[70]	training's l2: 0.00124165	valid_1's l2: 0.00129591
[80]	training's l2: 0.00121674	valid_1's l2: 0.00127419
[90]	training's l2: 0.00119504	valid_1's l2: 0.00125567
[100]	training's l2: 0.00117618	valid_1's l2: 0.0012398
[110]	training's l2: 0.00115956	valid_1's l2: 0.00122574
[120]	training's l2: 0.00114517	valid_1's l2: 0.00121376
[130]	training's l2: 0.00113257	valid_1's l2: 0.00120336
[140]	training's l2: 0.00112134	valid_1's l2: 0.00119414
[150]	training's l2: 0.00111117	valid_1's l2: 0.00118608
[160]	training's l2: 0.00110213	valid_1's l2: 0.001179
[170]	training's l2: 0.00109391	valid_1's l2: 0.00117262
[180]	training's l2: 0.00108646	valid_1's l2: 0.00116687
[190]	training's l2: 0.0010795	valid_1's l2: 0.00116167
[200]	training's l2: 0.00107302	valid_1's l2: 0.00115693
[210]	training's l2: 0.00106705	valid_1's l2: 0.00115257
[220]	training's l2: 0.00106154	valid_1's l2: 0.00114862
[230]	training's l2: 0.00105629	valid_1's l2: 0.00114502
[240]	training's l2: 0.00105135	valid_1's l2: 0.00114158
[250]	training's l2: 0.00104673	valid_1's l2: 0.00113845
[260]	training's l2: 0.00104217	valid_1's l2: 0.00113535
[270]	training's l2: 0.00103793	valid_1's l2: 0.0011327
[280]	training's l2: 0.00103389	valid_1's l2: 0.00113017
[290]	training's l2: 0.00102993	valid_1's l2: 0.00112775
[300]	training's l2: 0.00102621	valid_1's l2: 0.00112567
[310]	training's l2: 0.00102238	valid_1's l2: 0.00112338
[320]	training's l2: 0.00101909	valid_1's l2: 0.00112154
[330]	training's l2: 0.00101558	valid_1's l2: 0.00111937
[340]	training's l2: 0.00101238	valid_1's l2: 0.00111749
[350]	training's l2: 0.00100925	valid_1's l2: 0.0011157
[360]	training's l2: 0.0010062	valid_1's l2: 0.00111397
[370]	training's l2: 0.00100296	valid_1's l2: 0.00111219
[380]	training's l2: 0.000999953	valid_1's l2: 0.00111069
[390]	training's l2: 0.000997165	valid_1's l2: 0.00110932
[400]	training's l2: 0.000994517	valid_1's l2: 0.00110805
[410]	training's l2: 0.000991915	valid_1's l2: 0.00110681
[420]	training's l2: 0.000989349	valid_1's l2: 0.00110564
[430]	training's l2: 0.000986903	valid_1's l2: 0.00110461
[440]	training's l2: 0.000984459	valid_1's l2: 0.00110352
[450]	training's l2: 0.000981956	valid_1's l2: 0.00110252
[460]	training's l2: 0.000979642	valid_1's l2: 0.00110159
[470]	training's l2: 0.000977145	valid_1's l2: 0.00110055
[480]	training's l2: 0.000974698	valid_1's l2: 0.00109973
[490]	training's l2: 0.000972112	valid_1's l2: 0.00109876
[500]	training's l2: 0.000969667	valid_1's l2: 0.00109778
[510]	training's l2: 0.000967322	valid_1's l2: 0.00109691
[520]	training's l2: 0.000965109	valid_1's l2: 0.00109621
[530]	training's l2: 0.00096271	valid_1's l2: 0.00109547
[540]	training's l2: 0.000960414	valid_1's l2: 0.0010947
[550]	training's l2: 0.000958241	valid_1's l2: 0.00109398
[560]	training's l2: 0.000956239	valid_1's l2: 0.00109338
[570]	training's l2: 0.000954097	valid_1's l2: 0.00109267
[580]	training's l2: 0.000952206	valid_1's l2: 0.00109207
[590]	training's l2: 0.000949955	valid_1's l2: 0.00109127
[600]	training's l2: 0.000947994	valid_1's l2: 0.00109066
[610]	training's l2: 0.000946087	valid_1's l2: 0.00109014
[620]	training's l2: 0.000944157	valid_1's l2: 0.00108962
[630]	training's l2: 0.000942017	valid_1's l2: 0.00108899
[640]	training's l2: 0.000939995	valid_1's l2: 0.00108843
[650]	training's l2: 0.0009382	valid_1's l2: 0.001088
[660]	training's l2: 0.000936228	valid_1's l2: 0.00108747
[670]	training's l2: 0.000934223	valid_1's l2: 0.00108686
[680]	training's l2: 0.000932338	valid_1's l2: 0.0010864
[690]	training's l2: 0.000930561	valid_1's l2: 0.00108597
[700]	training's l2: 0.000928707	valid_1's l2: 0.00108553
[710]	training's l2: 0.00092702	valid_1's l2: 0.00108516
[720]	training's l2: 0.000925129	valid_1's l2: 0.00108465
[730]	training's l2: 0.000923393	valid_1's l2: 0.00108423
[740]	training's l2: 0.00092163	valid_1's l2: 0.0010838
[750]	training's l2: 0.000919932	valid_1's l2: 0.00108357
[760]	training's l2: 0.000918276	valid_1's l2: 0.00108321
[770]	training's l2: 0.000916447	valid_1's l2: 0.00108279
[780]	training's l2: 0.000914795	valid_1's l2: 0.00108247
[790]	training's l2: 0.000913122	valid_1's l2: 0.00108215
[800]	training's l2: 0.000911428	valid_1's l2: 0.00108186
[810]	training's l2: 0.000909816	valid_1's l2: 0.00108153
[820]	training's l2: 0.000908219	valid_1's l2: 0.00108124
[830]	training's l2: 0.000906559	valid_1's l2: 0.00108099
[840]	training's l2: 0.000905078	valid_1's l2: 0.00108078
[850]	training's l2: 0.000903495	valid_1's l2: 0.00108048
[860]	training's l2: 0.000902024	valid_1's l2: 0.00108023
[870]	training's l2: 0.000900469	valid_1's l2: 0.00107997
[880]	training's l2: 0.000898869	valid_1's l2: 0.0010796
[890]	training's l2: 0.000897343	valid_1's l2: 0.00107939
[900]	training's l2: 0.000895728	valid_1's l2: 0.00107914
[910]	training's l2: 0.000894223	valid_1's l2: 0.00107883
[920]	training's l2: 0.00089263	valid_1's l2: 0.00107854
[930]	training's l2: 0.000891101	valid_1's l2: 0.00107833
[940]	training's l2: 0.000889515	valid_1's l2: 0.00107802
[950]	training's l2: 0.00088801	valid_1's l2: 0.00107775
[960]	training's l2: 0.000886441	valid_1's l2: 0.00107751
[970]	training's l2: 0.000884972	valid_1's l2: 0.00107725
[980]	training's l2: 0.000883589	valid_1's l2: 0.00107712
[990]	training's l2: 0.000882043	valid_1's l2: 0.00107686
[1000]	training's l2: 0.000880559	valid_1's l2: 0.00107672
[1010]	training's l2: 0.000879166	valid_1's l2: 0.00107652
[1020]	training's l2: 0.000877675	valid_1's l2: 0.00107634
[1030]	training's l2: 0.000876379	valid_1's l2: 0.00107619
[1040]	training's l2: 0.000874896	valid_1's l2: 0.00107598
[1050]	training's l2: 0.000873553	valid_1's l2: 0.00107581
[1060]	training's l2: 0.000872144	valid_1's l2: 0.00107569
[1070]	training's l2: 0.000870835	valid_1's l2: 0.00107553
[1080]	training's l2: 0.000869336	valid_1's l2: 0.00107537
[1090]	training's l2: 0.000867986	valid_1's l2: 0.0010753
[1100]	training's l2: 0.000866668	valid_1's l2: 0.00107521
[1110]	training's l2: 0.000865295	valid_1's l2: 0.0010751
[1120]	training's l2: 0.000863929	valid_1's l2: 0.00107496
[1130]	training's l2: 0.000862575	valid_1's l2: 0.00107489
[1140]	training's l2: 0.000861216	valid_1's l2: 0.00107477
[1150]	training's l2: 0.000859862	valid_1's l2: 0.00107471
[1160]	training's l2: 0.000858588	valid_1's l2: 0.00107465
[1170]	training's l2: 0.000857366	valid_1's l2: 0.00107456
[1180]	training's l2: 0.000855976	valid_1's l2: 0.00107441
[1190]	training's l2: 0.000854742	valid_1's l2: 0.00107435
[1200]	training's l2: 0.000853498	valid_1's l2: 0.00107426
[1210]	training's l2: 0.00085219	valid_1's l2: 0.0010742
[1220]	training's l2: 0.000850936	valid_1's l2: 0.0010741
[1230]	training's l2: 0.000849683	valid_1's l2: 0.00107392
[1240]	training's l2: 0.000848385	valid_1's l2: 0.00107384
[1250]	training's l2: 0.000847179	valid_1's l2: 0.00107377
[1260]	training's l2: 0.000845956	valid_1's l2: 0.00107368
[1270]	training's l2: 0.000844724	valid_1's l2: 0.00107362
[1280]	training's l2: 0.000843449	valid_1's l2: 0.00107348
[1290]	training's l2: 0.000842291	valid_1's l2: 0.00107343
[1300]	training's l2: 0.000841102	valid_1's l2: 0.0010734
[1310]	training's l2: 0.000839897	valid_1's l2: 0.00107335
[1320]	training's l2: 0.000838701	valid_1's l2: 0.00107325
[1330]	training's l2: 0.000837546	valid_1's l2: 0.00107322
[1340]	training's l2: 0.000836356	valid_1's l2: 0.00107315
[1350]	training's l2: 0.000835107	valid_1's l2: 0.00107311
[1360]	training's l2: 0.000833986	valid_1's l2: 0.00107306
[1370]	training's l2: 0.000832852	valid_1's l2: 0.00107296
[1380]	training's l2: 0.000831681	valid_1's l2: 0.00107291
[1390]	training's l2: 0.00083053	valid_1's l2: 0.00107284
[1400]	training's l2: 0.000829415	valid_1's l2: 0.00107279
[1410]	training's l2: 0.000828284	valid_1's l2: 0.0010727
[1420]	training's l2: 0.000827189	valid_1's l2: 0.00107267
[1430]	training's l2: 0.000826066	valid_1's l2: 0.00107267
[1440]	training's l2: 0.000824935	valid_1's l2: 0.00107258
[1450]	training's l2: 0.000823846	valid_1's l2: 0.00107251
[1460]	training's l2: 0.000822785	valid_1's l2: 0.00107241
[1470]	training's l2: 0.000821695	valid_1's l2: 0.00107234
[1480]	training's l2: 0.000820616	valid_1's l2: 0.00107226
[1490]	training's l2: 0.000819505	valid_1's l2: 0.00107215
[1500]	training's l2: 0.00081837	valid_1's l2: 0.00107208
[1510]	training's l2: 0.000817355	valid_1's l2: 0.00107206
[1520]	training's l2: 0.000816292	valid_1's l2: 0.00107201
[1530]	training's l2: 0.000815204	valid_1's l2: 0.00107194
[1540]	training's l2: 0.000814124	valid_1's l2: 0.00107189
[1550]	training's l2: 0.000813119	valid_1's l2: 0.00107191
[1560]	training's l2: 0.000812027	valid_1's l2: 0.00107179
[1570]	training's l2: 0.000811004	valid_1's l2: 0.00107178
[1580]	training's l2: 0.000809971	valid_1's l2: 0.00107172
[1590]	training's l2: 0.00080893	valid_1's l2: 0.00107166
[1600]	training's l2: 0.000807926	valid_1's l2: 0.00107164
[1610]	training's l2: 0.000806932	valid_1's l2: 0.00107167
[1620]	training's l2: 0.000805869	valid_1's l2: 0.00107169
[1630]	training's l2: 0.000804835	valid_1's l2: 0.00107166
[1640]	training's l2: 0.000803812	valid_1's l2: 0.00107161
[1650]	training's l2: 0.000802786	valid_1's l2: 0.00107149
[1660]	training's l2: 0.000801842	valid_1's l2: 0.00107142
[1670]	training's l2: 0.000800783	valid_1's l2: 0.00107136
[1680]	training's l2: 0.000799796	valid_1's l2: 0.00107138
[1690]	training's l2: 0.000798851	valid_1's l2: 0.00107127
[1700]	training's l2: 0.000797892	valid_1's l2: 0.00107132
[1710]	training's l2: 0.00079681	valid_1's l2: 0.00107126
[1720]	training's l2: 0.000795869	valid_1's l2: 0.00107116
[1730]	training's l2: 0.0007948	valid_1's l2: 0.00107104
[1740]	training's l2: 0.000793819	valid_1's l2: 0.00107099
[1750]	training's l2: 0.000792856	valid_1's l2: 0.00107098
[1760]	training's l2: 0.00079189	valid_1's l2: 0.00107094
[1770]	training's l2: 0.000790992	valid_1's l2: 0.00107091
[1780]	training's l2: 0.000789983	valid_1's l2: 0.00107085
[1790]	training's l2: 0.000788993	valid_1's l2: 0.00107074
[1800]	training's l2: 0.000788084	valid_1's l2: 0.0010707
[1810]	training's l2: 0.000787179	valid_1's l2: 0.00107067
[1820]	training's l2: 0.000786313	valid_1's l2: 0.00107063
[1830]	training's l2: 0.000785368	valid_1's l2: 0.00107064
[1840]	training's l2: 0.000784452	valid_1's l2: 0.00107059
[1850]	training's l2: 0.000783548	valid_1's l2: 0.00107056
[1860]	training's l2: 0.000782652	valid_1's l2: 0.00107055
[1870]	training's l2: 0.000781711	valid_1's l2: 0.00107052
[1880]	training's l2: 0.000780871	valid_1's l2: 0.00107047
[1890]	training's l2: 0.000780029	valid_1's l2: 0.00107045
[1900]	training's l2: 0.000779149	valid_1's l2: 0.00107041
[1910]	training's l2: 0.00077829	valid_1's l2: 0.00107041
[1920]	training's l2: 0.000777464	valid_1's l2: 0.00107039
[1930]	training's l2: 0.000776635	valid_1's l2: 0.00107037
[1940]	training's l2: 0.000775825	valid_1's l2: 0.00107031
[1950]	training's l2: 0.000774963	valid_1's l2: 0.00107024
[1960]	training's l2: 0.000774077	valid_1's l2: 0.00107015
[1970]	training's l2: 0.000773242	valid_1's l2: 0.00107014
[1980]	training's l2: 0.000772404	valid_1's l2: 0.00107013
[1990]	training's l2: 0.000771535	valid_1's l2: 0.00107011
[2000]	training's l2: 0.000770706	valid_1's l2: 0.00107007
[2010]	training's l2: 0.000769909	valid_1's l2: 0.00107003
[2020]	training's l2: 0.000769089	valid_1's l2: 0.00107006
[2030]	training's l2: 0.000768258	valid_1's l2: 0.00107004
[2040]	training's l2: 0.00076741	valid_1's l2: 0.00107004
[2050]	training's l2: 0.000766614	valid_1's l2: 0.00107005
[2060]	training's l2: 0.000765713	valid_1's l2: 0.00107001
[2070]	training's l2: 0.000764956	valid_1's l2: 0.00107001
[2080]	training's l2: 0.000764154	valid_1's l2: 0.00106998
[2090]	training's l2: 0.000763328	valid_1's l2: 0.00106992
[2100]	training's l2: 0.000762367	valid_1's l2: 0.00106983
[2110]	training's l2: 0.000761565	valid_1's l2: 0.00106987
[2120]	training's l2: 0.000760792	valid_1's l2: 0.00106987
[2130]	training's l2: 0.000759946	valid_1's l2: 0.00106984
Early stopping, best iteration is:
[2102]	training's l2: 0.000762198	valid_1's l2: 0.00106982
score1: 1.2294052805950026
