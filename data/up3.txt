standard_time.pickle download finish Gilgamesh
up_average.pickle download finish Gilgamesh
up_pace_regressin.pickle download finish Gilgamesh
up_kind_ave_data.pickle download finish Gilgamesh
money_class_true_skill_data.pickle download finish Gilgamesh
race_ave_true_skill.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
race_time_analyze_data.pickle download finish Gilgamesh
up3_analyze_data.pickle download finish Gilgamesh
first_up3_halon.pickle download finish Gilgamesh
stride_ablity_analyze_data.pickle download finish Gilgamesh
time_index_data.pickle download finish Gilgamesh
train_time_data.pickle download finish Gilgamesh
train_ave_data.pickle download finish Gilgamesh
train_ave_key_data.pickle download finish Gilgamesh
race_info_data.pickle download finish Gilgamesh
jockey_analyze_data.pickle download finish Gilgamesh
jockey_id_data.pickle download finish Gilgamesh
jockey_year_rank_data.pickle download finish Gilgamesh
trainer_analyze_data.pickle download finish Gilgamesh
race_trainer_id_data.pickle download finish Gilgamesh
race_rank_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
foot_used.pickle download finish Gilgamesh
wrap_data.pickle download finish Gilgamesh
race_data.pickle download finish Gilgamesh
horce_data_storage.pickle download finish Gilgamesh
baba_index_data.pickle download finish Gilgamesh
parent_id_data.pickle download finish Gilgamesh
race_day.pickle download finish Gilgamesh
horce_sex_data.pickle download finish Gilgamesh
race_jockey_id_data.pickle download finish Gilgamesh
true_skill_data.pickle download finish Gilgamesh
waku_three_rate_data.pickle download finish Gilgamesh
corner_horce_body.pickle download finish Gilgamesh
jockey_judgment_up3_data.pickle download finish Gilgamesh
jockey_judgment_up3_rate_data.pickle download finish Gilgamesh
trainer_judgment_up3_data.pickle download finish Gilgamesh
first_passing_true_skill_data.pickle download finish Gilgamesh
last_passing_true_skill_data.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
predict_last_passing_rank.pickle download finish Gilgamesh
up3_true_skill_data.pickle download finish Gilgamesh
predict_netkeiba_pace_data.pickle download finish Gilgamesh
predict_netkeiba_deployment_data.pickle download finish Gilgamesh
condition_devi_data.pickle download finish Gilgamesh
start rank:1
condition_devi_data.pickle download finish Gilgamesh
condition_devi_data.pickle download finish Gilgamesh
condition_devi_data.pickle download finish Gilgamesh
start rank:4
condition_devi_data.pickle download finish Gilgamesh
start rank:5
start rank:2
start rank:3
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.351543 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 47779
[LightGBM] [Info] Number of data points in the train set: 564536, number of used features: 262
[LightGBM] [Info] Start training from score 37.122498
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 3.68795	valid_1's l2: 3.85128
[20]	training's l2: 3.02432	valid_1's l2: 3.15216
[30]	training's l2: 2.56684	valid_1's l2: 2.67202
[40]	training's l2: 2.24616	valid_1's l2: 2.33933
[50]	training's l2: 2.02138	valid_1's l2: 2.10972
[60]	training's l2: 1.86224	valid_1's l2: 1.94841
[70]	training's l2: 1.74838	valid_1's l2: 1.83501
[80]	training's l2: 1.66442	valid_1's l2: 1.75347
[90]	training's l2: 1.60187	valid_1's l2: 1.69456
[100]	training's l2: 1.55385	valid_1's l2: 1.65081
[110]	training's l2: 1.51693	valid_1's l2: 1.61806
[120]	training's l2: 1.48805	valid_1's l2: 1.59283
[130]	training's l2: 1.46478	valid_1's l2: 1.5737
[140]	training's l2: 1.44579	valid_1's l2: 1.559
[150]	training's l2: 1.42937	valid_1's l2: 1.54652
[160]	training's l2: 1.4153	valid_1's l2: 1.53675
[170]	training's l2: 1.40236	valid_1's l2: 1.52912
[180]	training's l2: 1.3896	valid_1's l2: 1.52188
[190]	training's l2: 1.37962	valid_1's l2: 1.51633
[200]	training's l2: 1.37125	valid_1's l2: 1.51166
[210]	training's l2: 1.3637	valid_1's l2: 1.50836
[220]	training's l2: 1.35631	valid_1's l2: 1.50512
[230]	training's l2: 1.34995	valid_1's l2: 1.50238
[240]	training's l2: 1.34357	valid_1's l2: 1.49986
[250]	training's l2: 1.33783	valid_1's l2: 1.49756
[260]	training's l2: 1.33255	valid_1's l2: 1.49553
[270]	training's l2: 1.32739	valid_1's l2: 1.49357
[280]	training's l2: 1.32192	valid_1's l2: 1.49201
[290]	training's l2: 1.31698	valid_1's l2: 1.49057
[300]	training's l2: 1.31227	valid_1's l2: 1.48889
[310]	training's l2: 1.30766	valid_1's l2: 1.48747
[320]	training's l2: 1.30319	valid_1's l2: 1.48605
[330]	training's l2: 1.29906	valid_1's l2: 1.48479
[340]	training's l2: 1.29504	valid_1's l2: 1.48327
[350]	training's l2: 1.2914	valid_1's l2: 1.48231
[360]	training's l2: 1.28785	valid_1's l2: 1.48128
[370]	training's l2: 1.2841	valid_1's l2: 1.48033
[380]	training's l2: 1.28047	valid_1's l2: 1.47945
[390]	training's l2: 1.27706	valid_1's l2: 1.47832
[400]	training's l2: 1.27354	valid_1's l2: 1.47736
[410]	training's l2: 1.27022	valid_1's l2: 1.47658
[420]	training's l2: 1.26681	valid_1's l2: 1.4757
[430]	training's l2: 1.26369	valid_1's l2: 1.4751
[440]	training's l2: 1.26043	valid_1's l2: 1.47418
[450]	training's l2: 1.25741	valid_1's l2: 1.47369
[460]	training's l2: 1.2545	valid_1's l2: 1.47264
[470]	training's l2: 1.25129	valid_1's l2: 1.47195
[480]	training's l2: 1.24836	valid_1's l2: 1.47111
[490]	training's l2: 1.24556	valid_1's l2: 1.47038
[500]	training's l2: 1.24255	valid_1's l2: 1.47006
[510]	training's l2: 1.23959	valid_1's l2: 1.46948
[520]	training's l2: 1.23697	valid_1's l2: 1.46899
[530]	training's l2: 1.2343	valid_1's l2: 1.46809
[540]	training's l2: 1.2315	valid_1's l2: 1.4673
[550]	training's l2: 1.22866	valid_1's l2: 1.46676
[560]	training's l2: 1.2261	valid_1's l2: 1.46627
[570]	training's l2: 1.22323	valid_1's l2: 1.46586
[580]	training's l2: 1.22081	valid_1's l2: 1.46536
[590]	training's l2: 1.21835	valid_1's l2: 1.46526
[600]	training's l2: 1.21569	valid_1's l2: 1.46494
[610]	training's l2: 1.21328	valid_1's l2: 1.4645
[620]	training's l2: 1.2109	valid_1's l2: 1.46417
[630]	training's l2: 1.20844	valid_1's l2: 1.46396
[640]	training's l2: 1.2061	valid_1's l2: 1.46367
[650]	training's l2: 1.20396	valid_1's l2: 1.46371
[660]	training's l2: 1.20156	valid_1's l2: 1.46351
[670]	training's l2: 1.19933	valid_1's l2: 1.46338
[680]	training's l2: 1.19712	valid_1's l2: 1.46301
[690]	training's l2: 1.195	valid_1's l2: 1.46253
[700]	training's l2: 1.19275	valid_1's l2: 1.46221
[710]	training's l2: 1.1906	valid_1's l2: 1.46203
[720]	training's l2: 1.18854	valid_1's l2: 1.46189
[730]	training's l2: 1.18651	valid_1's l2: 1.46162
[740]	training's l2: 1.1842	valid_1's l2: 1.46117
[750]	training's l2: 1.18197	valid_1's l2: 1.46088
[760]	training's l2: 1.17997	valid_1's l2: 1.46067
[770]	training's l2: 1.17787	valid_1's l2: 1.46062
[780]	training's l2: 1.17593	valid_1's l2: 1.46034
[790]	training's l2: 1.17395	valid_1's l2: 1.46
[800]	training's l2: 1.1719	valid_1's l2: 1.45969
[810]	training's l2: 1.16988	valid_1's l2: 1.45942
[820]	training's l2: 1.16808	valid_1's l2: 1.45933
[830]	training's l2: 1.1662	valid_1's l2: 1.45909
[840]	training's l2: 1.16437	valid_1's l2: 1.45885
[850]	training's l2: 1.16245	valid_1's l2: 1.45871
[860]	training's l2: 1.16058	valid_1's l2: 1.45863
[870]	training's l2: 1.15874	valid_1's l2: 1.45858
[880]	training's l2: 1.15701	valid_1's l2: 1.45848
[890]	training's l2: 1.15515	valid_1's l2: 1.45839
[900]	training's l2: 1.15336	valid_1's l2: 1.4582
[910]	training's l2: 1.1515	valid_1's l2: 1.45805
[920]	training's l2: 1.14975	valid_1's l2: 1.45818
[930]	training's l2: 1.14803	valid_1's l2: 1.45796
[940]	training's l2: 1.14629	valid_1's l2: 1.45771
[950]	training's l2: 1.14457	valid_1's l2: 1.45764
[960]	training's l2: 1.143	valid_1's l2: 1.45751
[970]	training's l2: 1.14119	valid_1's l2: 1.45746
[980]	training's l2: 1.13937	valid_1's l2: 1.4574
[990]	training's l2: 1.1375	valid_1's l2: 1.45723
[1000]	training's l2: 1.1359	valid_1's l2: 1.45704
[1010]	training's l2: 1.13419	valid_1's l2: 1.45714
[1020]	training's l2: 1.13265	valid_1's l2: 1.45712
[1030]	training's l2: 1.13092	valid_1's l2: 1.45713
[1040]	training's l2: 1.12923	valid_1's l2: 1.45692
[1050]	training's l2: 1.12753	valid_1's l2: 1.45687
[1060]	training's l2: 1.12594	valid_1's l2: 1.45674
[1070]	training's l2: 1.1244	valid_1's l2: 1.45677
[1080]	training's l2: 1.12282	valid_1's l2: 1.45673
[1090]	training's l2: 1.12137	valid_1's l2: 1.45669
[1100]	training's l2: 1.11977	valid_1's l2: 1.45655
[1110]	training's l2: 1.11824	valid_1's l2: 1.45664
[1120]	training's l2: 1.11652	valid_1's l2: 1.45648
[1130]	training's l2: 1.11496	valid_1's l2: 1.45638
[1140]	training's l2: 1.11356	valid_1's l2: 1.45628
[1150]	training's l2: 1.11211	valid_1's l2: 1.45626
[1160]	training's l2: 1.1106	valid_1's l2: 1.45614
[1170]	training's l2: 1.10915	valid_1's l2: 1.45609
[1180]	training's l2: 1.10761	valid_1's l2: 1.45604
[1190]	training's l2: 1.10605	valid_1's l2: 1.45602
[1200]	training's l2: 1.10455	valid_1's l2: 1.45597
[1210]	training's l2: 1.10312	valid_1's l2: 1.45586
[1220]	training's l2: 1.10172	valid_1's l2: 1.4558
[1230]	training's l2: 1.10034	valid_1's l2: 1.45576
[1240]	training's l2: 1.09895	valid_1's l2: 1.45578
[1250]	training's l2: 1.0975	valid_1's l2: 1.45587
Early stopping, best iteration is:
[1225]	training's l2: 1.10098	valid_1's l2: 1.4557
score: 1.2491871045620968
