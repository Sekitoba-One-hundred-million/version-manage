Looking in indexes: https://pypi.org/simple, http://100.95.241.19
Requirement already satisfied: SekitobaLibrary in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (1.2.111)
Requirement already satisfied: requests in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (2.28.1)
Requirement already satisfied: pandas in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (1.5.2)
Requirement already satisfied: lightgbm in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (3.3.3)
Requirement already satisfied: numpy in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (1.24.1)
Requirement already satisfied: matplotlib in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (3.6.2)
Requirement already satisfied: tqdm in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (4.64.1)
Requirement already satisfied: statistics in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (1.0.3.5)
Requirement already satisfied: boto3 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (1.26.42)
Requirement already satisfied: torch in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (1.13.1)
Requirement already satisfied: mpi4py in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (3.1.4)
Requirement already satisfied: trueskill in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (0.4.5)
Requirement already satisfied: bs4 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (0.0.1)
Requirement already satisfied: jpholiday in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from SekitobaLibrary) (0.1.8)
Requirement already satisfied: botocore<1.30.0,>=1.29.42 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from boto3->SekitobaLibrary) (1.29.42)
Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from boto3->SekitobaLibrary) (1.0.1)
Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from boto3->SekitobaLibrary) (0.6.0)
Requirement already satisfied: beautifulsoup4 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from bs4->SekitobaLibrary) (4.11.1)
Requirement already satisfied: wheel in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from lightgbm->SekitobaLibrary) (0.38.4)
Requirement already satisfied: scipy in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from lightgbm->SekitobaLibrary) (1.9.3)
Requirement already satisfied: scikit-learn!=0.22.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from lightgbm->SekitobaLibrary) (1.2.0)
Requirement already satisfied: contourpy>=1.0.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (1.0.6)
Requirement already satisfied: cycler>=0.10 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (4.38.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (1.4.4)
Requirement already satisfied: packaging>=20.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (22.0)
Requirement already satisfied: pillow>=6.2.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (9.3.0)
Requirement already satisfied: pyparsing>=2.2.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (3.0.9)
Requirement already satisfied: python-dateutil>=2.7 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib->SekitobaLibrary) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from pandas->SekitobaLibrary) (2022.7)
Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from requests->SekitobaLibrary) (2.1.1)
Requirement already satisfied: idna<4,>=2.5 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from requests->SekitobaLibrary) (3.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from requests->SekitobaLibrary) (1.26.13)
Requirement already satisfied: certifi>=2017.4.17 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from requests->SekitobaLibrary) (2022.12.7)
Requirement already satisfied: docutils>=0.3 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from statistics->SekitobaLibrary) (0.19)
Requirement already satisfied: typing-extensions in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from torch->SekitobaLibrary) (4.4.0)
Requirement already satisfied: six in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from trueskill->SekitobaLibrary) (1.16.0)
Requirement already satisfied: joblib>=1.1.1 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm->SekitobaLibrary) (1.2.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm->SekitobaLibrary) (3.1.0)
Requirement already satisfied: soupsieve>1.2 in /Users/kansei/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from beautifulsoup4->bs4->SekitobaLibrary) (2.3.2.post1)
wrap_data.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
race_cource_info.pickle download finish Gilgamesh
predict_train_score.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
predict_last_passing_rank.pickle download finish Gilgamesh
start rank:1
start rank:2
start rank:5
start rank:3
start rank:4
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
up3_learn_data.pickle download finish Gilgamesh
up3_simu_data.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.832634 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 50073
[LightGBM] [Info] Number of data points in the train set: 638354, number of used features: 276
[LightGBM] [Info] Start training from score 37.103949
[1]	training's l2: 4.42955	valid_1's l2: 4.7938
Training until validation scores don't improve for 30 rounds
[2]	training's l2: 4.19325	valid_1's l2: 4.55194
[3]	training's l2: 3.97466	valid_1's l2: 4.32832
[4]	training's l2: 3.77243	valid_1's l2: 4.12145
[5]	training's l2: 3.58518	valid_1's l2: 3.92985
[6]	training's l2: 3.41209	valid_1's l2: 3.75274
[7]	training's l2: 3.25171	valid_1's l2: 3.58848
[8]	training's l2: 3.10334	valid_1's l2: 3.43646
[9]	training's l2: 2.96605	valid_1's l2: 3.29549
[10]	training's l2: 2.83878	valid_1's l2: 3.16488
[11]	training's l2: 2.72094	valid_1's l2: 3.0437
[12]	training's l2: 2.61189	valid_1's l2: 2.93182
[13]	training's l2: 2.5109	valid_1's l2: 2.82823
[14]	training's l2: 2.41716	valid_1's l2: 2.7321
[15]	training's l2: 2.33033	valid_1's l2: 2.64331
[16]	training's l2: 2.2499	valid_1's l2: 2.56041
[17]	training's l2: 2.17552	valid_1's l2: 2.48418
[18]	training's l2: 2.10638	valid_1's l2: 2.4136
[19]	training's l2: 2.04227	valid_1's l2: 2.34806
[20]	training's l2: 1.98292	valid_1's l2: 2.28739
[21]	training's l2: 1.92773	valid_1's l2: 2.23089
[22]	training's l2: 1.8766	valid_1's l2: 2.17856
[23]	training's l2: 1.829	valid_1's l2: 2.13001
[24]	training's l2: 1.78481	valid_1's l2: 2.08547
[25]	training's l2: 1.74381	valid_1's l2: 2.04368
[26]	training's l2: 1.70559	valid_1's l2: 2.00489
[27]	training's l2: 1.67007	valid_1's l2: 1.96909
[28]	training's l2: 1.63709	valid_1's l2: 1.9357
[29]	training's l2: 1.60634	valid_1's l2: 1.90484
[30]	training's l2: 1.57778	valid_1's l2: 1.87635
[31]	training's l2: 1.55123	valid_1's l2: 1.8493
[32]	training's l2: 1.52649	valid_1's l2: 1.82467
[33]	training's l2: 1.50341	valid_1's l2: 1.80176
[34]	training's l2: 1.4819	valid_1's l2: 1.78023
[35]	training's l2: 1.46196	valid_1's l2: 1.76041
[36]	training's l2: 1.44313	valid_1's l2: 1.74169
[37]	training's l2: 1.42575	valid_1's l2: 1.72435
[38]	training's l2: 1.4094	valid_1's l2: 1.70823
[39]	training's l2: 1.39411	valid_1's l2: 1.69316
[40]	training's l2: 1.37987	valid_1's l2: 1.67924
[41]	training's l2: 1.36655	valid_1's l2: 1.66608
[42]	training's l2: 1.35396	valid_1's l2: 1.65388
[43]	training's l2: 1.34219	valid_1's l2: 1.64277
[44]	training's l2: 1.3312	valid_1's l2: 1.63242
[45]	training's l2: 1.32089	valid_1's l2: 1.62262
[46]	training's l2: 1.31113	valid_1's l2: 1.61366
[47]	training's l2: 1.30211	valid_1's l2: 1.60482
[48]	training's l2: 1.29351	valid_1's l2: 1.59707
[49]	training's l2: 1.2854	valid_1's l2: 1.58956
[50]	training's l2: 1.27773	valid_1's l2: 1.58273
[51]	training's l2: 1.27056	valid_1's l2: 1.57633
[52]	training's l2: 1.26381	valid_1's l2: 1.5702
[53]	training's l2: 1.2573	valid_1's l2: 1.56458
[54]	training's l2: 1.25129	valid_1's l2: 1.55937
[55]	training's l2: 1.24554	valid_1's l2: 1.55421
[56]	training's l2: 1.24012	valid_1's l2: 1.54961
[57]	training's l2: 1.23494	valid_1's l2: 1.54523
[58]	training's l2: 1.23009	valid_1's l2: 1.54121
[59]	training's l2: 1.22544	valid_1's l2: 1.53736
[60]	training's l2: 1.22096	valid_1's l2: 1.53364
[61]	training's l2: 1.21672	valid_1's l2: 1.53011
[62]	training's l2: 1.21262	valid_1's l2: 1.52705
[63]	training's l2: 1.20875	valid_1's l2: 1.52411
[64]	training's l2: 1.20511	valid_1's l2: 1.52142
[65]	training's l2: 1.20159	valid_1's l2: 1.51882
[66]	training's l2: 1.19823	valid_1's l2: 1.51663
[67]	training's l2: 1.19494	valid_1's l2: 1.51429
[68]	training's l2: 1.19189	valid_1's l2: 1.51217
[69]	training's l2: 1.1889	valid_1's l2: 1.51009
[70]	training's l2: 1.18598	valid_1's l2: 1.50815
[71]	training's l2: 1.18317	valid_1's l2: 1.50624
[72]	training's l2: 1.18029	valid_1's l2: 1.5044
[73]	training's l2: 1.17773	valid_1's l2: 1.50271
[74]	training's l2: 1.1751	valid_1's l2: 1.50124
[75]	training's l2: 1.17267	valid_1's l2: 1.49974
[76]	training's l2: 1.17017	valid_1's l2: 1.49841
[77]	training's l2: 1.16792	valid_1's l2: 1.49722
[78]	training's l2: 1.16564	valid_1's l2: 1.49566
[79]	training's l2: 1.16333	valid_1's l2: 1.49442
[80]	training's l2: 1.16113	valid_1's l2: 1.49351
[81]	training's l2: 1.15915	valid_1's l2: 1.49236
[82]	training's l2: 1.15719	valid_1's l2: 1.49114
[83]	training's l2: 1.15519	valid_1's l2: 1.49016
[84]	training's l2: 1.15325	valid_1's l2: 1.48928
[85]	training's l2: 1.15158	valid_1's l2: 1.48845
[86]	training's l2: 1.14983	valid_1's l2: 1.48752
[87]	training's l2: 1.1481	valid_1's l2: 1.48659
[88]	training's l2: 1.14612	valid_1's l2: 1.48597
[89]	training's l2: 1.14408	valid_1's l2: 1.48543
[90]	training's l2: 1.14246	valid_1's l2: 1.48454
[91]	training's l2: 1.14065	valid_1's l2: 1.48418
[92]	training's l2: 1.1387	valid_1's l2: 1.48338
[93]	training's l2: 1.13704	valid_1's l2: 1.48271
[94]	training's l2: 1.13542	valid_1's l2: 1.48192
[95]	training's l2: 1.13391	valid_1's l2: 1.48136
[96]	training's l2: 1.13248	valid_1's l2: 1.48076
[97]	training's l2: 1.13063	valid_1's l2: 1.47995
[98]	training's l2: 1.12895	valid_1's l2: 1.47946
[99]	training's l2: 1.12749	valid_1's l2: 1.47893
[100]	training's l2: 1.12593	valid_1's l2: 1.47828
[101]	training's l2: 1.12427	valid_1's l2: 1.47771
[102]	training's l2: 1.12275	valid_1's l2: 1.47724
[103]	training's l2: 1.12121	valid_1's l2: 1.47675
[104]	training's l2: 1.11982	valid_1's l2: 1.4762
[105]	training's l2: 1.11851	valid_1's l2: 1.47584
[106]	training's l2: 1.11707	valid_1's l2: 1.47531
[107]	training's l2: 1.11554	valid_1's l2: 1.47461
[108]	training's l2: 1.11424	valid_1's l2: 1.47414
[109]	training's l2: 1.11281	valid_1's l2: 1.47379
[110]	training's l2: 1.11154	valid_1's l2: 1.4734
[111]	training's l2: 1.11003	valid_1's l2: 1.47283
[112]	training's l2: 1.10877	valid_1's l2: 1.47268
[113]	training's l2: 1.10746	valid_1's l2: 1.47238
[114]	training's l2: 1.1062	valid_1's l2: 1.47212
[115]	training's l2: 1.10495	valid_1's l2: 1.47177
[116]	training's l2: 1.10374	valid_1's l2: 1.47129
[117]	training's l2: 1.10253	valid_1's l2: 1.47096
[118]	training's l2: 1.10115	valid_1's l2: 1.47073
[119]	training's l2: 1.09986	valid_1's l2: 1.47038
[120]	training's l2: 1.09871	valid_1's l2: 1.47007
[121]	training's l2: 1.09761	valid_1's l2: 1.46974
[122]	training's l2: 1.09639	valid_1's l2: 1.46946
[123]	training's l2: 1.09533	valid_1's l2: 1.46923
[124]	training's l2: 1.09415	valid_1's l2: 1.46878
[125]	training's l2: 1.09307	valid_1's l2: 1.46845
[126]	training's l2: 1.09207	valid_1's l2: 1.46815
[127]	training's l2: 1.09102	valid_1's l2: 1.46789
[128]	training's l2: 1.08951	valid_1's l2: 1.46789
[129]	training's l2: 1.08842	valid_1's l2: 1.46767
[130]	training's l2: 1.0873	valid_1's l2: 1.46744
[131]	training's l2: 1.08632	valid_1's l2: 1.46719
[132]	training's l2: 1.08533	valid_1's l2: 1.46694
[133]	training's l2: 1.08423	valid_1's l2: 1.46686
[134]	training's l2: 1.08324	valid_1's l2: 1.4666
[135]	training's l2: 1.0822	valid_1's l2: 1.46635
[136]	training's l2: 1.08097	valid_1's l2: 1.46614
[137]	training's l2: 1.07989	valid_1's l2: 1.46601
[138]	training's l2: 1.07893	valid_1's l2: 1.46574
[139]	training's l2: 1.07802	valid_1's l2: 1.46556
[140]	training's l2: 1.07705	valid_1's l2: 1.46537
[141]	training's l2: 1.07608	valid_1's l2: 1.46524
[142]	training's l2: 1.07487	valid_1's l2: 1.46518
[143]	training's l2: 1.07386	valid_1's l2: 1.46492
[144]	training's l2: 1.07282	valid_1's l2: 1.46485
[145]	training's l2: 1.07188	valid_1's l2: 1.46471
[146]	training's l2: 1.07092	valid_1's l2: 1.46444
[147]	training's l2: 1.06998	valid_1's l2: 1.46427
[148]	training's l2: 1.06896	valid_1's l2: 1.46431
[149]	training's l2: 1.06783	valid_1's l2: 1.4642
[150]	training's l2: 1.06699	valid_1's l2: 1.46409
[151]	training's l2: 1.06609	valid_1's l2: 1.46383
[152]	training's l2: 1.06509	valid_1's l2: 1.46375
[153]	training's l2: 1.06414	valid_1's l2: 1.46354
[154]	training's l2: 1.06326	valid_1's l2: 1.46332
[155]	training's l2: 1.06237	valid_1's l2: 1.46316
[156]	training's l2: 1.06113	valid_1's l2: 1.46318
[157]	training's l2: 1.05992	valid_1's l2: 1.46301
[158]	training's l2: 1.05904	valid_1's l2: 1.46288
[159]	training's l2: 1.05819	valid_1's l2: 1.46274
[160]	training's l2: 1.05717	valid_1's l2: 1.46272
[161]	training's l2: 1.05631	valid_1's l2: 1.46253
[162]	training's l2: 1.05507	valid_1's l2: 1.46239
[163]	training's l2: 1.05416	valid_1's l2: 1.46225
[164]	training's l2: 1.05326	valid_1's l2: 1.46208
[165]	training's l2: 1.05239	valid_1's l2: 1.46196
[166]	training's l2: 1.05126	valid_1's l2: 1.46214
[167]	training's l2: 1.05043	valid_1's l2: 1.46197
[168]	training's l2: 1.04951	valid_1's l2: 1.46171
[169]	training's l2: 1.04831	valid_1's l2: 1.46151
[170]	training's l2: 1.04738	valid_1's l2: 1.46138
[171]	training's l2: 1.04655	valid_1's l2: 1.46128
[172]	training's l2: 1.04577	valid_1's l2: 1.46116
[173]	training's l2: 1.04486	valid_1's l2: 1.46104
[174]	training's l2: 1.04394	valid_1's l2: 1.46097
[175]	training's l2: 1.04308	valid_1's l2: 1.46082
[176]	training's l2: 1.04212	valid_1's l2: 1.46094
[177]	training's l2: 1.04133	valid_1's l2: 1.46085
[178]	training's l2: 1.04034	valid_1's l2: 1.46084
[179]	training's l2: 1.03955	valid_1's l2: 1.46069
[180]	training's l2: 1.0385	valid_1's l2: 1.46055
[181]	training's l2: 1.03766	valid_1's l2: 1.46048
[182]	training's l2: 1.03689	valid_1's l2: 1.46039
[183]	training's l2: 1.036	valid_1's l2: 1.46026
[184]	training's l2: 1.03499	valid_1's l2: 1.46035
[185]	training's l2: 1.03404	valid_1's l2: 1.4602
[186]	training's l2: 1.03324	valid_1's l2: 1.46017
[187]	training's l2: 1.03221	valid_1's l2: 1.46015
[188]	training's l2: 1.03146	valid_1's l2: 1.46007
[189]	training's l2: 1.03051	valid_1's l2: 1.46013
[190]	training's l2: 1.02973	valid_1's l2: 1.46001
[191]	training's l2: 1.02881	valid_1's l2: 1.45986
[192]	training's l2: 1.02759	valid_1's l2: 1.46
[193]	training's l2: 1.02678	valid_1's l2: 1.45986
[194]	training's l2: 1.02597	valid_1's l2: 1.45972
[195]	training's l2: 1.02514	valid_1's l2: 1.45963
[196]	training's l2: 1.02434	valid_1's l2: 1.45955
[197]	training's l2: 1.02349	valid_1's l2: 1.45945
[198]	training's l2: 1.02276	valid_1's l2: 1.45939
[199]	training's l2: 1.02205	valid_1's l2: 1.45939
[200]	training's l2: 1.0213	valid_1's l2: 1.45934
[201]	training's l2: 1.02016	valid_1's l2: 1.45936
[202]	training's l2: 1.0194	valid_1's l2: 1.45933
[203]	training's l2: 1.01852	valid_1's l2: 1.45928
[204]	training's l2: 1.01739	valid_1's l2: 1.45891
[205]	training's l2: 1.01653	valid_1's l2: 1.45878
[206]	training's l2: 1.01548	valid_1's l2: 1.45862
[207]	training's l2: 1.01469	valid_1's l2: 1.45853
[208]	training's l2: 1.01382	valid_1's l2: 1.45841
[209]	training's l2: 1.01308	valid_1's l2: 1.45839
[210]	training's l2: 1.01226	valid_1's l2: 1.45832
[211]	training's l2: 1.01155	valid_1's l2: 1.45828
[212]	training's l2: 1.01073	valid_1's l2: 1.45818
[213]	training's l2: 1.0101	valid_1's l2: 1.45812
[214]	training's l2: 1.00934	valid_1's l2: 1.45808
[215]	training's l2: 1.00865	valid_1's l2: 1.45802
[216]	training's l2: 1.00789	valid_1's l2: 1.45801
[217]	training's l2: 1.00691	valid_1's l2: 1.4582
[218]	training's l2: 1.00589	valid_1's l2: 1.45814
[219]	training's l2: 1.00515	valid_1's l2: 1.45804
[220]	training's l2: 1.00419	valid_1's l2: 1.45797
[221]	training's l2: 1.0035	valid_1's l2: 1.45791
[222]	training's l2: 1.00275	valid_1's l2: 1.45778
[223]	training's l2: 1.00191	valid_1's l2: 1.45766
[224]	training's l2: 1.00117	valid_1's l2: 1.4576
[225]	training's l2: 1.00046	valid_1's l2: 1.45761
[226]	training's l2: 0.999469	valid_1's l2: 1.45759
[227]	training's l2: 0.998734	valid_1's l2: 1.45755
[228]	training's l2: 0.997972	valid_1's l2: 1.45759
[229]	training's l2: 0.997172	valid_1's l2: 1.45755
[230]	training's l2: 0.996235	valid_1's l2: 1.45757
[231]	training's l2: 0.995535	valid_1's l2: 1.45737
[232]	training's l2: 0.994614	valid_1's l2: 1.45734
[233]	training's l2: 0.993917	valid_1's l2: 1.45729
[234]	training's l2: 0.993198	valid_1's l2: 1.45733
[235]	training's l2: 0.992464	valid_1's l2: 1.45732
[236]	training's l2: 0.991678	valid_1's l2: 1.45726
[237]	training's l2: 0.990971	valid_1's l2: 1.45726
[238]	training's l2: 0.990269	valid_1's l2: 1.45719
[239]	training's l2: 0.989469	valid_1's l2: 1.45717
[240]	training's l2: 0.988471	valid_1's l2: 1.45721
[241]	training's l2: 0.987781	valid_1's l2: 1.45712
[242]	training's l2: 0.98709	valid_1's l2: 1.45707
[243]	training's l2: 0.986276	valid_1's l2: 1.45701
[244]	training's l2: 0.985424	valid_1's l2: 1.45698
[245]	training's l2: 0.984764	valid_1's l2: 1.45684
[246]	training's l2: 0.984056	valid_1's l2: 1.4568
[247]	training's l2: 0.983358	valid_1's l2: 1.45674
[248]	training's l2: 0.982704	valid_1's l2: 1.45675
[249]	training's l2: 0.981833	valid_1's l2: 1.4569
[250]	training's l2: 0.981099	valid_1's l2: 1.45689
[251]	training's l2: 0.980217	valid_1's l2: 1.45687
[252]	training's l2: 0.97952	valid_1's l2: 1.45689
[253]	training's l2: 0.978823	valid_1's l2: 1.45686
[254]	training's l2: 0.978087	valid_1's l2: 1.45685
[255]	training's l2: 0.977411	valid_1's l2: 1.45682
[256]	training's l2: 0.976784	valid_1's l2: 1.45674
[257]	training's l2: 0.976077	valid_1's l2: 1.45678
[258]	training's l2: 0.975388	valid_1's l2: 1.45669
[259]	training's l2: 0.974678	valid_1's l2: 1.45671
[260]	training's l2: 0.973924	valid_1's l2: 1.45663
[261]	training's l2: 0.973178	valid_1's l2: 1.4565
[262]	training's l2: 0.972333	valid_1's l2: 1.45642
[263]	training's l2: 0.971729	valid_1's l2: 1.4564
[264]	training's l2: 0.971048	valid_1's l2: 1.45647
[265]	training's l2: 0.970056	valid_1's l2: 1.45649
[266]	training's l2: 0.969381	valid_1's l2: 1.45651
[267]	training's l2: 0.968754	valid_1's l2: 1.45642
[268]	training's l2: 0.968008	valid_1's l2: 1.45638
[269]	training's l2: 0.96736	valid_1's l2: 1.45631
[270]	training's l2: 0.966511	valid_1's l2: 1.4563
[271]	training's l2: 0.965684	valid_1's l2: 1.45624
[272]	training's l2: 0.965005	valid_1's l2: 1.45617
[273]	training's l2: 0.964131	valid_1's l2: 1.45618
[274]	training's l2: 0.963503	valid_1's l2: 1.45613
[275]	training's l2: 0.962884	valid_1's l2: 1.45616
[276]	training's l2: 0.962257	valid_1's l2: 1.4561
[277]	training's l2: 0.961573	valid_1's l2: 1.45607
[278]	training's l2: 0.960727	valid_1's l2: 1.4562
[279]	training's l2: 0.960124	valid_1's l2: 1.45616
[280]	training's l2: 0.959448	valid_1's l2: 1.45615
[281]	training's l2: 0.958612	valid_1's l2: 1.45619
[282]	training's l2: 0.958011	valid_1's l2: 1.45613
[283]	training's l2: 0.957451	valid_1's l2: 1.45618
[284]	training's l2: 0.956836	valid_1's l2: 1.45617
[285]	training's l2: 0.956042	valid_1's l2: 1.45614
[286]	training's l2: 0.955419	valid_1's l2: 1.45611
[287]	training's l2: 0.954777	valid_1's l2: 1.4561
[288]	training's l2: 0.954059	valid_1's l2: 1.45611
[289]	training's l2: 0.953417	valid_1's l2: 1.45605
[290]	training's l2: 0.952836	valid_1's l2: 1.45599
[291]	training's l2: 0.952167	valid_1's l2: 1.45591
[292]	training's l2: 0.951443	valid_1's l2: 1.45594
[293]	training's l2: 0.95072	valid_1's l2: 1.45597
[294]	training's l2: 0.950144	valid_1's l2: 1.45591
[295]	training's l2: 0.949519	valid_1's l2: 1.45586
[296]	training's l2: 0.948928	valid_1's l2: 1.45586
[297]	training's l2: 0.948259	valid_1's l2: 1.45591
[298]	training's l2: 0.947668	valid_1's l2: 1.45581
[299]	training's l2: 0.946841	valid_1's l2: 1.45605
[300]	training's l2: 0.946268	valid_1's l2: 1.45608
[301]	training's l2: 0.945674	valid_1's l2: 1.45606
[302]	training's l2: 0.9451	valid_1's l2: 1.45598
[303]	training's l2: 0.944508	valid_1's l2: 1.45601
[304]	training's l2: 0.943844	valid_1's l2: 1.45602
[305]	training's l2: 0.943157	valid_1's l2: 1.4561
[306]	training's l2: 0.942584	valid_1's l2: 1.45607
[307]	training's l2: 0.941953	valid_1's l2: 1.45614
[308]	training's l2: 0.941331	valid_1's l2: 1.4561
[309]	training's l2: 0.940699	valid_1's l2: 1.45607
[310]	training's l2: 0.939998	valid_1's l2: 1.45614
[311]	training's l2: 0.93921	valid_1's l2: 1.4562
[312]	training's l2: 0.938527	valid_1's l2: 1.45612
[313]	training's l2: 0.937942	valid_1's l2: 1.45609
[314]	training's l2: 0.937244	valid_1's l2: 1.45611
[315]	training's l2: 0.936662	valid_1's l2: 1.45607
[316]	training's l2: 0.936093	valid_1's l2: 1.45607
[317]	training's l2: 0.935451	valid_1's l2: 1.45617
[318]	training's l2: 0.934841	valid_1's l2: 1.45613
[319]	training's l2: 0.934178	valid_1's l2: 1.45613
[320]	training's l2: 0.933563	valid_1's l2: 1.4561
[321]	training's l2: 0.932972	valid_1's l2: 1.45619
[322]	training's l2: 0.932147	valid_1's l2: 1.45635
[323]	training's l2: 0.93152	valid_1's l2: 1.45639
[324]	training's l2: 0.930808	valid_1's l2: 1.45658
[325]	training's l2: 0.930057	valid_1's l2: 1.45663
[326]	training's l2: 0.929535	valid_1's l2: 1.45663
[327]	training's l2: 0.928968	valid_1's l2: 1.45654
[328]	training's l2: 0.928433	valid_1's l2: 1.45648
Early stopping, best iteration is:
[298]	training's l2: 0.947668	valid_1's l2: 1.45581
score: 1.2702389898679012
