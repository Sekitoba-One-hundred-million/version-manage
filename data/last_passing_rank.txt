wrap_data.pickle download finish Gilgamesh
race_money_data.pickle download finish Gilgamesh
next_race_data.pickle download finish Gilgamesh
predict_first_passing_rank.pickle download finish Gilgamesh
predict_pace_data.pickle download finish Gilgamesh
start rank:1
start rank:4
start rank:5
start rank:2
start rank:3
1-instance.pickle download finish Gilgamesh
2-instance.pickle download finish Gilgamesh
3-instance.pickle download finish Gilgamesh
4-instance.pickle download finish Gilgamesh
5-instance.pickle download finish Gilgamesh
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.394368 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 39372
[LightGBM] [Info] Number of data points in the train set: 632073, number of used features: 223
[LightGBM] [Info] Start training from score -0.071946
Training until validation scores don't improve for 30 rounds
[10]	training's l2: 4.80256	valid_1's l2: 4.49834
[20]	training's l2: 4.66798	valid_1's l2: 4.39391
[30]	training's l2: 4.56291	valid_1's l2: 4.31548
[40]	training's l2: 4.47888	valid_1's l2: 4.25393
[50]	training's l2: 4.4116	valid_1's l2: 4.20609
[60]	training's l2: 4.35717	valid_1's l2: 4.16933
[70]	training's l2: 4.31186	valid_1's l2: 4.14023
[80]	training's l2: 4.27392	valid_1's l2: 4.11664
[90]	training's l2: 4.24121	valid_1's l2: 4.09733
[100]	training's l2: 4.21265	valid_1's l2: 4.08203
[110]	training's l2: 4.18793	valid_1's l2: 4.0691
[120]	training's l2: 4.16537	valid_1's l2: 4.05875
[130]	training's l2: 4.14531	valid_1's l2: 4.05001
[140]	training's l2: 4.12734	valid_1's l2: 4.04305
[150]	training's l2: 4.11052	valid_1's l2: 4.03682
[160]	training's l2: 4.09532	valid_1's l2: 4.03151
[170]	training's l2: 4.08083	valid_1's l2: 4.02739
[180]	training's l2: 4.06707	valid_1's l2: 4.02341
[190]	training's l2: 4.05398	valid_1's l2: 4.0198
[200]	training's l2: 4.04146	valid_1's l2: 4.01669
[210]	training's l2: 4.02935	valid_1's l2: 4.01415
[220]	training's l2: 4.01781	valid_1's l2: 4.01197
[230]	training's l2: 4.00699	valid_1's l2: 4.01025
[240]	training's l2: 3.99632	valid_1's l2: 4.00882
[250]	training's l2: 3.98573	valid_1's l2: 4.00666
[260]	training's l2: 3.97539	valid_1's l2: 4.00499
[270]	training's l2: 3.96547	valid_1's l2: 4.00357
[280]	training's l2: 3.95592	valid_1's l2: 4.00182
[290]	training's l2: 3.9463	valid_1's l2: 4.00048
[300]	training's l2: 3.93712	valid_1's l2: 3.99934
[310]	training's l2: 3.92828	valid_1's l2: 3.99838
[320]	training's l2: 3.91947	valid_1's l2: 3.99738
[330]	training's l2: 3.91065	valid_1's l2: 3.99634
[340]	training's l2: 3.90198	valid_1's l2: 3.99533
[350]	training's l2: 3.89333	valid_1's l2: 3.99464
[360]	training's l2: 3.88511	valid_1's l2: 3.99388
[370]	training's l2: 3.87678	valid_1's l2: 3.99324
[380]	training's l2: 3.86857	valid_1's l2: 3.99256
[390]	training's l2: 3.86053	valid_1's l2: 3.99192
[400]	training's l2: 3.85244	valid_1's l2: 3.99133
[410]	training's l2: 3.84468	valid_1's l2: 3.99115
[420]	training's l2: 3.83687	valid_1's l2: 3.99068
[430]	training's l2: 3.82948	valid_1's l2: 3.99014
[440]	training's l2: 3.82196	valid_1's l2: 3.98952
[450]	training's l2: 3.8144	valid_1's l2: 3.98929
[460]	training's l2: 3.80703	valid_1's l2: 3.98903
[470]	training's l2: 3.79975	valid_1's l2: 3.98882
[480]	training's l2: 3.79228	valid_1's l2: 3.98839
[490]	training's l2: 3.78509	valid_1's l2: 3.98844
[500]	training's l2: 3.77803	valid_1's l2: 3.98827
[510]	training's l2: 3.77081	valid_1's l2: 3.9881
[520]	training's l2: 3.76388	valid_1's l2: 3.98786
[530]	training's l2: 3.75677	valid_1's l2: 3.98749
[540]	training's l2: 3.74985	valid_1's l2: 3.98746
[550]	training's l2: 3.74277	valid_1's l2: 3.9872
[560]	training's l2: 3.73604	valid_1's l2: 3.98698
[570]	training's l2: 3.72916	valid_1's l2: 3.98658
[580]	training's l2: 3.72238	valid_1's l2: 3.98622
[590]	training's l2: 3.71573	valid_1's l2: 3.98581
[600]	training's l2: 3.70915	valid_1's l2: 3.98551
[610]	training's l2: 3.70255	valid_1's l2: 3.9852
[620]	training's l2: 3.69577	valid_1's l2: 3.98479
[630]	training's l2: 3.68919	valid_1's l2: 3.98449
[640]	training's l2: 3.68261	valid_1's l2: 3.98436
[650]	training's l2: 3.67637	valid_1's l2: 3.98415
[660]	training's l2: 3.66997	valid_1's l2: 3.98395
[670]	training's l2: 3.66376	valid_1's l2: 3.98386
[680]	training's l2: 3.6577	valid_1's l2: 3.98378
[690]	training's l2: 3.65155	valid_1's l2: 3.98349
[700]	training's l2: 3.64528	valid_1's l2: 3.98308
[710]	training's l2: 3.63903	valid_1's l2: 3.98256
[720]	training's l2: 3.63294	valid_1's l2: 3.98243
[730]	training's l2: 3.62718	valid_1's l2: 3.98207
[740]	training's l2: 3.62137	valid_1's l2: 3.98174
[750]	training's l2: 3.61527	valid_1's l2: 3.98159
[760]	training's l2: 3.60942	valid_1's l2: 3.98155
[770]	training's l2: 3.60386	valid_1's l2: 3.98145
[780]	training's l2: 3.59788	valid_1's l2: 3.98124
[790]	training's l2: 3.59223	valid_1's l2: 3.98087
[800]	training's l2: 3.5865	valid_1's l2: 3.98065
[810]	training's l2: 3.58077	valid_1's l2: 3.98038
[820]	training's l2: 3.57495	valid_1's l2: 3.98046
[830]	training's l2: 3.56939	valid_1's l2: 3.98013
[840]	training's l2: 3.56366	valid_1's l2: 3.98015
[850]	training's l2: 3.55795	valid_1's l2: 3.97997
[860]	training's l2: 3.55256	valid_1's l2: 3.9799
[870]	training's l2: 3.54746	valid_1's l2: 3.97988
[880]	training's l2: 3.54202	valid_1's l2: 3.97993
Early stopping, best iteration is:
[854]	training's l2: 3.55567	valid_1's l2: 3.97981
score: 3.3387373662193873
